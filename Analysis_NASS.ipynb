{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "[![Open on GitHub](https://img.shields.io/badge/GitHub-View%20Source-181717?style=for-the-badge&logo=github)](https://github.com/SeenaKhosravi/NASS/blob/main/Analysis_NASS.ipynb)\n",
        "[![Open In Colab](https://img.shields.io/badge/Colab-Open%20Notebook-F9AB00?style=for-the-badge&logo=google-colab)](https://colab.research.google.com/github/SeenaKhosravi/NASS/blob/main/Analysis_NASS.ipynb)\n",
        "[![Open in Vertex AI](https://img.shields.io/badge/Vertex%20AI-Open%20Workbench-4285F4?style=for-the-badge&logo=google-cloud)](https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/SeenaKhosravi/NASS/main/Analysis_NASS.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbe6c3e6"
      },
      "source": [
        "# Socioeconomic and Demographic Drivers of Ambulatory Surgery Usage\n",
        "### HCUP NASS 2020 ‚Äì Reproducible Pipeline (Python + R)\n",
        "\n",
        "**Author:** Seena Khosravi, MD  \n",
        "**LLMs Utilized:** Claude Sonnet 4.1, Opus 4.1; ChatGPT 4o, o4; Deepseek 3.1; Gemini 2.5 Pro  \n",
        "**Last Updated:** September 9, 2025  \n",
        "\n",
        "**Data Source:**  \n",
        "Department of Health & Human Services (HHS)  \n",
        "Agency for Healthcare Research and Quality (AHRQ)  \n",
        "Healthcare Cost and Utilization Project (HCUP)  \n",
        "National Ambulatory Surgical Sample (NASS) \n",
        "Year - 2020 \n",
        "\n",
        "---\n",
        "\n",
        "## Overview\n",
        "This notebook provides a reproducible analysis pipeline for examining socioeconomic and demographic factors influencing ambulatory surgery usage patterns. The analysis combines Python for data processing and R for statistical modeling. It assumes a processed dataset was created from the HCUP files via [Raw_NASS_Processing.R](https://github.com/SeenaKhosravi/NASS/blob/a7764ce80be8a82fc449831821c27d957176c410/Raw%20NASS%20%20Processing.R).\n",
        "\n",
        "### Data Usage Agreement\n",
        "**DUA Compliant Online Implementation** ‚Äî This notebook uses a simulated, artificial, smaller dataset with identical structure to the file created by [Raw_NASS_Processing.R](https://github.com/SeenaKhosravi/NASS/blob/a7764ce80be8a82fc449831821c27d957176c410/Raw%20NASS%20%20Processing.R). The simulated dataset production methodology is also in [Raw_NASS_Processing.R](https://github.com/SeenaKhosravi/NASS/blob/a7764ce80be8a82fc449831821c27d957176c410/Raw%20NASS%20%20Processing.R). If DUA signed and data purchased from HCUP, this notebook can run on full dataset loaded from your local storage or cloud storage. \n",
        "\n",
        "[Please see the DUA Agreement here.](https://hcup-us.ahrq.gov/team/NationwideDUA.jsp)\n",
        "\n",
        "### Key Features\n",
        "- **Multiple Platform:** Works on jupyter implementations via local environments, server, cloud VM instance, or platform as a service.\n",
        "- **Flexible Data Storage:** GitHub (simulated, static, open access), Google Drive, Google Cloud Storage, or local files (closed access)\n",
        "- **Reproducible:** All dependencies and environment setup included\n",
        "- **Scalable:** Handles both simulated (1GB, 700k rows) and full dataset (12 GB, 7.8M rows). Scalable cloud options. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "019b6fe9"
      },
      "source": [
        "---\n",
        "\n",
        "## Design Notes\n",
        "\n",
        "### Architecture\n",
        "- **Python primary, w/ R run via rpy2 python extension**\n",
        "- **Python cells** handle \"plumbing\" (file I/O, environment setup, rpy2 configuration, data previews)\n",
        "- **R cells** (prefixed by `%%R`) perform statistical analysis: survey weights, Census lookups, multilevel models, plots, classifiers, etc.\n",
        "\n",
        "### Data Sources\n",
        "- **Default:** Simulated dataset (1GB) from GitHub releases\n",
        "- **Local:** Switch to locally stored files via configuration\n",
        "- **Drive:** Google Drive (Only availble in Colab)\n",
        "- **Cloud:** Google Cloud Storage support for large datasets\n",
        "\n",
        "\n",
        "### Environment Support\n",
        "- Local (Jupyterlab w/ Python 3.12 kernel)\n",
        "- Jupyter Server (may require some configuring depending on your implementation)\n",
        "- Google Colab (Pro recommended, high-ram option)\n",
        "- Vertex AI Workbench (JupyterLab 3, Python 3 kernel) (used for full analysis)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 1. Configuration\n",
        "\n",
        "Configure all settings here prior to run - data sources, debugging options, and file paths. Defaults to simulated dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Configuration loaded\n",
            "  Data source: github\n",
            "  Verbose mode: True\n"
          ]
        }
      ],
      "source": [
        "# ==================== CONFIGURATION ====================\n",
        "# Data Source Options\n",
        "DATA_SOURCE = \"github\"      # Options: \"github\", \"local\", \"gcs\", \"drive\"\n",
        "VERBOSE_PRINTS = True       # False ‚Üí suppress debug output\n",
        "\n",
        "# GitHub source (default - simulated data)\n",
        "GITHUB_URL = \"https://github.com/SeenaKhosravi/NASS/releases/download/v1.0.0/nass_2020_simulated.csv\"\n",
        "\n",
        "# Local file options\n",
        "LOCAL_FILENAME = \"nass_2020_local.csv\"\n",
        "\n",
        "# Google Cloud Storage options\n",
        "GCS_BUCKET = \"nass_2020\"\n",
        "GCS_BLOB = \"nass_2020_all.csv\"\n",
        "GCS_SERVICE_ACCOUNT_KEY = \"/path/to/service-account-key.json\"  # Optional\n",
        "\n",
        "# Google Drive options (for Colab)\n",
        "DRIVE_PATH = \"/content/drive/MyDrive/NASS/nass_2020_full.csv\"\n",
        "# ======================================================\n",
        "\n",
        "print(\"‚úì Configuration loaded\")\n",
        "print(f\"  Data source: {DATA_SOURCE}\")\n",
        "print(f\"  Verbose mode: {VERBOSE_PRINTS}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 2. Environment Setup & Package Installation\n",
        "\n",
        "Detect environment, and define python functions for loading packages, via Conda unless in colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment: Local/Jupyter\n",
            "Installing/checking packages...\n",
            "Installing pandas...\n",
            "Installing requests...\n",
            "Installing requests...\n",
            "Installing rpy2...\n",
            "Installing rpy2...\n",
            "Installing google.cloud.storage...\n",
            "Installing google.cloud.storage...\n",
            "‚úì All packages ready\n",
            "‚úì All packages ready\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "class EnvironmentManager:\n",
        "    def __init__(self):\n",
        "        self.detect_environment()\n",
        "        self.setup_packages()\n",
        "    \n",
        "    def detect_environment(self):\n",
        "        \"\"\"Detect runtime environment\"\"\"\n",
        "        self.is_colab = 'COLAB_GPU' in os.environ or 'google.colab' in sys.modules\n",
        "        self.is_vertex = 'DL_ANACONDA_HOME' in os.environ\n",
        "        \n",
        "        if self.is_colab:\n",
        "            self.env_type = \"Google Colab\"\n",
        "        elif self.is_vertex:\n",
        "            self.env_type = \"Vertex AI\"\n",
        "        else:\n",
        "            self.env_type = \"Local/Jupyter\"\n",
        "        \n",
        "        print(f\"Environment: {self.env_type}\")\n",
        "    \n",
        "    def check_conda_available(self):\n",
        "        \"\"\"Check if conda is available\"\"\"\n",
        "        try:\n",
        "            subprocess.check_call(['conda', '--version'], \n",
        "                                stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "            return True\n",
        "        except (subprocess.CalledProcessError, FileNotFoundError):\n",
        "            return False\n",
        "    \n",
        "    def install_package(self, package, conda_name=None):\n",
        "        \"\"\"Smart package installation with fallback\"\"\"\n",
        "        try:\n",
        "            __import__(package)\n",
        "            return True\n",
        "        except ImportError:\n",
        "            print(f\"Installing {package}...\")\n",
        "            \n",
        "            # Try conda first if available and not in Colab\n",
        "            if conda_name and not self.is_colab and self.check_conda_available():\n",
        "                try:\n",
        "                    subprocess.check_call(['conda', 'install', '-y', conda_name], \n",
        "                                        stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "                    return True\n",
        "                except subprocess.CalledProcessError:\n",
        "                    print(f\"  Conda install failed for {conda_name}, trying pip...\")\n",
        "            \n",
        "            # Fallback to pip\n",
        "            try:\n",
        "                subprocess.check_call([sys.executable, '-m', 'pip', 'install', package], \n",
        "                                    stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "                return True\n",
        "            except subprocess.CalledProcessError as e:\n",
        "                print(f\"  Pip install failed for {package}: {e}\")\n",
        "                return False\n",
        "    \n",
        "    def setup_packages(self):\n",
        "        \"\"\"Install required packages efficiently\"\"\"\n",
        "        packages = {\n",
        "            'pandas': 'pandas',\n",
        "            'requests': 'requests', \n",
        "            'rpy2': 'rpy2',\n",
        "            'google.cloud.storage': 'google-cloud-storage'\n",
        "        }\n",
        "        \n",
        "        print(\"Installing/checking packages...\")\n",
        "        failed = []\n",
        "        \n",
        "        for pkg, install_name in packages.items():\n",
        "            if not self.install_package(pkg, install_name):\n",
        "                failed.append(pkg)\n",
        "        \n",
        "        # Store failed packages globally for recovery\n",
        "        globals()['failed_packages'] = failed\n",
        "        \n",
        "        if failed:\n",
        "            print(f\"‚ö†Ô∏è  Failed to install: {', '.join(failed)}\")\n",
        "            print(\"Some features may not work\")\n",
        "            \n",
        "            # Provide specific guidance for rpy2\n",
        "            if 'rpy2' in failed:\n",
        "                print(\"\\nüí° For rpy2 installation issues:\")\n",
        "                if self.is_vertex:\n",
        "                    print(\"   - Vertex AI: R may not be installed by default\")\n",
        "                    print(\"   - Run the next cell for automated R setup\")\n",
        "                else:\n",
        "                    print(\"   - On Windows: May need Visual Studio Build Tools\")\n",
        "                    print(\"   - Try: conda install -c conda-forge rpy2\")\n",
        "                    print(\"   - Or: pip install rpy2 (requires R to be installed)\")\n",
        "        else:\n",
        "            print(\"‚úì All packages ready\")\n",
        "        \n",
        "        # Mount Google Drive if needed (check if DATA_SOURCE exists)\n",
        "        try:\n",
        "            if globals().get('DATA_SOURCE') == \"drive\" and self.is_colab:\n",
        "                self.mount_drive()\n",
        "        except NameError:\n",
        "            pass  # DATA_SOURCE not defined yet\n",
        "    \n",
        "    def mount_drive(self):\n",
        "        \"\"\"Mount Google Drive in Colab\"\"\"\n",
        "        try:\n",
        "            from google.colab import drive\n",
        "            drive.mount('/content/drive')\n",
        "            print(\"‚úì Google Drive mounted\")\n",
        "        except:\n",
        "            print(\"‚ùå Failed to mount Google Drive\")\n",
        "\n",
        "# Initialize environment\n",
        "env_manager = EnvironmentManager()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If Running in Vertex Workbench, and last cell did not work, run this cell to install R, and re-run last cell. \n",
        "\n",
        "Otherwise, skip this cell. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vertex AI Workbench: R and rpy2 Installation Helper\n",
        "def setup_r_for_vertex_ai():\n",
        "    \"\"\"Install R and rpy2 on Vertex AI Workbench\"\"\"\n",
        "    print(\"Setting up R environment for Vertex AI...\")\n",
        "    \n",
        "    # Check if R is installed\n",
        "    try:\n",
        "        subprocess.check_call(['R', '--version'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "        print(\"‚úì R is already installed\")\n",
        "        r_installed = True\n",
        "    except (subprocess.CalledProcessError, FileNotFoundError):\n",
        "        print(\"‚ùå R not found - installing...\")\n",
        "        r_installed = False\n",
        "    \n",
        "    # Install R if not present\n",
        "    if not r_installed:\n",
        "        try:\n",
        "            # Update package list\n",
        "            subprocess.check_call(['sudo', 'apt-get', 'update'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "            \n",
        "            # Install R\n",
        "            subprocess.check_call(['sudo', 'apt-get', 'install', '-y', 'r-base', 'r-base-dev'], \n",
        "                                stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "            \n",
        "            # Install development tools needed for rpy2\n",
        "            subprocess.check_call(['sudo', 'apt-get', 'install', '-y', 'build-essential', 'libcurl4-openssl-dev', \n",
        "                                 'libssl-dev', 'libxml2-dev'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "            \n",
        "            print(\"‚úì R installed successfully\")\n",
        "            \n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"‚ùå Failed to install R: {e}\")\n",
        "            return False\n",
        "    \n",
        "    # Now try to install rpy2\n",
        "    print(\"Installing rpy2...\")\n",
        "    methods = [\n",
        "        ([sys.executable, '-m', 'pip', 'install', '--upgrade', 'pip', 'setuptools', 'wheel'], \"upgrade pip tools\"),\n",
        "        ([sys.executable, '-m', 'pip', 'install', 'rpy2'], \"pip install rpy2\"),\n",
        "        (['conda', 'install', '-c', 'conda-forge', 'rpy2', '-y'], \"conda-forge rpy2\"),\n",
        "        ([sys.executable, '-m', 'pip', 'install', '--no-cache-dir', '--force-reinstall', 'rpy2'], \"force reinstall rpy2\"),\n",
        "    ]\n",
        "    \n",
        "    for cmd, description in methods:\n",
        "        try:\n",
        "            print(f\"  Trying: {description}\")\n",
        "            subprocess.check_call(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "            print(f\"  ‚úì Success: {description}\")\n",
        "            \n",
        "            # Test if rpy2 can be imported\n",
        "            try:\n",
        "                import rpy2\n",
        "                print(\"‚úì rpy2 installed and importable\")\n",
        "                return True\n",
        "            except ImportError:\n",
        "                print(f\"  ‚ö†Ô∏è {description} completed but rpy2 still not importable\")\n",
        "                continue\n",
        "                \n",
        "        except (subprocess.CalledProcessError, FileNotFoundError):\n",
        "            print(f\"  ‚úó Failed: {description}\")\n",
        "            continue\n",
        "    \n",
        "    print(\"‚ùå All rpy2 installation methods failed\")\n",
        "    return False\n",
        "\n",
        "def install_rpy2_alternatives():\n",
        "    \"\"\"Try different methods to install rpy2 with environment-specific handling\"\"\"\n",
        "    print(\"Attempting rpy2 installation...\")\n",
        "    \n",
        "    # Check if we're on Vertex AI and try specialized setup\n",
        "    if env_manager.is_vertex:\n",
        "        print(\"Detected Vertex AI - using specialized R setup...\")\n",
        "        if setup_r_for_vertex_ai():\n",
        "            return True\n",
        "    \n",
        "    # Standard installation methods\n",
        "    print(\"Trying standard installation methods...\")\n",
        "    methods = [\n",
        "        ([sys.executable, '-m', 'pip', 'install', '--upgrade', 'pip'], \"upgrade pip\"),\n",
        "        ([sys.executable, '-m', 'pip', 'install', 'rpy2'], \"pip install rpy2\"),\n",
        "        (['conda', 'install', '-c', 'conda-forge', 'rpy2', '-y'], \"conda-forge rpy2\"),\n",
        "        ([sys.executable, '-m', 'pip', 'install', '--no-cache-dir', 'rpy2'], \"pip no-cache rpy2\"),\n",
        "    ]\n",
        "    \n",
        "    for cmd, description in methods:\n",
        "        try:\n",
        "            print(f\"Trying: {description}\")\n",
        "            subprocess.check_call(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "            \n",
        "            # Test import\n",
        "            try:\n",
        "                import rpy2\n",
        "                print(\"‚úì Success!\")\n",
        "                return True\n",
        "            except ImportError:\n",
        "                continue\n",
        "                \n",
        "        except (subprocess.CalledProcessError, FileNotFoundError):\n",
        "            print(f\"‚úó Failed: {description}\")\n",
        "            continue\n",
        "    \n",
        "    print(\"‚ùå All rpy2 installation methods failed\")\n",
        "    print(\"\\nüí° Manual solutions:\")\n",
        "    \n",
        "    if env_manager.is_vertex:\n",
        "        print(\"For Vertex AI Workbench:\")\n",
        "        print(\"   1. Open a terminal in JupyterLab\")\n",
        "        print(\"   2. Run: sudo apt-get update\")\n",
        "        print(\"   3. Run: sudo apt-get install -y r-base r-base-dev build-essential\")\n",
        "        print(\"   4. Run: pip install rpy2\")\n",
        "        print(\"   5. Restart the Python kernel\")\n",
        "    else:\n",
        "        print(\"General solutions:\")\n",
        "        print(\"   1. Ensure R is installed on your system\")\n",
        "        print(\"   2. On Windows: install Visual Studio Build Tools\")\n",
        "        print(\"   3. Try: pip install --upgrade pip setuptools wheel\")\n",
        "        print(\"   4. Then: pip install rpy2\")\n",
        "    \n",
        "    return False\n",
        "\n",
        "# Run the installation if rpy2 failed in the main setup\n",
        "if 'rpy2' in globals().get('failed_packages', []):\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"ATTEMPTING rpy2 RECOVERY\")\n",
        "    print(\"=\"*50)\n",
        "    install_rpy2_alternatives()\n",
        "    print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Manual R Installation for Vertex AI Workbench\n",
        "\n",
        "If automatic installation still fails, you can manually install R and rpy2 by opening a **Terminal** in JupyterLab and running these commands:\n",
        "\n",
        "```bash\n",
        "# Update package list\n",
        "sudo apt-get update\n",
        "\n",
        "# Install R and development tools\n",
        "sudo apt-get install -y r-base r-base-dev build-essential libcurl4-openssl-dev libssl-dev libxml2-dev\n",
        "\n",
        "# Install rpy2 \n",
        "pip install --upgrade pip setuptools wheel\n",
        "pip install rpy2\n",
        "\n",
        "# Verify installation\n",
        "python -c \"import rpy2; print('rpy2 installed successfully')\"\n",
        "```\n",
        "\n",
        "After running these commands:\n",
        "1. **Restart the Python kernel** (Kernel ‚Üí Restart Kernel)\n",
        "2. Re-run the environment setup cells\n",
        "3. Continue with the analysis\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 3. Data Loading\n",
        "\n",
        "Config based data loader with error handling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data from: GITHUB\n",
            "‚úì Downloaded from GitHub (213436933 bytes)\n",
            "‚úì Downloaded from GitHub (213436933 bytes)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\laure\\AppData\\Local\\Temp\\ipykernel_11324\\2611932633.py:35: DtypeWarning: Columns (56,57,58,59) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  return pd.read_csv(data_path)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Data loaded successfully!\n",
            "   Shape: (139233, 675)\n",
            "   Memory: 885.2 MB\n",
            "\n",
            "Columns: ['KEY_NASS', 'HOSP_NASS', 'HOSP_TEACH', 'HOSP_LOCATION', 'HOSP_LOCTEACH', 'HOSP_REGION', 'HOSP_BEDSIZE_CAT', 'DISCWT', 'NASS_STRATUM', 'N_DISC_U', 'N_HOSP_U', 'S_DISC_U', 'S_HOSP_U', 'TOTAL_AS_ENCOUNTERS', 'YEAR', 'AGE', 'FEMALE', 'PL_NCHS', 'ZIPINC_QRTL', 'AMONTH', 'AWEEKEND', 'DQTR', 'PAY1', 'DISPUNIFORM', 'TOTCHG', 'NCPT_INSCOPE', 'CPTCCS1', 'CPTCCS2', 'CPTCCS3', 'CPTCCS4', 'CPTCCS5', 'CPTCCS6', 'CPTCCS7', 'CPTCCS8', 'CPTCCS9', 'CPTCCS10', 'CPTCCS11', 'CPTCCS12', 'CPTCCS13', 'CPTCCS14', 'CPTCCS15', 'CPTCCS16', 'CPTCCS17', 'CPTCCS18', 'CPTCCS19', 'CPTCCS20', 'CPTCCS21', 'CPTCCS22', 'CPTCCS23', 'CPTCCS24', 'CPTCCS25', 'CPTCCS26', 'CPTCCS27', 'CPTCCS28', 'CPTCCS29', 'CPTCCS30', 'CPT1', 'CPT2', 'CPT3', 'CPT4', 'CPT5', 'CPT6', 'CPT7', 'CPT8', 'CPT9', 'CPT10', 'CPT11', 'CPT12', 'CPT13', 'CPT14', 'CPT15', 'CPT16', 'CPT17', 'CPT18', 'CPT19', 'CPT20', 'CPT21', 'CPT22', 'CPT23', 'CPT24', 'CPT25', 'CPT26', 'CPT27', 'CPT28', 'CPT29', 'CPT30', 'I10_NDX', 'I10_DX1', 'I10_DX2', 'I10_DX3', 'I10_DX4', 'I10_DX5', 'I10_DX6', 'I10_DX7', 'I10_DX8', 'I10_DX9', 'I10_DX10', 'I10_DX11', 'I10_DX12', 'I10_DX13', 'I10_DX14', 'I10_DX15', 'I10_DX16', 'I10_DX17', 'I10_DX18', 'I10_DX19', 'I10_DX20', 'RACE', 'I10_INJURY', 'I10_MULTINJURY', 'CMR_AIDS', 'CMR_ALCOHOL', 'CMR_AUTOIMMUNE', 'CMR_CANCER_LYMPH', 'CMR_CANCER_LEUK', 'CMR_CANCER_METS', 'CMR_CANCER_NSITU', 'CMR_CANCER_SOLID', 'CMR_DEMENTIA', 'CMR_DEPRESS', 'CMR_DIAB_UNCX', 'CMR_DIAB_CX', 'CMR_DRUG_ABUSE', 'CMR_HTN_CX', 'CMR_HTN_UNCX', 'CMR_LUNG_CHRONIC', 'CMR_OBESE', 'CMR_PERIVASC', 'CMR_THYROID_HYPO', 'CMR_THYROID_OTH', 'CMR_VERSION', 'DXCCSR_Default_DX1', 'DXCCSR_BLD001', 'DXCCSR_BLD002', 'DXCCSR_BLD003', 'DXCCSR_BLD004', 'DXCCSR_BLD005', 'DXCCSR_BLD006', 'DXCCSR_BLD007', 'DXCCSR_BLD008', 'DXCCSR_BLD009', 'DXCCSR_BLD010', 'DXCCSR_CIR001', 'DXCCSR_CIR002', 'DXCCSR_CIR003', 'DXCCSR_CIR004', 'DXCCSR_CIR005', 'DXCCSR_CIR006', 'DXCCSR_CIR007', 'DXCCSR_CIR008', 'DXCCSR_CIR009', 'DXCCSR_CIR010', 'DXCCSR_CIR011', 'DXCCSR_CIR012', 'DXCCSR_CIR013', 'DXCCSR_CIR014', 'DXCCSR_CIR015', 'DXCCSR_CIR016', 'DXCCSR_CIR017', 'DXCCSR_CIR018', 'DXCCSR_CIR019', 'DXCCSR_CIR020', 'DXCCSR_CIR021', 'DXCCSR_CIR022', 'DXCCSR_CIR023', 'DXCCSR_CIR024', 'DXCCSR_CIR025', 'DXCCSR_CIR026', 'DXCCSR_CIR027', 'DXCCSR_CIR028', 'DXCCSR_CIR029', 'DXCCSR_CIR030', 'DXCCSR_CIR031', 'DXCCSR_CIR032', 'DXCCSR_CIR033', 'DXCCSR_CIR034', 'DXCCSR_CIR035', 'DXCCSR_CIR036', 'DXCCSR_CIR037', 'DXCCSR_CIR038', 'DXCCSR_CIR039', 'DXCCSR_DIG001', 'DXCCSR_DIG002', 'DXCCSR_DIG003', 'DXCCSR_DIG004', 'DXCCSR_DIG005', 'DXCCSR_DIG006', 'DXCCSR_DIG007', 'DXCCSR_DIG008', 'DXCCSR_DIG009', 'DXCCSR_DIG010', 'DXCCSR_DIG011', 'DXCCSR_DIG012', 'DXCCSR_DIG013', 'DXCCSR_DIG014', 'DXCCSR_DIG015', 'DXCCSR_DIG016', 'DXCCSR_DIG017', 'DXCCSR_DIG018', 'DXCCSR_DIG019', 'DXCCSR_DIG020', 'DXCCSR_DIG021', 'DXCCSR_DIG022', 'DXCCSR_DIG023', 'DXCCSR_DIG024', 'DXCCSR_DIG025', 'DXCCSR_EAR001', 'DXCCSR_EAR002', 'DXCCSR_EAR003', 'DXCCSR_EAR004', 'DXCCSR_EAR005', 'DXCCSR_EAR006', 'DXCCSR_END001', 'DXCCSR_END002', 'DXCCSR_END003', 'DXCCSR_END004', 'DXCCSR_END005', 'DXCCSR_END006', 'DXCCSR_END007', 'DXCCSR_END008', 'DXCCSR_END009', 'DXCCSR_END010', 'DXCCSR_END011', 'DXCCSR_END012', 'DXCCSR_END013', 'DXCCSR_END014', 'DXCCSR_END015', 'DXCCSR_END016', 'DXCCSR_END017', 'DXCCSR_EXT001', 'DXCCSR_EXT002', 'DXCCSR_EXT003', 'DXCCSR_EXT004', 'DXCCSR_EXT005', 'DXCCSR_EXT006', 'DXCCSR_EXT007', 'DXCCSR_EXT008', 'DXCCSR_EXT009', 'DXCCSR_EXT010', 'DXCCSR_EXT011', 'DXCCSR_EXT012', 'DXCCSR_EXT013', 'DXCCSR_EXT014', 'DXCCSR_EXT015', 'DXCCSR_EXT016', 'DXCCSR_EXT017', 'DXCCSR_EXT018', 'DXCCSR_EXT019', 'DXCCSR_EXT020', 'DXCCSR_EXT021', 'DXCCSR_EXT022', 'DXCCSR_EXT023', 'DXCCSR_EXT024', 'DXCCSR_EXT025', 'DXCCSR_EXT026', 'DXCCSR_EXT027', 'DXCCSR_EXT028', 'DXCCSR_EXT029', 'DXCCSR_EXT030', 'DXCCSR_EYE001', 'DXCCSR_EYE002', 'DXCCSR_EYE003', 'DXCCSR_EYE004', 'DXCCSR_EYE005', 'DXCCSR_EYE006', 'DXCCSR_EYE007', 'DXCCSR_EYE008', 'DXCCSR_EYE009', 'DXCCSR_EYE010', 'DXCCSR_EYE011', 'DXCCSR_EYE012', 'DXCCSR_FAC001', 'DXCCSR_FAC002', 'DXCCSR_FAC003', 'DXCCSR_FAC004', 'DXCCSR_FAC005', 'DXCCSR_FAC006', 'DXCCSR_FAC007', 'DXCCSR_FAC008', 'DXCCSR_FAC009', 'DXCCSR_FAC010', 'DXCCSR_FAC011', 'DXCCSR_FAC012', 'DXCCSR_FAC013', 'DXCCSR_FAC014', 'DXCCSR_FAC015', 'DXCCSR_FAC016', 'DXCCSR_FAC017', 'DXCCSR_FAC018', 'DXCCSR_FAC019', 'DXCCSR_FAC020', 'DXCCSR_FAC021', 'DXCCSR_FAC022', 'DXCCSR_FAC023', 'DXCCSR_FAC024', 'DXCCSR_FAC025', 'DXCCSR_GEN001', 'DXCCSR_GEN002', 'DXCCSR_GEN003', 'DXCCSR_GEN004', 'DXCCSR_GEN005', 'DXCCSR_GEN006', 'DXCCSR_GEN007', 'DXCCSR_GEN008', 'DXCCSR_GEN009', 'DXCCSR_GEN010', 'DXCCSR_GEN011', 'DXCCSR_GEN012', 'DXCCSR_GEN013', 'DXCCSR_GEN014', 'DXCCSR_GEN015', 'DXCCSR_GEN016', 'DXCCSR_GEN017', 'DXCCSR_GEN018', 'DXCCSR_GEN019', 'DXCCSR_GEN020', 'DXCCSR_GEN021', 'DXCCSR_GEN022', 'DXCCSR_GEN023', 'DXCCSR_GEN024', 'DXCCSR_GEN025', 'DXCCSR_GEN026', 'DXCCSR_INF001', 'DXCCSR_INF002', 'DXCCSR_INF003', 'DXCCSR_INF004', 'DXCCSR_INF005', 'DXCCSR_INF006', 'DXCCSR_INF007', 'DXCCSR_INF008', 'DXCCSR_INF009', 'DXCCSR_INF010', 'DXCCSR_INF011', 'DXCCSR_INF012', 'DXCCSR_INJ001', 'DXCCSR_INJ002', 'DXCCSR_INJ003', 'DXCCSR_INJ004', 'DXCCSR_INJ005', 'DXCCSR_INJ006', 'DXCCSR_INJ007', 'DXCCSR_INJ008', 'DXCCSR_INJ009', 'DXCCSR_INJ010', 'DXCCSR_INJ011', 'DXCCSR_INJ012', 'DXCCSR_INJ013', 'DXCCSR_INJ014', 'DXCCSR_INJ015', 'DXCCSR_INJ016', 'DXCCSR_INJ017', 'DXCCSR_INJ018', 'DXCCSR_INJ019', 'DXCCSR_INJ020', 'DXCCSR_INJ021', 'DXCCSR_INJ022', 'DXCCSR_INJ023', 'DXCCSR_INJ024', 'DXCCSR_INJ025', 'DXCCSR_INJ026', 'DXCCSR_INJ027', 'DXCCSR_INJ028', 'DXCCSR_INJ029', 'DXCCSR_INJ030', 'DXCCSR_INJ031', 'DXCCSR_INJ032', 'DXCCSR_INJ033', 'DXCCSR_INJ034', 'DXCCSR_INJ035', 'DXCCSR_INJ036', 'DXCCSR_INJ037', 'DXCCSR_INJ038', 'DXCCSR_INJ039', 'DXCCSR_INJ040', 'DXCCSR_INJ041', 'DXCCSR_INJ042', 'DXCCSR_INJ043', 'DXCCSR_INJ044', 'DXCCSR_INJ045', 'DXCCSR_INJ046', 'DXCCSR_INJ047', 'DXCCSR_INJ048', 'DXCCSR_INJ049', 'DXCCSR_INJ050', 'DXCCSR_INJ051', 'DXCCSR_INJ052', 'DXCCSR_INJ053', 'DXCCSR_INJ054', 'DXCCSR_INJ055', 'DXCCSR_INJ056', 'DXCCSR_INJ057', 'DXCCSR_INJ058', 'DXCCSR_INJ059', 'DXCCSR_INJ060', 'DXCCSR_INJ061', 'DXCCSR_INJ062', 'DXCCSR_INJ063', 'DXCCSR_INJ064', 'DXCCSR_INJ065', 'DXCCSR_INJ066', 'DXCCSR_INJ067', 'DXCCSR_INJ068', 'DXCCSR_INJ069', 'DXCCSR_INJ070', 'DXCCSR_INJ071', 'DXCCSR_INJ072', 'DXCCSR_INJ073', 'DXCCSR_INJ074', 'DXCCSR_INJ075', 'DXCCSR_INJ076', 'DXCCSR_MAL001', 'DXCCSR_MAL002', 'DXCCSR_MAL003', 'DXCCSR_MAL004', 'DXCCSR_MAL005', 'DXCCSR_MAL006', 'DXCCSR_MAL007', 'DXCCSR_MAL008', 'DXCCSR_MAL009', 'DXCCSR_MAL010', 'DXCCSR_MBD001', 'DXCCSR_MBD002', 'DXCCSR_MBD003', 'DXCCSR_MBD004', 'DXCCSR_MBD005', 'DXCCSR_MBD006', 'DXCCSR_MBD007', 'DXCCSR_MBD008', 'DXCCSR_MBD009', 'DXCCSR_MBD010', 'DXCCSR_MBD011', 'DXCCSR_MBD012', 'DXCCSR_MBD013', 'DXCCSR_MBD014', 'DXCCSR_MBD017', 'DXCCSR_MBD018', 'DXCCSR_MBD019', 'DXCCSR_MBD020', 'DXCCSR_MBD021', 'DXCCSR_MBD022', 'DXCCSR_MBD023', 'DXCCSR_MBD024', 'DXCCSR_MBD025', 'DXCCSR_MBD026', 'DXCCSR_MBD027', 'DXCCSR_MBD028', 'DXCCSR_MBD029', 'DXCCSR_MBD030', 'DXCCSR_MBD031', 'DXCCSR_MBD032', 'DXCCSR_MBD033', 'DXCCSR_MBD034', 'DXCCSR_MUS001', 'DXCCSR_MUS002', 'DXCCSR_MUS003', 'DXCCSR_MUS004', 'DXCCSR_MUS005', 'DXCCSR_MUS006', 'DXCCSR_MUS007', 'DXCCSR_MUS008', 'DXCCSR_MUS009', 'DXCCSR_MUS010', 'DXCCSR_MUS011', 'DXCCSR_MUS012', 'DXCCSR_MUS013', 'DXCCSR_MUS014', 'DXCCSR_MUS015', 'DXCCSR_MUS016', 'DXCCSR_MUS017', 'DXCCSR_MUS018', 'DXCCSR_MUS019', 'DXCCSR_MUS020', 'DXCCSR_MUS021', 'DXCCSR_MUS022', 'DXCCSR_MUS023', 'DXCCSR_MUS024', 'DXCCSR_MUS025', 'DXCCSR_MUS026', 'DXCCSR_MUS027', 'DXCCSR_MUS028', 'DXCCSR_MUS029', 'DXCCSR_MUS030', 'DXCCSR_MUS031', 'DXCCSR_MUS032', 'DXCCSR_MUS033', 'DXCCSR_MUS034', 'DXCCSR_MUS035', 'DXCCSR_MUS036', 'DXCCSR_MUS037', 'DXCCSR_MUS038', 'DXCCSR_NEO001', 'DXCCSR_NEO002', 'DXCCSR_NEO003', 'DXCCSR_NEO004', 'DXCCSR_NEO005', 'DXCCSR_NEO006', 'DXCCSR_NEO007', 'DXCCSR_NEO008', 'DXCCSR_NEO009', 'DXCCSR_NEO010', 'DXCCSR_NEO011', 'DXCCSR_NEO012', 'DXCCSR_NEO013', 'DXCCSR_NEO014', 'DXCCSR_NEO015', 'DXCCSR_NEO016', 'DXCCSR_NEO017', 'DXCCSR_NEO018', 'DXCCSR_NEO019', 'DXCCSR_NEO020', 'DXCCSR_NEO021', 'DXCCSR_NEO022', 'DXCCSR_NEO023', 'DXCCSR_NEO024', 'DXCCSR_NEO025', 'DXCCSR_NEO026', 'DXCCSR_NEO027', 'DXCCSR_NEO028', 'DXCCSR_NEO029', 'DXCCSR_NEO030', 'DXCCSR_NEO031', 'DXCCSR_NEO032', 'DXCCSR_NEO033', 'DXCCSR_NEO034', 'DXCCSR_NEO035', 'DXCCSR_NEO036', 'DXCCSR_NEO037', 'DXCCSR_NEO038', 'DXCCSR_NEO039', 'DXCCSR_NEO040', 'DXCCSR_NEO041', 'DXCCSR_NEO042', 'DXCCSR_NEO043', 'DXCCSR_NEO044', 'DXCCSR_NEO045', 'DXCCSR_NEO046', 'DXCCSR_NEO047', 'DXCCSR_NEO048', 'DXCCSR_NEO049', 'DXCCSR_NEO050', 'DXCCSR_NEO051', 'DXCCSR_NEO052', 'DXCCSR_NEO053', 'DXCCSR_NEO054', 'DXCCSR_NEO055', 'DXCCSR_NEO056', 'DXCCSR_NEO057', 'DXCCSR_NEO058', 'DXCCSR_NEO059', 'DXCCSR_NEO060', 'DXCCSR_NEO061', 'DXCCSR_NEO062', 'DXCCSR_NEO063', 'DXCCSR_NEO064', 'DXCCSR_NEO065', 'DXCCSR_NEO066', 'DXCCSR_NEO067', 'DXCCSR_NEO068', 'DXCCSR_NEO069', 'DXCCSR_NEO070', 'DXCCSR_NEO071', 'DXCCSR_NEO072', 'DXCCSR_NEO073', 'DXCCSR_NEO074', 'DXCCSR_NVS001', 'DXCCSR_NVS002', 'DXCCSR_NVS003', 'DXCCSR_NVS004', 'DXCCSR_NVS005', 'DXCCSR_NVS006', 'DXCCSR_NVS007', 'DXCCSR_NVS008', 'DXCCSR_NVS009', 'DXCCSR_NVS010', 'DXCCSR_NVS011', 'DXCCSR_NVS012', 'DXCCSR_NVS013', 'DXCCSR_NVS014', 'DXCCSR_NVS015', 'DXCCSR_NVS016', 'DXCCSR_NVS017', 'DXCCSR_NVS018', 'DXCCSR_NVS019', 'DXCCSR_NVS020', 'DXCCSR_NVS021', 'DXCCSR_NVS022', 'DXCCSR_PNL001', 'DXCCSR_PNL002', 'DXCCSR_PNL003', 'DXCCSR_PNL004', 'DXCCSR_PNL005', 'DXCCSR_PNL006', 'DXCCSR_PNL007', 'DXCCSR_PNL008', 'DXCCSR_PNL009', 'DXCCSR_PNL010', 'DXCCSR_PNL011', 'DXCCSR_PNL012', 'DXCCSR_PNL013', 'DXCCSR_PNL014', 'DXCCSR_PNL015', 'DXCCSR_PRG001', 'DXCCSR_PRG002', 'DXCCSR_PRG003', 'DXCCSR_PRG004', 'DXCCSR_PRG005', 'DXCCSR_PRG006', 'DXCCSR_PRG007', 'DXCCSR_PRG008', 'DXCCSR_PRG009', 'DXCCSR_PRG010', 'DXCCSR_PRG011', 'DXCCSR_PRG012', 'DXCCSR_PRG013', 'DXCCSR_PRG014', 'DXCCSR_PRG015', 'DXCCSR_PRG016', 'DXCCSR_PRG017', 'DXCCSR_PRG018', 'DXCCSR_PRG019', 'DXCCSR_PRG020', 'DXCCSR_PRG021', 'DXCCSR_PRG022', 'DXCCSR_PRG023', 'DXCCSR_PRG024', 'DXCCSR_PRG025', 'DXCCSR_PRG026', 'DXCCSR_PRG027', 'DXCCSR_PRG028', 'DXCCSR_PRG029', 'DXCCSR_PRG030', 'DXCCSR_RSP001', 'DXCCSR_RSP002', 'DXCCSR_RSP003', 'DXCCSR_RSP004', 'DXCCSR_RSP005', 'DXCCSR_RSP006', 'DXCCSR_RSP007', 'DXCCSR_RSP008', 'DXCCSR_RSP009', 'DXCCSR_RSP010', 'DXCCSR_RSP011', 'DXCCSR_RSP012', 'DXCCSR_RSP013', 'DXCCSR_RSP014', 'DXCCSR_RSP015', 'DXCCSR_RSP016', 'DXCCSR_RSP017', 'DXCCSR_SKN001', 'DXCCSR_SKN002', 'DXCCSR_SKN003', 'DXCCSR_SKN004', 'DXCCSR_SKN005', 'DXCCSR_SKN006', 'DXCCSR_SKN007', 'DXCCSR_SYM001', 'DXCCSR_SYM002', 'DXCCSR_SYM003', 'DXCCSR_SYM004', 'DXCCSR_SYM005', 'DXCCSR_SYM006', 'DXCCSR_SYM007', 'DXCCSR_SYM008', 'DXCCSR_SYM009', 'DXCCSR_SYM010', 'DXCCSR_SYM011', 'DXCCSR_SYM012', 'DXCCSR_SYM013', 'DXCCSR_SYM014', 'DXCCSR_SYM015', 'DXCCSR_SYM016', 'DXCCSR_SYM017', 'DXCCSR_VERSION', 'AGEGRP', 'AGEGRP2']\n",
            "\n",
            "First 3 rows:\n",
            "   KEY_NASS  HOSP_NASS  HOSP_TEACH  HOSP_LOCATION  HOSP_LOCTEACH  HOSP_REGION  \\\n",
            "0  90000001      40053           1              1              3            4   \n",
            "1  90000002      20162           0              1              2            2   \n",
            "2  90000003      30223           1              1              3            3   \n",
            "\n",
            "   HOSP_BEDSIZE_CAT    DISCWT  NASS_STRATUM  N_DISC_U  ...  DXCCSR_SYM011  \\\n",
            "0                 2  1.579073             9    321406  ...              0   \n",
            "1                 2  1.031092            49    152635  ...              0   \n",
            "2                 3  1.245274             7    837566  ...              0   \n",
            "\n",
            "   DXCCSR_SYM012  DXCCSR_SYM013  DXCCSR_SYM014  DXCCSR_SYM015  DXCCSR_SYM016  \\\n",
            "0              0              0              0              0              0   \n",
            "1              0              0              0              0              0   \n",
            "2              0              0              0              0              0   \n",
            "\n",
            "   DXCCSR_SYM017  DXCCSR_VERSION  AGEGRP  AGEGRP2  \n",
            "0              0          2022.1    0-17     0-17  \n",
            "1              0          2022.1   18-64    40-54  \n",
            "2              0          2022.1   18-64    55-64  \n",
            "\n",
            "[3 rows x 675 columns]\n",
            "   Memory: 885.2 MB\n",
            "\n",
            "Columns: ['KEY_NASS', 'HOSP_NASS', 'HOSP_TEACH', 'HOSP_LOCATION', 'HOSP_LOCTEACH', 'HOSP_REGION', 'HOSP_BEDSIZE_CAT', 'DISCWT', 'NASS_STRATUM', 'N_DISC_U', 'N_HOSP_U', 'S_DISC_U', 'S_HOSP_U', 'TOTAL_AS_ENCOUNTERS', 'YEAR', 'AGE', 'FEMALE', 'PL_NCHS', 'ZIPINC_QRTL', 'AMONTH', 'AWEEKEND', 'DQTR', 'PAY1', 'DISPUNIFORM', 'TOTCHG', 'NCPT_INSCOPE', 'CPTCCS1', 'CPTCCS2', 'CPTCCS3', 'CPTCCS4', 'CPTCCS5', 'CPTCCS6', 'CPTCCS7', 'CPTCCS8', 'CPTCCS9', 'CPTCCS10', 'CPTCCS11', 'CPTCCS12', 'CPTCCS13', 'CPTCCS14', 'CPTCCS15', 'CPTCCS16', 'CPTCCS17', 'CPTCCS18', 'CPTCCS19', 'CPTCCS20', 'CPTCCS21', 'CPTCCS22', 'CPTCCS23', 'CPTCCS24', 'CPTCCS25', 'CPTCCS26', 'CPTCCS27', 'CPTCCS28', 'CPTCCS29', 'CPTCCS30', 'CPT1', 'CPT2', 'CPT3', 'CPT4', 'CPT5', 'CPT6', 'CPT7', 'CPT8', 'CPT9', 'CPT10', 'CPT11', 'CPT12', 'CPT13', 'CPT14', 'CPT15', 'CPT16', 'CPT17', 'CPT18', 'CPT19', 'CPT20', 'CPT21', 'CPT22', 'CPT23', 'CPT24', 'CPT25', 'CPT26', 'CPT27', 'CPT28', 'CPT29', 'CPT30', 'I10_NDX', 'I10_DX1', 'I10_DX2', 'I10_DX3', 'I10_DX4', 'I10_DX5', 'I10_DX6', 'I10_DX7', 'I10_DX8', 'I10_DX9', 'I10_DX10', 'I10_DX11', 'I10_DX12', 'I10_DX13', 'I10_DX14', 'I10_DX15', 'I10_DX16', 'I10_DX17', 'I10_DX18', 'I10_DX19', 'I10_DX20', 'RACE', 'I10_INJURY', 'I10_MULTINJURY', 'CMR_AIDS', 'CMR_ALCOHOL', 'CMR_AUTOIMMUNE', 'CMR_CANCER_LYMPH', 'CMR_CANCER_LEUK', 'CMR_CANCER_METS', 'CMR_CANCER_NSITU', 'CMR_CANCER_SOLID', 'CMR_DEMENTIA', 'CMR_DEPRESS', 'CMR_DIAB_UNCX', 'CMR_DIAB_CX', 'CMR_DRUG_ABUSE', 'CMR_HTN_CX', 'CMR_HTN_UNCX', 'CMR_LUNG_CHRONIC', 'CMR_OBESE', 'CMR_PERIVASC', 'CMR_THYROID_HYPO', 'CMR_THYROID_OTH', 'CMR_VERSION', 'DXCCSR_Default_DX1', 'DXCCSR_BLD001', 'DXCCSR_BLD002', 'DXCCSR_BLD003', 'DXCCSR_BLD004', 'DXCCSR_BLD005', 'DXCCSR_BLD006', 'DXCCSR_BLD007', 'DXCCSR_BLD008', 'DXCCSR_BLD009', 'DXCCSR_BLD010', 'DXCCSR_CIR001', 'DXCCSR_CIR002', 'DXCCSR_CIR003', 'DXCCSR_CIR004', 'DXCCSR_CIR005', 'DXCCSR_CIR006', 'DXCCSR_CIR007', 'DXCCSR_CIR008', 'DXCCSR_CIR009', 'DXCCSR_CIR010', 'DXCCSR_CIR011', 'DXCCSR_CIR012', 'DXCCSR_CIR013', 'DXCCSR_CIR014', 'DXCCSR_CIR015', 'DXCCSR_CIR016', 'DXCCSR_CIR017', 'DXCCSR_CIR018', 'DXCCSR_CIR019', 'DXCCSR_CIR020', 'DXCCSR_CIR021', 'DXCCSR_CIR022', 'DXCCSR_CIR023', 'DXCCSR_CIR024', 'DXCCSR_CIR025', 'DXCCSR_CIR026', 'DXCCSR_CIR027', 'DXCCSR_CIR028', 'DXCCSR_CIR029', 'DXCCSR_CIR030', 'DXCCSR_CIR031', 'DXCCSR_CIR032', 'DXCCSR_CIR033', 'DXCCSR_CIR034', 'DXCCSR_CIR035', 'DXCCSR_CIR036', 'DXCCSR_CIR037', 'DXCCSR_CIR038', 'DXCCSR_CIR039', 'DXCCSR_DIG001', 'DXCCSR_DIG002', 'DXCCSR_DIG003', 'DXCCSR_DIG004', 'DXCCSR_DIG005', 'DXCCSR_DIG006', 'DXCCSR_DIG007', 'DXCCSR_DIG008', 'DXCCSR_DIG009', 'DXCCSR_DIG010', 'DXCCSR_DIG011', 'DXCCSR_DIG012', 'DXCCSR_DIG013', 'DXCCSR_DIG014', 'DXCCSR_DIG015', 'DXCCSR_DIG016', 'DXCCSR_DIG017', 'DXCCSR_DIG018', 'DXCCSR_DIG019', 'DXCCSR_DIG020', 'DXCCSR_DIG021', 'DXCCSR_DIG022', 'DXCCSR_DIG023', 'DXCCSR_DIG024', 'DXCCSR_DIG025', 'DXCCSR_EAR001', 'DXCCSR_EAR002', 'DXCCSR_EAR003', 'DXCCSR_EAR004', 'DXCCSR_EAR005', 'DXCCSR_EAR006', 'DXCCSR_END001', 'DXCCSR_END002', 'DXCCSR_END003', 'DXCCSR_END004', 'DXCCSR_END005', 'DXCCSR_END006', 'DXCCSR_END007', 'DXCCSR_END008', 'DXCCSR_END009', 'DXCCSR_END010', 'DXCCSR_END011', 'DXCCSR_END012', 'DXCCSR_END013', 'DXCCSR_END014', 'DXCCSR_END015', 'DXCCSR_END016', 'DXCCSR_END017', 'DXCCSR_EXT001', 'DXCCSR_EXT002', 'DXCCSR_EXT003', 'DXCCSR_EXT004', 'DXCCSR_EXT005', 'DXCCSR_EXT006', 'DXCCSR_EXT007', 'DXCCSR_EXT008', 'DXCCSR_EXT009', 'DXCCSR_EXT010', 'DXCCSR_EXT011', 'DXCCSR_EXT012', 'DXCCSR_EXT013', 'DXCCSR_EXT014', 'DXCCSR_EXT015', 'DXCCSR_EXT016', 'DXCCSR_EXT017', 'DXCCSR_EXT018', 'DXCCSR_EXT019', 'DXCCSR_EXT020', 'DXCCSR_EXT021', 'DXCCSR_EXT022', 'DXCCSR_EXT023', 'DXCCSR_EXT024', 'DXCCSR_EXT025', 'DXCCSR_EXT026', 'DXCCSR_EXT027', 'DXCCSR_EXT028', 'DXCCSR_EXT029', 'DXCCSR_EXT030', 'DXCCSR_EYE001', 'DXCCSR_EYE002', 'DXCCSR_EYE003', 'DXCCSR_EYE004', 'DXCCSR_EYE005', 'DXCCSR_EYE006', 'DXCCSR_EYE007', 'DXCCSR_EYE008', 'DXCCSR_EYE009', 'DXCCSR_EYE010', 'DXCCSR_EYE011', 'DXCCSR_EYE012', 'DXCCSR_FAC001', 'DXCCSR_FAC002', 'DXCCSR_FAC003', 'DXCCSR_FAC004', 'DXCCSR_FAC005', 'DXCCSR_FAC006', 'DXCCSR_FAC007', 'DXCCSR_FAC008', 'DXCCSR_FAC009', 'DXCCSR_FAC010', 'DXCCSR_FAC011', 'DXCCSR_FAC012', 'DXCCSR_FAC013', 'DXCCSR_FAC014', 'DXCCSR_FAC015', 'DXCCSR_FAC016', 'DXCCSR_FAC017', 'DXCCSR_FAC018', 'DXCCSR_FAC019', 'DXCCSR_FAC020', 'DXCCSR_FAC021', 'DXCCSR_FAC022', 'DXCCSR_FAC023', 'DXCCSR_FAC024', 'DXCCSR_FAC025', 'DXCCSR_GEN001', 'DXCCSR_GEN002', 'DXCCSR_GEN003', 'DXCCSR_GEN004', 'DXCCSR_GEN005', 'DXCCSR_GEN006', 'DXCCSR_GEN007', 'DXCCSR_GEN008', 'DXCCSR_GEN009', 'DXCCSR_GEN010', 'DXCCSR_GEN011', 'DXCCSR_GEN012', 'DXCCSR_GEN013', 'DXCCSR_GEN014', 'DXCCSR_GEN015', 'DXCCSR_GEN016', 'DXCCSR_GEN017', 'DXCCSR_GEN018', 'DXCCSR_GEN019', 'DXCCSR_GEN020', 'DXCCSR_GEN021', 'DXCCSR_GEN022', 'DXCCSR_GEN023', 'DXCCSR_GEN024', 'DXCCSR_GEN025', 'DXCCSR_GEN026', 'DXCCSR_INF001', 'DXCCSR_INF002', 'DXCCSR_INF003', 'DXCCSR_INF004', 'DXCCSR_INF005', 'DXCCSR_INF006', 'DXCCSR_INF007', 'DXCCSR_INF008', 'DXCCSR_INF009', 'DXCCSR_INF010', 'DXCCSR_INF011', 'DXCCSR_INF012', 'DXCCSR_INJ001', 'DXCCSR_INJ002', 'DXCCSR_INJ003', 'DXCCSR_INJ004', 'DXCCSR_INJ005', 'DXCCSR_INJ006', 'DXCCSR_INJ007', 'DXCCSR_INJ008', 'DXCCSR_INJ009', 'DXCCSR_INJ010', 'DXCCSR_INJ011', 'DXCCSR_INJ012', 'DXCCSR_INJ013', 'DXCCSR_INJ014', 'DXCCSR_INJ015', 'DXCCSR_INJ016', 'DXCCSR_INJ017', 'DXCCSR_INJ018', 'DXCCSR_INJ019', 'DXCCSR_INJ020', 'DXCCSR_INJ021', 'DXCCSR_INJ022', 'DXCCSR_INJ023', 'DXCCSR_INJ024', 'DXCCSR_INJ025', 'DXCCSR_INJ026', 'DXCCSR_INJ027', 'DXCCSR_INJ028', 'DXCCSR_INJ029', 'DXCCSR_INJ030', 'DXCCSR_INJ031', 'DXCCSR_INJ032', 'DXCCSR_INJ033', 'DXCCSR_INJ034', 'DXCCSR_INJ035', 'DXCCSR_INJ036', 'DXCCSR_INJ037', 'DXCCSR_INJ038', 'DXCCSR_INJ039', 'DXCCSR_INJ040', 'DXCCSR_INJ041', 'DXCCSR_INJ042', 'DXCCSR_INJ043', 'DXCCSR_INJ044', 'DXCCSR_INJ045', 'DXCCSR_INJ046', 'DXCCSR_INJ047', 'DXCCSR_INJ048', 'DXCCSR_INJ049', 'DXCCSR_INJ050', 'DXCCSR_INJ051', 'DXCCSR_INJ052', 'DXCCSR_INJ053', 'DXCCSR_INJ054', 'DXCCSR_INJ055', 'DXCCSR_INJ056', 'DXCCSR_INJ057', 'DXCCSR_INJ058', 'DXCCSR_INJ059', 'DXCCSR_INJ060', 'DXCCSR_INJ061', 'DXCCSR_INJ062', 'DXCCSR_INJ063', 'DXCCSR_INJ064', 'DXCCSR_INJ065', 'DXCCSR_INJ066', 'DXCCSR_INJ067', 'DXCCSR_INJ068', 'DXCCSR_INJ069', 'DXCCSR_INJ070', 'DXCCSR_INJ071', 'DXCCSR_INJ072', 'DXCCSR_INJ073', 'DXCCSR_INJ074', 'DXCCSR_INJ075', 'DXCCSR_INJ076', 'DXCCSR_MAL001', 'DXCCSR_MAL002', 'DXCCSR_MAL003', 'DXCCSR_MAL004', 'DXCCSR_MAL005', 'DXCCSR_MAL006', 'DXCCSR_MAL007', 'DXCCSR_MAL008', 'DXCCSR_MAL009', 'DXCCSR_MAL010', 'DXCCSR_MBD001', 'DXCCSR_MBD002', 'DXCCSR_MBD003', 'DXCCSR_MBD004', 'DXCCSR_MBD005', 'DXCCSR_MBD006', 'DXCCSR_MBD007', 'DXCCSR_MBD008', 'DXCCSR_MBD009', 'DXCCSR_MBD010', 'DXCCSR_MBD011', 'DXCCSR_MBD012', 'DXCCSR_MBD013', 'DXCCSR_MBD014', 'DXCCSR_MBD017', 'DXCCSR_MBD018', 'DXCCSR_MBD019', 'DXCCSR_MBD020', 'DXCCSR_MBD021', 'DXCCSR_MBD022', 'DXCCSR_MBD023', 'DXCCSR_MBD024', 'DXCCSR_MBD025', 'DXCCSR_MBD026', 'DXCCSR_MBD027', 'DXCCSR_MBD028', 'DXCCSR_MBD029', 'DXCCSR_MBD030', 'DXCCSR_MBD031', 'DXCCSR_MBD032', 'DXCCSR_MBD033', 'DXCCSR_MBD034', 'DXCCSR_MUS001', 'DXCCSR_MUS002', 'DXCCSR_MUS003', 'DXCCSR_MUS004', 'DXCCSR_MUS005', 'DXCCSR_MUS006', 'DXCCSR_MUS007', 'DXCCSR_MUS008', 'DXCCSR_MUS009', 'DXCCSR_MUS010', 'DXCCSR_MUS011', 'DXCCSR_MUS012', 'DXCCSR_MUS013', 'DXCCSR_MUS014', 'DXCCSR_MUS015', 'DXCCSR_MUS016', 'DXCCSR_MUS017', 'DXCCSR_MUS018', 'DXCCSR_MUS019', 'DXCCSR_MUS020', 'DXCCSR_MUS021', 'DXCCSR_MUS022', 'DXCCSR_MUS023', 'DXCCSR_MUS024', 'DXCCSR_MUS025', 'DXCCSR_MUS026', 'DXCCSR_MUS027', 'DXCCSR_MUS028', 'DXCCSR_MUS029', 'DXCCSR_MUS030', 'DXCCSR_MUS031', 'DXCCSR_MUS032', 'DXCCSR_MUS033', 'DXCCSR_MUS034', 'DXCCSR_MUS035', 'DXCCSR_MUS036', 'DXCCSR_MUS037', 'DXCCSR_MUS038', 'DXCCSR_NEO001', 'DXCCSR_NEO002', 'DXCCSR_NEO003', 'DXCCSR_NEO004', 'DXCCSR_NEO005', 'DXCCSR_NEO006', 'DXCCSR_NEO007', 'DXCCSR_NEO008', 'DXCCSR_NEO009', 'DXCCSR_NEO010', 'DXCCSR_NEO011', 'DXCCSR_NEO012', 'DXCCSR_NEO013', 'DXCCSR_NEO014', 'DXCCSR_NEO015', 'DXCCSR_NEO016', 'DXCCSR_NEO017', 'DXCCSR_NEO018', 'DXCCSR_NEO019', 'DXCCSR_NEO020', 'DXCCSR_NEO021', 'DXCCSR_NEO022', 'DXCCSR_NEO023', 'DXCCSR_NEO024', 'DXCCSR_NEO025', 'DXCCSR_NEO026', 'DXCCSR_NEO027', 'DXCCSR_NEO028', 'DXCCSR_NEO029', 'DXCCSR_NEO030', 'DXCCSR_NEO031', 'DXCCSR_NEO032', 'DXCCSR_NEO033', 'DXCCSR_NEO034', 'DXCCSR_NEO035', 'DXCCSR_NEO036', 'DXCCSR_NEO037', 'DXCCSR_NEO038', 'DXCCSR_NEO039', 'DXCCSR_NEO040', 'DXCCSR_NEO041', 'DXCCSR_NEO042', 'DXCCSR_NEO043', 'DXCCSR_NEO044', 'DXCCSR_NEO045', 'DXCCSR_NEO046', 'DXCCSR_NEO047', 'DXCCSR_NEO048', 'DXCCSR_NEO049', 'DXCCSR_NEO050', 'DXCCSR_NEO051', 'DXCCSR_NEO052', 'DXCCSR_NEO053', 'DXCCSR_NEO054', 'DXCCSR_NEO055', 'DXCCSR_NEO056', 'DXCCSR_NEO057', 'DXCCSR_NEO058', 'DXCCSR_NEO059', 'DXCCSR_NEO060', 'DXCCSR_NEO061', 'DXCCSR_NEO062', 'DXCCSR_NEO063', 'DXCCSR_NEO064', 'DXCCSR_NEO065', 'DXCCSR_NEO066', 'DXCCSR_NEO067', 'DXCCSR_NEO068', 'DXCCSR_NEO069', 'DXCCSR_NEO070', 'DXCCSR_NEO071', 'DXCCSR_NEO072', 'DXCCSR_NEO073', 'DXCCSR_NEO074', 'DXCCSR_NVS001', 'DXCCSR_NVS002', 'DXCCSR_NVS003', 'DXCCSR_NVS004', 'DXCCSR_NVS005', 'DXCCSR_NVS006', 'DXCCSR_NVS007', 'DXCCSR_NVS008', 'DXCCSR_NVS009', 'DXCCSR_NVS010', 'DXCCSR_NVS011', 'DXCCSR_NVS012', 'DXCCSR_NVS013', 'DXCCSR_NVS014', 'DXCCSR_NVS015', 'DXCCSR_NVS016', 'DXCCSR_NVS017', 'DXCCSR_NVS018', 'DXCCSR_NVS019', 'DXCCSR_NVS020', 'DXCCSR_NVS021', 'DXCCSR_NVS022', 'DXCCSR_PNL001', 'DXCCSR_PNL002', 'DXCCSR_PNL003', 'DXCCSR_PNL004', 'DXCCSR_PNL005', 'DXCCSR_PNL006', 'DXCCSR_PNL007', 'DXCCSR_PNL008', 'DXCCSR_PNL009', 'DXCCSR_PNL010', 'DXCCSR_PNL011', 'DXCCSR_PNL012', 'DXCCSR_PNL013', 'DXCCSR_PNL014', 'DXCCSR_PNL015', 'DXCCSR_PRG001', 'DXCCSR_PRG002', 'DXCCSR_PRG003', 'DXCCSR_PRG004', 'DXCCSR_PRG005', 'DXCCSR_PRG006', 'DXCCSR_PRG007', 'DXCCSR_PRG008', 'DXCCSR_PRG009', 'DXCCSR_PRG010', 'DXCCSR_PRG011', 'DXCCSR_PRG012', 'DXCCSR_PRG013', 'DXCCSR_PRG014', 'DXCCSR_PRG015', 'DXCCSR_PRG016', 'DXCCSR_PRG017', 'DXCCSR_PRG018', 'DXCCSR_PRG019', 'DXCCSR_PRG020', 'DXCCSR_PRG021', 'DXCCSR_PRG022', 'DXCCSR_PRG023', 'DXCCSR_PRG024', 'DXCCSR_PRG025', 'DXCCSR_PRG026', 'DXCCSR_PRG027', 'DXCCSR_PRG028', 'DXCCSR_PRG029', 'DXCCSR_PRG030', 'DXCCSR_RSP001', 'DXCCSR_RSP002', 'DXCCSR_RSP003', 'DXCCSR_RSP004', 'DXCCSR_RSP005', 'DXCCSR_RSP006', 'DXCCSR_RSP007', 'DXCCSR_RSP008', 'DXCCSR_RSP009', 'DXCCSR_RSP010', 'DXCCSR_RSP011', 'DXCCSR_RSP012', 'DXCCSR_RSP013', 'DXCCSR_RSP014', 'DXCCSR_RSP015', 'DXCCSR_RSP016', 'DXCCSR_RSP017', 'DXCCSR_SKN001', 'DXCCSR_SKN002', 'DXCCSR_SKN003', 'DXCCSR_SKN004', 'DXCCSR_SKN005', 'DXCCSR_SKN006', 'DXCCSR_SKN007', 'DXCCSR_SYM001', 'DXCCSR_SYM002', 'DXCCSR_SYM003', 'DXCCSR_SYM004', 'DXCCSR_SYM005', 'DXCCSR_SYM006', 'DXCCSR_SYM007', 'DXCCSR_SYM008', 'DXCCSR_SYM009', 'DXCCSR_SYM010', 'DXCCSR_SYM011', 'DXCCSR_SYM012', 'DXCCSR_SYM013', 'DXCCSR_SYM014', 'DXCCSR_SYM015', 'DXCCSR_SYM016', 'DXCCSR_SYM017', 'DXCCSR_VERSION', 'AGEGRP', 'AGEGRP2']\n",
            "\n",
            "First 3 rows:\n",
            "   KEY_NASS  HOSP_NASS  HOSP_TEACH  HOSP_LOCATION  HOSP_LOCTEACH  HOSP_REGION  \\\n",
            "0  90000001      40053           1              1              3            4   \n",
            "1  90000002      20162           0              1              2            2   \n",
            "2  90000003      30223           1              1              3            3   \n",
            "\n",
            "   HOSP_BEDSIZE_CAT    DISCWT  NASS_STRATUM  N_DISC_U  ...  DXCCSR_SYM011  \\\n",
            "0                 2  1.579073             9    321406  ...              0   \n",
            "1                 2  1.031092            49    152635  ...              0   \n",
            "2                 3  1.245274             7    837566  ...              0   \n",
            "\n",
            "   DXCCSR_SYM012  DXCCSR_SYM013  DXCCSR_SYM014  DXCCSR_SYM015  DXCCSR_SYM016  \\\n",
            "0              0              0              0              0              0   \n",
            "1              0              0              0              0              0   \n",
            "2              0              0              0              0              0   \n",
            "\n",
            "   DXCCSR_SYM017  DXCCSR_VERSION  AGEGRP  AGEGRP2  \n",
            "0              0          2022.1    0-17     0-17  \n",
            "1              0          2022.1   18-64    40-54  \n",
            "2              0          2022.1   18-64    55-64  \n",
            "\n",
            "[3 rows x 675 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "class DataLoader:\n",
        "    def __init__(self):\n",
        "        self.base_path = Path('/content') if env_manager.is_colab else Path.home()\n",
        "        self.data_dir = self.base_path / 'data'\n",
        "        self.data_dir.mkdir(exist_ok=True)\n",
        "    \n",
        "    def load_data(self):\n",
        "        \"\"\"Load data based on configuration\"\"\"\n",
        "        loaders = {\n",
        "            'github': self._load_github,\n",
        "            'local': self._load_local,\n",
        "            'gcs': self._load_gcs,\n",
        "            'drive': self._load_drive\n",
        "        }\n",
        "        \n",
        "        if DATA_SOURCE not in loaders:\n",
        "            raise ValueError(f\"Invalid DATA_SOURCE: {DATA_SOURCE}\")\n",
        "        \n",
        "        print(f\"Loading data from: {DATA_SOURCE.upper()}\")\n",
        "        return loaders[DATA_SOURCE]()\n",
        "    \n",
        "    def _load_github(self):\n",
        "        \"\"\"Load from GitHub releases\"\"\"\n",
        "        response = requests.get(GITHUB_URL, timeout=60)\n",
        "        response.raise_for_status()\n",
        "        \n",
        "        data_path = self.data_dir / \"nass_data.csv\"\n",
        "        data_path.write_bytes(response.content)\n",
        "        \n",
        "        print(f\"‚úì Downloaded from GitHub ({response.headers.get('content-length', 'unknown')} bytes)\")\n",
        "        return pd.read_csv(data_path)\n",
        "    \n",
        "    def _load_local(self):\n",
        "        \"\"\"Load from local file\"\"\"\n",
        "        search_paths = [\n",
        "            self.base_path / LOCAL_FILENAME,\n",
        "            self.data_dir / LOCAL_FILENAME,\n",
        "            Path.cwd() / LOCAL_FILENAME\n",
        "        ]\n",
        "        \n",
        "        for path in search_paths:\n",
        "            if path.exists():\n",
        "                print(f\"‚úì Found local file: {path}\")\n",
        "                return pd.read_csv(path)\n",
        "        \n",
        "        raise FileNotFoundError(f\"File not found in: {[str(p) for p in search_paths]}\")\n",
        "    \n",
        "    def _load_gcs(self):\n",
        "        \"\"\"Load from Google Cloud Storage\"\"\"\n",
        "        from google.cloud import storage\n",
        "        \n",
        "        # Smart authentication\n",
        "        if Path(GCS_SERVICE_ACCOUNT_KEY).exists():\n",
        "            client = storage.Client.from_service_account_json(GCS_SERVICE_ACCOUNT_KEY)\n",
        "        else:\n",
        "            client = storage.Client()  # Use default credentials\n",
        "        \n",
        "        bucket = client.bucket(GCS_BUCKET)\n",
        "        blob = bucket.blob(GCS_BLOB)\n",
        "        \n",
        "        data_path = self.data_dir / \"nass_data.csv\"\n",
        "        blob.download_to_filename(data_path)\n",
        "        \n",
        "        print(f\"‚úì Downloaded from GCS: {GCS_BUCKET}/{GCS_BLOB}\")\n",
        "        return pd.read_csv(data_path)\n",
        "    \n",
        "    def _load_drive(self):\n",
        "        \"\"\"Load from Google Drive (Colab only)\"\"\"\n",
        "        if not env_manager.is_colab:\n",
        "            raise RuntimeError(\"Drive loading only available in Google Colab\")\n",
        "        \n",
        "        drive_path = Path(DRIVE_PATH)\n",
        "        if not drive_path.exists():\n",
        "            raise FileNotFoundError(f\"Drive file not found: {DRIVE_PATH}\")\n",
        "        \n",
        "        print(f\"‚úì Loading from Google Drive: {DRIVE_PATH}\")\n",
        "        return pd.read_csv(drive_path)\n",
        "\n",
        "# Load data\n",
        "try:\n",
        "    loader = DataLoader()\n",
        "    df = loader.load_data()\n",
        "    \n",
        "    print(f\"‚úÖ Data loaded successfully!\")\n",
        "    print(f\"   Shape: {df.shape}\")\n",
        "    print(f\"   Memory: {df.memory_usage(deep=True).sum() / 1e6:.1f} MB\")\n",
        "    \n",
        "    if VERBOSE_PRINTS:\n",
        "        print(f\"\\nColumns: {list(df.columns)}\")\n",
        "        print(f\"\\nFirst 3 rows:\")\n",
        "        print(df.head(3))\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Data loading failed: {e}\")\n",
        "    print(f\"üí° Try changing DATA_SOURCE or check file paths\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 4. R Environment Setup\n",
        "\n",
        "Load R integration and install R packages efficiently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Error importing in API mode: ImportError('On Windows, cffi mode \"ANY\" is only \"ABI\".')\n",
            "Trying to import in ABI mode.\n",
            "Trying to import in ABI mode.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì R integration loaded\n"
          ]
        }
      ],
      "source": [
        "# Load rpy2 extension for R integration\n",
        "try:\n",
        "    %load_ext rpy2.ipython\n",
        "    print(\"‚úì R integration loaded\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Failed to load R integration: {e}\")\n",
        "    print(\"Install rpy2: pip install rpy2\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%R -i VERBOSE_PRINTS\n",
        "\n",
        "# Smart R package installation\n",
        "required_packages <- c(\"data.table\", \"survey\", \"dplyr\", \"tidyverse\", \n",
        "                      \"tidycensus\", \"ggplot2\", \"gridExtra\", \"pROC\", \n",
        "                      \"broom\", \"lme4\")\n",
        "\n",
        "# Check what's already installed\n",
        "installed_packages <- rownames(installed.packages())\n",
        "missing_packages <- required_packages[!required_packages %in% installed_packages]\n",
        "\n",
        "# Install missing packages\n",
        "if(length(missing_packages) > 0) {\n",
        "  cat(\"Installing R packages:\", paste(missing_packages, collapse=\", \"), \"\\n\")\n",
        "  install.packages(missing_packages, repos=\"https://cloud.r-project.org\", \n",
        "                   quiet=!VERBOSE_PRINTS, dependencies=TRUE)\n",
        "}\n",
        "\n",
        "# Load all packages\n",
        "success <- sapply(required_packages, function(pkg) {\n",
        "  suppressMessages(suppressWarnings(library(pkg, character.only=TRUE, quietly=TRUE)))\n",
        "})\n",
        "\n",
        "cat(\"‚úì R packages loaded:\", sum(success), \"/\", length(required_packages), \"\\n\")\n",
        "if(any(!success)) {\n",
        "  cat(\"‚ö†Ô∏è  Failed to load:\", paste(names(success)[!success], collapse=\", \"), \"\\n\")\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10dad708"
      },
      "outputs": [],
      "source": [
        "%%R -i df -i VERBOSE_PRINTS\n",
        "options(datatable.print.nrows = 10)\n",
        "\n",
        "NASS <- as.data.table(df)\n",
        "if (VERBOSE_PRINTS) print(NASS[1:10])\n",
        "\n",
        "# Light type coercion\n",
        "num_cols  <- c(\"AGE\",\"DISCWT\",\"TOTCHG\",\"TOTAL_AS_ENCOUNTERS\")\n",
        "NASS[, (num_cols) := lapply(.SD, as.numeric), .SDcols = num_cols]\n",
        "\n",
        "# Boolean helper\n",
        "NASS[, WHITE := fifelse(RACE == 1, 1, 0)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7341f8ab"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "cat(\"Rows:\", nrow(NASS), \"  Cols:\", ncol(NASS), \"\\n\")\n",
        "top10 <- NASS[, .N, by = CPTCCS1][order(-N)][1:10]\n",
        "knitr::kable(top10, caption = \"Top 10 CPTCCS1 counts (simulated)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43230586"
      },
      "source": [
        "---\n",
        "## 9. R Analysis - Income Quartile vs Procedure\n",
        "\n",
        "Visualize income distribution within the most common procedures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ee3556ca"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "top_codes <- top10$CPTCCS1\n",
        "plt_income <- NASS[CPTCCS1 %in% top_codes] |>\n",
        "  ggplot(aes(x = fct_infreq(CPTCCS1), fill = ZIPINC_QRTL)) +\n",
        "  geom_bar(position = \"fill\") +\n",
        "  scale_y_continuous(labels = scales::percent) +\n",
        "  coord_flip() +\n",
        "  labs(y = \"Share within CPT\", x = \"CPTCCS1\", fill = \"ZIP Quartile\",\n",
        "       title = \"Income distribution within 10 most-common procedures\")\n",
        "print(plt_income)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20a6a8a8"
      },
      "source": [
        "---\n",
        "## 10. Census API Setup\n",
        "\n",
        "Set up environment variable for Census API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6d0c69b9"
      },
      "outputs": [],
      "source": [
        "import getpass, os, json, textwrap\n",
        "os.environ[\"CENSUS_API_KEY\"] = getpass.getpass(\"Enter your Census API key (will not echo):\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c39ad38"
      },
      "source": [
        "---\n",
        "## 11. R | Set Census Key & Pull 2020 DHC Totals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "240fd569"
      },
      "outputs": [],
      "source": [
        "%%R -i states_in_nass=character() -i VERBOSE_PRINTS\n",
        "# If you've already installed the key once, this is a no-op\n",
        "tidycensus::census_api_key(Sys.getenv(\"CENSUS_API_KEY\"), overwrite = FALSE, install = FALSE)\n",
        "\n",
        "get_vars <- function(base) sprintf(\"%s_%03dN\", base, 1:49)\n",
        "\n",
        "vars_total <- get_vars(\"P12\")\n",
        "vars_white <- get_vars(\"P12I\")\n",
        "\n",
        "pull_state_totals <- function(vars){\n",
        "  get_decennial(geography = \"state\",\n",
        "                variables = vars,\n",
        "                year = 2020, sumfile = \"dhc\") |>\n",
        "  group_by(NAME) |> summarise(total = sum(value))\n",
        "}\n",
        "\n",
        "total_pop  <- pull_state_totals(vars_total)\n",
        "white_pop  <- pull_state_totals(vars_white)\n",
        "\n",
        "census_prop <- merge(total_pop, white_pop, by = \"NAME\",\n",
        "                     suffixes = c(\"_all\",\"_white\"))\n",
        "census_prop[, prop_white := total_white / total_all]\n",
        "\n",
        "if (VERBOSE_PRINTS) head(census_prop)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6239ac5"
      },
      "source": [
        "---\n",
        "## 12. R | Weighted vs Unweighted Proportion Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9a539f9"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "library(survey)\n",
        "\n",
        "# Survey design using provided discharge weight\n",
        "des <- svydesign(ids = ~1, weights = ~DISCWT, data = NASS)\n",
        "\n",
        "unweighted_hat <- mean(NASS$WHITE)\n",
        "weighted_hat   <- svymean(~WHITE, des)[1]\n",
        "\n",
        "us_prop <- weighted.mean(census_prop$prop_white,\n",
        "                         w = census_prop$total_all)\n",
        "\n",
        "cat(sprintf(\"Unweighted NASS white %%: %.3f\\n\", unweighted_hat))\n",
        "cat(sprintf(\"Weighted   NASS white %%: %.3f\\n\", weighted_hat))\n",
        "cat(sprintf(\"2020 Census (all NASS states) white %%: %.3f\\n\", us_prop))\n",
        "\n",
        "svytest <- svyciprop(~WHITE, des,\n",
        "                     method = \"likelihood\", level = 0.95)\n",
        "print(svytest)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d30e6ec7"
      },
      "source": [
        "---\n",
        "## 13. R | Age-by-sex plot vs Census (adapted from `agesociodiv.r`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfb4756f"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "age_breaks <- c(-Inf,4,9,14,17,19,20,21,24,29,34,39,44,49,54,59,61,64,\n",
        "                66,69,74,79,84,Inf)\n",
        "age_labels <- c(\"U5\",\"5-9\",\"10-14\",\"15-17\",\"18-19\",\"20\",\"21\",\n",
        "                \"22-24\",\"25-29\",\"30-34\",\"35-39\",\"40-44\",\"45-49\",\n",
        "                \"50-54\",\"55-59\",\"60-61\",\"62-64\",\"65-66\",\"67-69\",\n",
        "                \"70-74\",\"75-79\",\"80-84\",\"85+\")\n",
        "\n",
        "NASS[, AGE_GROUP := cut(AGE, breaks = age_breaks,\n",
        "                        labels = age_labels, right = TRUE)]\n",
        "\n",
        "plot_df <- NASS[, .(white = sum(WHITE),\n",
        "                    n     = .N),\n",
        "                by = .(SEX = factor(FEMALE, labels=c(\"Male\",\"Female\")),\n",
        "                       AGE_GROUP)]\n",
        "plot_df[, prop := white/n]\n",
        "\n",
        "gg_gender <- ggplot(plot_df, aes(x = AGE_GROUP, y = prop,\n",
        "                                 group = SEX, color = SEX)) +\n",
        "  geom_line(linewidth=1) +\n",
        "  geom_point() +\n",
        "  scale_y_continuous(labels = scales::percent) +\n",
        "  labs(y = \"% White (NASS, simulated)\", x = \"Age-group\",\n",
        "       title = \"Crude white proportion by age & sex\") +\n",
        "  theme_minimal() +\n",
        "  theme(axis.text.x = element_text(angle=45, hjust=1))\n",
        "print(gg_gender)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "add395e2"
      },
      "source": [
        "---\n",
        "## 14. R | Multilevel logistic models (hospital nested, 3 tiers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8574bf3a"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "features <- NASS[, .(WHITE,\n",
        "                     FEMALE,\n",
        "                     ZIPINC_QRTL,\n",
        "                     PAY1,\n",
        "                     CPTCCS1,\n",
        "                     HOSP_LOCATION,\n",
        "                     HOSP_TEACH,\n",
        "                     HOSP_NASS)]\n",
        "\n",
        "features[, c(names(features)) := lapply(.SD, as.factor)]\n",
        "\n",
        "formulas <- list(\n",
        "  m1 = WHITE ~ FEMALE + (1|HOSP_NASS),\n",
        "  m2 = WHITE ~ FEMALE + ZIPINC_QRTL + (1|HOSP_NASS),\n",
        "  m3 = WHITE ~ FEMALE + ZIPINC_QRTL + PAY1 + CPTCCS1 +\n",
        "                    HOSP_LOCATION + HOSP_TEACH + (1|HOSP_NASS)\n",
        ")\n",
        "\n",
        "fit <- lapply(formulas, glmer, family = binomial, data = features,\n",
        "              control = glmerControl(optimizer=\"bobyqa\", optCtrl=list(maxfun=2e4)))\n",
        "\n",
        "sapply(fit, function(m) broom::tidy(m, effects = \"fixed\")[1:5,])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa999863"
      },
      "source": [
        "---\n",
        "## 15. R | Compare AUC across the three models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9781417"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "library(pROC)\n",
        "auc_vals <- sapply(fit, function(m){\n",
        "  preds <- predict(m, type=\"response\")\n",
        "  roc(features$WHITE, preds)$auc\n",
        "})\n",
        "knitr::kable(data.frame(model = names(auc_vals), AUC = auc_vals),\n",
        "             caption = \"AUC (in-sample, simulated data)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a2a8180"
      },
      "source": [
        "---\n",
        "## 16. Python | Teardown Helper (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38a0324d"
      },
      "outputs": [],
      "source": [
        "if not USE_DRIVE:\n",
        "    print(\"Done ‚úÖ ‚Äî runtime will auto-delete downloaded CSV when session ends.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMqcgUl+g+r3Kzj0zmsaBpz",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
