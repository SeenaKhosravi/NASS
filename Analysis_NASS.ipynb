{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open on GitHub](https://img.shields.io/badge/GitHub-View%20Source-181717?style=for-the-badge&logo=github)](https://github.com/SeenaKhosravi/NASS/blob/main/Analysis_NASS.ipynb)\n",
        "[![Open In Colab](https://img.shields.io/badge/Colab-Open%20Notebook-F9AB00?style=for-the-badge&logo=google-colab)](https://colab.research.google.com/github/SeenaKhosravi/NASS/blob/main/Analysis_NASS.ipynb)\n",
        "[![Open in Vertex AI](https://img.shields.io/badge/Vertex%20AI-Open%20Workbench-4285F4?style=for-the-badge&logo=google-cloud)](https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/SeenaKhosravi/NASS/main/Analysis_NASS.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbe6c3e6"
      },
      "source": [
        "# Socioeconomic and Demographic Drivers of Ambulatory Surgery Usage\n",
        "### HCUP NASS 2020 – Reproducible Pipeline (Python + R)\n",
        "\n",
        "**Author:** Seena Khosravi, MD  \n",
        "**LLMs Utilized:** Claude Sonnet 4, Opus 4; ChatGPT 4o, o4; Deepseek 3.1; Gemini 2.5 Pro  \n",
        "**Last Updated:** September 13, 2025  \n",
        "\n",
        "**Data Source:**  \n",
        "Department of Health & Human Services (HHS)  \n",
        "Agency for Healthcare Research and Quality (AHRQ)  \n",
        "Healthcare Cost and Utilization Project (HCUP)  \n",
        "National Ambulatory Surgical Sample (NASS)\n",
        "Year - 2020\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOmuZCsusrTj"
      },
      "source": [
        "## Overview\n",
        "This notebook provides a reproducible analysis pipeline for examining socioeconomic and demographic factors influencing ambulatory surgery usage patterns. The analysis combines Python for data processing and R for statistical modeling.\n",
        "\n",
        "### Data Usage Agreement\n",
        "**DUA Compliant Online Implementation** — This notebook uses a simulated, artificial, smaller dataset with identical structure to the file created by [Raw_NASS_Processing.R](https://github.com/SeenaKhosravi/NASS/blob/a7764ce80be8a82fc449831821c27d957176c410/Raw%20NASS%20%20Processing.R). The simulated dataset production methodology is found in [Generate_Simulated_NASS.R](https://github.com/SeenaKhosravi/NASS/blob/161bf2b5c149da9654c0e887655b361fa2176db0/Generate_Simulated_NASS.R). If DUA signed and data purchased from HCUP, this notebook can run on full dataset loaded from your local or cloud storage.\n",
        "\n",
        "[Please see the DUA Agreement here.](https://hcup-us.ahrq.gov/team/NationwideDUA.jsp)\n",
        "\n",
        "### Key Features\n",
        "- **Multiple Platform:** Works on jupyter implementations via local environments, server, cloud VM instance, or platform as a service.\n",
        "- **Flexible Data Storage:** GitHub (simulated, static, open access), Google Drive, Google Cloud Storage, or local file\n",
        "- **Reproducible:** All dependencies and environment setup included; assumes new, unmodified colab/vertex instances\n",
        "- **Scalable:** Handles both simulated (0.2GB, 139k rows) and full dataset (12 GB, 7.8M rows). Scalable cloud options."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "019b6fe9"
      },
      "source": [
        "---\n",
        "\n",
        "## Design Notes\n",
        "\n",
        "### Architecture\n",
        "- **Python primary, w/ R run via rpy2 python extension**\n",
        "- **Python cells** handle \"plumbing\" (file I/O, environment setup, rpy2 configuration, data previews)\n",
        "- **R cells** (prefixed by `%%R`) perform statistical analysis: survey weights, Census lookups, multilevel models, plots, classifiers, etc.\n",
        "\n",
        "### Data Sources\n",
        "- **Default:** Simulated dataset (1GB) from GitHub releases\n",
        "- **Local:** Switch to locally stored files via configuration\n",
        "- **Drive:** Google Drive (Only availble in Colab)\n",
        "- **Cloud:** Google Cloud Storage support for large datasets\n",
        "\n",
        "\n",
        "### Environment Support\n",
        "- Local (Jupyterlab w/ Python 3.11.5 kernel)\n",
        "- Jupyter Server (may require some configuring depending on your implementation)\n",
        "- Google Colab (Pro recommended, high-ram option)\n",
        "- Vertex AI Workbench (JupyterLab 3, Python 3 kernel) (used for full analysis)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvQPKX8GrfZr"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUEIOQlXrPrd"
      },
      "source": [
        "---\n",
        "## 1. Configuration\n",
        "\n",
        "Configure all settings here prior to run - data sources, debugging options, and file paths. Defaults to simulated dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUU1wwMKrPre"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Configuration loaded\n",
            "  Data source: github\n",
            "  Verbose mode: True\n"
          ]
        }
      ],
      "source": [
        "# ==================== CONFIGURATION ====================\n",
        "# Data Source Options\n",
        "DATA_SOURCE = \"github\"      # Options: \"github\", \"local\", \"gcs\", \"drive\"\n",
        "VERBOSE_PRINTS = True       # False → suppress debug output\n",
        "\n",
        "# GitHub source (default - simulated data)\n",
        "GITHUB_URL = \"https://github.com/SeenaKhosravi/NASS/releases/download/v1.0.0/nass_2020_simulated.csv\"\n",
        "\n",
        "# Local file options\n",
        "LOCAL_FILENAME = \"nass_2020_local.csv\"\n",
        "\n",
        "# Google Cloud Storage options\n",
        "GCS_BUCKET = \"nass_2020\"\n",
        "GCS_BLOB = \"nass_2020_all.csv\"\n",
        "GCS_SERVICE_ACCOUNT_KEY = \"/path/to/service-account-key.json\"  # Optional\n",
        "\n",
        "# Google Drive options (for Colab)\n",
        "DRIVE_PATH = \"/content/drive/MyDrive/NASS/nass_2020_full.csv\"\n",
        "# ======================================================\n",
        "\n",
        "print(\"✓ Configuration loaded\")\n",
        "print(f\"  Data source: {DATA_SOURCE}\")\n",
        "print(f\"  Verbose mode: {VERBOSE_PRINTS}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WJ8_5sRrPre"
      },
      "source": [
        "---\n",
        "## 2. Environment Setup & Package Installation\n",
        "\n",
        "Detect environment and install Python packages via Conda if available, with fallbacks. If in Google Colab, mount Google Drive.\n",
        "\n",
        "**Note:** If running in Vertex AI Workbench for the first time, you need additional R setup prior to loading rpy2. Please skip the following cell and return after completing the subsequent cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "x9RcJjrWrPrf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment detected: Local/Jupyter\n",
            "Installing and checking packages...\n",
            "All packages ready\n",
            "All packages ready\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "class EnvironmentManager:\n",
        "    def __init__(self):\n",
        "        self.detect_environment()\n",
        "        self.setup_packages()\n",
        "\n",
        "    def detect_environment(self):\n",
        "        \"\"\"Detect runtime environment\"\"\"\n",
        "        self.is_colab = 'COLAB_GPU' in os.environ or 'google.colab' in sys.modules\n",
        "        self.is_vertex = 'DL_ANACONDA_HOME' in os.environ\n",
        "\n",
        "        if self.is_colab:\n",
        "            self.env_type = \"Google Colab\"\n",
        "        elif self.is_vertex:\n",
        "            self.env_type = \"Vertex AI\"\n",
        "        else:\n",
        "            self.env_type = \"Local/Jupyter\"\n",
        "\n",
        "        print(f\"Environment detected: {self.env_type}\")\n",
        "\n",
        "    def check_conda_available(self):\n",
        "        \"\"\"Check if conda is available\"\"\"\n",
        "        try:\n",
        "            subprocess.check_call(['conda', '--version'],\n",
        "                                stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "            return True\n",
        "        except (subprocess.CalledProcessError, FileNotFoundError):\n",
        "            return False\n",
        "\n",
        "    def install_package(self, package, conda_name=None):\n",
        "        \"\"\"Smart package installation with fallback\"\"\"\n",
        "        try:\n",
        "            __import__(package)\n",
        "            return True\n",
        "        except ImportError:\n",
        "            print(f\"Installing {package}...\")\n",
        "\n",
        "            # Try conda first if available and not in Colab\n",
        "            if conda_name and not self.is_colab and self.check_conda_available():\n",
        "                try:\n",
        "                    subprocess.check_call(['conda', 'install', '-y', conda_name],\n",
        "                                        stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "                    return True\n",
        "                except subprocess.CalledProcessError:\n",
        "                    print(f\"  Conda install failed for {conda_name}, trying pip...\")\n",
        "\n",
        "            # Fallback to pip\n",
        "            try:\n",
        "                subprocess.check_call([sys.executable, '-m', 'pip', 'install', package],\n",
        "                                    stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "                return True\n",
        "            except subprocess.CalledProcessError as e:\n",
        "                print(f\"  Pip install failed for {package}: {e}\")\n",
        "                return False\n",
        "\n",
        "    def setup_packages(self):\n",
        "        \"\"\"Install required packages efficiently\"\"\"\n",
        "        packages = {\n",
        "            'pandas': 'pandas',\n",
        "            'requests': 'requests',\n",
        "            'rpy2': 'rpy2',\n",
        "            'google.cloud.storage': 'google-cloud-storage'\n",
        "        }\n",
        "\n",
        "        print(\"Installing and checking packages...\")\n",
        "        failed = []\n",
        "\n",
        "        for pkg, install_name in packages.items():\n",
        "            if not self.install_package(pkg, install_name):\n",
        "                failed.append(pkg)\n",
        "\n",
        "        # Store failed packages globally for recovery\n",
        "        globals()['failed_packages'] = failed\n",
        "\n",
        "        if failed:\n",
        "            print(f\"Warning: Failed to install: {', '.join(failed)}\")\n",
        "            print(\"Some features may not work\")\n",
        "\n",
        "            # Provide specific guidance for rpy2\n",
        "            if 'rpy2' in failed:\n",
        "                print(\"\\nFor rpy2 installation issues:\")\n",
        "                if self.is_vertex:\n",
        "                    print(\"   - Vertex AI: R may not be installed by default\")\n",
        "                    print(\"   - Run the next cell for automated R setup\")\n",
        "                else:\n",
        "                    print(\"   - On Windows: May need Visual Studio Build Tools\")\n",
        "                    print(\"   - Try: conda install -c conda-forge rpy2\")\n",
        "                    print(\"   - Or: pip install rpy2 (requires R to be installed)\")\n",
        "        else:\n",
        "            print(\"All packages ready\")\n",
        "\n",
        "        # Mount Google Drive if needed (check if DATA_SOURCE exists)\n",
        "        try:\n",
        "            if globals().get('DATA_SOURCE') == \"drive\" and self.is_colab:\n",
        "                self.mount_drive()\n",
        "        except NameError:\n",
        "            pass  # DATA_SOURCE not defined yet\n",
        "\n",
        "    def mount_drive(self):\n",
        "        \"\"\"Mount Google Drive in Colab\"\"\"\n",
        "        try:\n",
        "            from google.colab import drive\n",
        "            drive.mount('/content/drive')\n",
        "            print(\"Google Drive mounted successfully\")\n",
        "        except:\n",
        "            print(\"Error: Failed to mount Google Drive\")\n",
        "\n",
        "# Initialize environment\n",
        "env_manager = EnvironmentManager()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyZ9A_kurPrf"
      },
      "source": [
        "If running in Vertex AI Workbench for the first time (or if the previous cell gave an error), run this cell to install R and setup essential dependencies, then re-run the previous cell for rpy2.\n",
        "\n",
        "Otherwise, skip this cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-4eMeiiMrPrg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "R Environment setup for Vertex AI - implementation pending\n"
          ]
        }
      ],
      "source": [
        "print(\"R Environment setup for Vertex AI - implementation pending\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mm4dTQb1rPrh"
      },
      "source": [
        "---\n",
        "## 3. R Environment Setup\n",
        "\n",
        "Load R integration and install R packages efficiently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7wpUbizDrPrh"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Error importing in API mode: ImportError('On Windows, cffi mode \"ANY\" is only \"ABI\".')\n",
            "Trying to import in ABI mode.\n",
            "Trying to import in ABI mode.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "R integration loaded successfully\n"
          ]
        }
      ],
      "source": [
        "# Load rpy2 extension for R integration\n",
        "try:\n",
        "    %load_ext rpy2.ipython\n",
        "    print(\"R integration loaded successfully\")\n",
        "    globals()['R_AVAILABLE'] = True\n",
        "except Exception as e:\n",
        "    print(f\"Error: Failed to load R integration: {e}\")\n",
        "\n",
        "    # Windows-specific troubleshooting\n",
        "    if \"R.dll\" in str(e) or \"error 0x7e\" in str(e):\n",
        "        print(\"\\nWindows R.dll loading issue detected:\")\n",
        "        print(\"   This is a common Windows + rpy2 compatibility issue\")\n",
        "        print(\"   Solutions:\")\n",
        "        print(\"   1. Restart Python kernel and try again\")\n",
        "        print(\"   2. Check R version compatibility with rpy2\")\n",
        "        print(\"   3. Try reinstalling R and rpy2\")\n",
        "        print(\"   4. Use Python-only analysis (fallback available)\")\n",
        "        globals()['R_AVAILABLE'] = False\n",
        "    else:\n",
        "        print(\"Install rpy2: pip install rpy2\")\n",
        "        globals()['R_AVAILABLE'] = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5iP0V_1rPri"
      },
      "source": [
        "Install essential R packages and attempt installation of optional packages.\n",
        "\n",
        "**Note:** Other packages needed for specific analysis (advanced modeling packages) will be installed and called as needed later in the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QGFfQQC5rPri"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Local environment detected\n",
            "Essential packages loaded: 3 / 3 \n",
            "Essential packages loaded: 3 / 3 \n",
            "Optional packages loaded: 2 / 2 \n",
            "Core environment ready! (data.table + ggplot2)\n",
            "Optional packages loaded: 2 / 2 \n",
            "Core environment ready! (data.table + ggplot2)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "In addition: Warning messages:\n",
              "1: package 'data.table' was built under R version 4.4.3 \n",
              "2: package 'ggplot2' was built under R version 4.4.2 \n",
              "3: package 'survey' was built under R version 4.4.3 \n",
              "4: package 'broom' was built under R version 4.4.2 \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%%R -i VERBOSE_PRINTS\n",
        "\n",
        "# Environment-aware R package setup\n",
        "# Standard approach, then Vertex AI fallback if needed\n",
        "\n",
        "# Detect environment\n",
        "is_vertex <- Sys.getenv(\"DL_ANACONDA_HOME\") != \"\"\n",
        "is_colab <- Sys.getenv(\"COLAB_GPU\") != \"\"\n",
        "\n",
        "if(is_colab) {\n",
        "  cat(\"Google Colab detected\\n\")\n",
        "} else if(is_vertex) {\n",
        "  cat(\"Vertex AI detected\\n\")\n",
        "} else {\n",
        "  cat(\"Local environment detected\\n\")\n",
        "}\n",
        "\n",
        "# Standard clean setup (for all environments initially)\n",
        "essential_packages <- c(\n",
        "  \"data.table\",    # Fast data manipulation\n",
        "  \"ggplot2\",       # Plotting\n",
        "  \"scales\"         # For ggplot2 percentage scales\n",
        ")\n",
        "\n",
        "optional_packages <- c(\n",
        "  \"survey\",        # Survey statistics\n",
        "  \"broom\"          # Model tidying\n",
        ")\n",
        "\n",
        "# Fast installation settings\n",
        "repos <- \"https://cloud.r-project.org\"\n",
        "options(repos = repos)\n",
        "Sys.setenv(MAKEFLAGS = paste0(\"-j\", parallel::detectCores()))\n",
        "\n",
        "# Package check and load functions\n",
        "pkg_available <- function(pkg) {\n",
        "  tryCatch({\n",
        "    find.package(pkg, quiet = TRUE)\n",
        "    TRUE\n",
        "  }, error = function(e) FALSE)\n",
        "}\n",
        "\n",
        "load_pkg <- function(pkg) {\n",
        "  tryCatch({\n",
        "    suppressMessages(library(pkg, character.only = TRUE, quietly = TRUE))\n",
        "    TRUE\n",
        "  }, error = function(e) FALSE)\n",
        "}\n",
        "\n",
        "# Install missing essential packages\n",
        "missing_essential <- essential_packages[!sapply(essential_packages, pkg_available)]\n",
        "\n",
        "if(length(missing_essential) > 0) {\n",
        "  cat(\"Installing essential packages:\", paste(missing_essential, collapse = \", \"), \"\\n\")\n",
        "\n",
        "  tryCatch({\n",
        "    install.packages(missing_essential,\n",
        "                    repos = repos,\n",
        "                    type = getOption(\"pkgType\"),\n",
        "                    dependencies = FALSE,\n",
        "                    quiet = !VERBOSE_PRINTS,\n",
        "                    Ncpus = parallel::detectCores())\n",
        "  }, error = function(e) {\n",
        "    cat(\"Binary install failed, trying source...\\n\")\n",
        "    install.packages(missing_essential,\n",
        "                    repos = repos,\n",
        "                    type = \"source\",\n",
        "                    dependencies = FALSE,\n",
        "                    quiet = !VERBOSE_PRINTS)\n",
        "  })\n",
        "}\n",
        "\n",
        "# Load essential packages\n",
        "essential_loaded <- sapply(essential_packages, load_pkg)\n",
        "essential_success <- sum(essential_loaded)\n",
        "\n",
        "cat(\"Essential packages loaded:\", essential_success, \"/\", length(essential_packages), \"\\n\")\n",
        "\n",
        "# Quick install optional packages (30s timeout)\n",
        "missing_optional <- optional_packages[!sapply(optional_packages, pkg_available)]\n",
        "\n",
        "if(length(missing_optional) > 0) {\n",
        "  cat(\"Installing optional packages...\\n\")\n",
        "\n",
        "  for(pkg in missing_optional) {\n",
        "    tryCatch({\n",
        "      setTimeLimit(cpu = 30, elapsed = 30, transient = TRUE)\n",
        "      install.packages(pkg, repos = repos,\n",
        "                      type = getOption(\"pkgType\"),\n",
        "                      dependencies = FALSE,\n",
        "                      quiet = TRUE)\n",
        "      cat(\"Installed:\", pkg, \"\\n\")\n",
        "    }, error = function(e) {\n",
        "      cat(\"Skipped (timeout):\", pkg, \"\\n\")\n",
        "    })\n",
        "\n",
        "    setTimeLimit(cpu = Inf, elapsed = Inf, transient = FALSE)\n",
        "  }\n",
        "}\n",
        "\n",
        "# Load optional packages\n",
        "optional_loaded <- sapply(optional_packages, load_pkg)\n",
        "optional_success <- sum(optional_loaded)\n",
        "\n",
        "cat(\"Optional packages loaded:\", optional_success, \"/\", length(optional_packages), \"\\n\")\n",
        "\n",
        "# Check if we need Vertex AI aggressive installation\n",
        "has_datatable <- require(\"data.table\", quietly = TRUE)\n",
        "has_ggplot <- require(\"ggplot2\", quietly = TRUE)\n",
        "\n",
        "if(is_vertex && (!has_datatable || !has_ggplot)) {\n",
        "  cat(\"\\nStandard installation incomplete on Vertex AI - using aggressive method...\\n\")\n",
        "\n",
        "  # Check R version for compatibility\n",
        "  r_version <- R.version.string\n",
        "  r_numeric <- as.numeric(R.version$major) + as.numeric(R.version$minor)/10\n",
        "  cat(\"R version:\", r_version, \"(numeric:\", r_numeric, \")\\n\")\n",
        "\n",
        "  # System dependencies for Vertex AI\n",
        "  system_deps <- c(\n",
        "    \"apt-get update -qq\",\n",
        "    \"apt-get install -y libfontconfig1-dev libcairo2-dev\",\n",
        "    \"apt-get install -y libxml2-dev libcurl4-openssl-dev libssl-dev\",\n",
        "    \"apt-get install -y libharfbuzz-dev libfribidi-dev\",\n",
        "    \"apt-get install -y libfreetype6-dev libpng-dev libtiff5-dev libjpeg-dev\"\n",
        "  )\n",
        "\n",
        "  cat(\"Installing system dependencies...\\n\")\n",
        "  for(cmd in system_deps) {\n",
        "    system(paste(\"sudo\", cmd), ignore.stdout = TRUE, ignore.stderr = TRUE)\n",
        "  }\n",
        "\n",
        "  # Aggressive package installation for failed packages\n",
        "  failed_packages <- c()\n",
        "  if(!has_datatable) failed_packages <- c(failed_packages, \"data.table\")\n",
        "  if(!has_ggplot) failed_packages <- c(failed_packages, \"ggplot2\", \"scales\")\n",
        "\n",
        "  repos_vertex <- c(\"https://cran.rstudio.com/\", \"https://cloud.r-project.org\")\n",
        "\n",
        "  for(pkg in failed_packages) {\n",
        "    cat(\"Aggressively installing\", pkg, \"...\")\n",
        "    installed <- FALSE\n",
        "\n",
        "    # For ggplot2/scales, try version-specific installation if R < 4.1\n",
        "    if((pkg == \"ggplot2\" || pkg == \"scales\") && r_numeric < 4.1) {\n",
        "      cat(\"(R < 4.1 detected - trying compatible versions)...\")\n",
        "\n",
        "      # First try to install remotes if not available\n",
        "      if(!require(\"remotes\", quietly = TRUE)) {\n",
        "        tryCatch({\n",
        "          install.packages(\"remotes\", repos = repos_vertex[1], quiet = TRUE)\n",
        "        }, error = function(e) NULL)\n",
        "      }\n",
        "\n",
        "      # Try installing older compatible versions\n",
        "      if(pkg == \"ggplot2\" && require(\"remotes\", quietly = TRUE)) {\n",
        "        # Try ggplot2 versions compatible with older R\n",
        "        old_versions <- c(\"3.4.4\", \"3.4.3\", \"3.4.2\", \"3.4.0\", \"3.3.6\")\n",
        "        for(ver in old_versions) {\n",
        "          tryCatch({\n",
        "            remotes::install_version(\"ggplot2\", version = ver, repos = repos_vertex[1], quiet = TRUE)\n",
        "            if(require(\"ggplot2\", quietly = TRUE)) {\n",
        "              cat(\" Success (v\", ver, \")\\n\")\n",
        "              installed <- TRUE\n",
        "              break\n",
        "            }\n",
        "          }, error = function(e) NULL)\n",
        "        }\n",
        "      } else if(pkg == \"scales\" && require(\"remotes\", quietly = TRUE)) {\n",
        "        # Try scales versions compatible with older R\n",
        "        old_versions <- c(\"1.3.0\", \"1.2.1\", \"1.2.0\", \"1.1.1\")\n",
        "        for(ver in old_versions) {\n",
        "          tryCatch({\n",
        "            remotes::install_version(\"scales\", version = ver, repos = repos_vertex[1], quiet = TRUE)\n",
        "            if(require(\"scales\", quietly = TRUE)) {\n",
        "              cat(\" Success (v\", ver, \")\\n\")\n",
        "              installed <- TRUE\n",
        "              break\n",
        "            }\n",
        "          }, error = function(e) NULL)\n",
        "        }\n",
        "      }\n",
        "\n",
        "      # Fallback: try archived CRAN packages if remotes failed\n",
        "      if(!installed && pkg == \"ggplot2\") {\n",
        "        cat(\"(trying archived versions)...\")\n",
        "        archived_urls <- c(\n",
        "          \"https://cran.r-project.org/src/contrib/Archive/ggplot2/ggplot2_3.4.4.tar.gz\",\n",
        "          \"https://cran.r-project.org/src/contrib/Archive/ggplot2/ggplot2_3.4.0.tar.gz\",\n",
        "          \"https://cran.r-project.org/src/contrib/Archive/ggplot2/ggplot2_3.3.6.tar.gz\"\n",
        "        )\n",
        "        for(url in archived_urls) {\n",
        "          tryCatch({\n",
        "            install.packages(url, repos = NULL, type = \"source\", quiet = TRUE)\n",
        "            if(require(\"ggplot2\", quietly = TRUE)) {\n",
        "              cat(\" Success (archived)\\n\")\n",
        "              installed <- TRUE\n",
        "              break\n",
        "            }\n",
        "          }, error = function(e) NULL)\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "\n",
        "    # Standard installation if version-specific didn't work\n",
        "    if(!installed) {\n",
        "      for(repo in repos_vertex) {\n",
        "        tryCatch({\n",
        "          install.packages(pkg, repos = repo, dependencies = TRUE, quiet = TRUE)\n",
        "          if(require(pkg, character.only = TRUE, quietly = TRUE)) {\n",
        "            cat(\" Success\\n\")\n",
        "            installed <- TRUE\n",
        "            break\n",
        "          }\n",
        "        }, error = function(e) NULL)\n",
        "      }\n",
        "    }\n",
        "\n",
        "    if(!installed) cat(\" FAILED\\n\")\n",
        "  }\n",
        "\n",
        "  # Re-check after aggressive installation\n",
        "  has_datatable <- require(\"data.table\", quietly = TRUE)\n",
        "  has_ggplot <- require(\"ggplot2\", quietly = TRUE)\n",
        "\n",
        "  cat(\"After aggressive installation: data.table =\", has_datatable, \"| ggplot2 =\", has_ggplot, \"\\n\")\n",
        "}\n",
        "\n",
        "# Final status check (universal)\n",
        "if(has_datatable && has_ggplot) {\n",
        "  cat(\"Core environment ready! (data.table + ggplot2)\\n\")\n",
        "  setDTthreads(0)  # Use all cores\n",
        "\n",
        "} else if(has_datatable) {\n",
        "  cat(\"Warning: Partial setup - data.table ready, plotting may be limited\\n\")\n",
        "  setDTthreads(0)\n",
        "\n",
        "} else {\n",
        "  cat(\"Error: Critical failure - data.table not available\\n\")\n",
        "  stop(\"Cannot proceed without data.table\")\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAtjPad_rPri"
      },
      "source": [
        "Verify R setup is complete and ready for analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WMh-C5gvrPrj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Verifying R environment...\n",
            "data.table ready\n",
            "ggplot2 ready\n",
            "R environment optimized and ready!\n",
            "data.table ready\n",
            "ggplot2 ready\n",
            "R environment optimized and ready!\n"
          ]
        }
      ],
      "source": [
        "%%R\n",
        "\n",
        "# Quick verification and setup\n",
        "cat(\"Verifying R environment...\\n\")\n",
        "\n",
        "# Test core functionality\n",
        "tryCatch({\n",
        "  # Test data.table (essential)\n",
        "  dt_test <- data.table(x = 1:3, y = letters[1:3])\n",
        "  cat(\"data.table ready\\n\")\n",
        "\n",
        "  # Test ggplot2 (optional)\n",
        "  if(require(\"ggplot2\", quietly = TRUE)) {\n",
        "    cat(\"ggplot2 ready\\n\")\n",
        "  } else {\n",
        "    cat(\"Warning: ggplot2 not available (plots disabled)\\n\")\n",
        "  }\n",
        "\n",
        "  # Set up data.table options for performance\n",
        "  setDTthreads(0)  # Use all cores\n",
        "\n",
        "  cat(\"R environment optimized and ready!\\n\")\n",
        "\n",
        "}, error = function(e) {\n",
        "  cat(\"Error: R environment verification failed:\", e$message, \"\\n\")\n",
        "  stop(\"R setup incomplete\")\n",
        "})\n",
        "\n",
        "# Clean up test objects\n",
        "rm(list = ls()[!ls() %in% c(\"VERBOSE_PRINTS\")])\n",
        "invisible(gc())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8pUXVbsrPrg"
      },
      "source": [
        "---\n",
        "## 4. Data Loading\n",
        "\n",
        "Config based data loader with error handling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "s-KUtlK-rPrh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data from: GITHUB\n",
            "✓ Downloaded from GitHub (213436933 bytes)\n",
            "✓ Downloaded from GitHub (213436933 bytes)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\laure\\AppData\\Local\\Temp\\ipykernel_4416\\2490609550.py:35: DtypeWarning: Columns (56,57,58,59) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  return pd.read_csv(data_path)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Data loaded successfully!\n",
            "   Shape: (139233, 675)\n",
            "   Memory: 885.2 MB\n",
            "\n",
            "Columns: ['KEY_NASS', 'HOSP_NASS', 'HOSP_TEACH', 'HOSP_LOCATION', 'HOSP_LOCTEACH', 'HOSP_REGION', 'HOSP_BEDSIZE_CAT', 'DISCWT', 'NASS_STRATUM', 'N_DISC_U', 'N_HOSP_U', 'S_DISC_U', 'S_HOSP_U', 'TOTAL_AS_ENCOUNTERS', 'YEAR', 'AGE', 'FEMALE', 'PL_NCHS', 'ZIPINC_QRTL', 'AMONTH', 'AWEEKEND', 'DQTR', 'PAY1', 'DISPUNIFORM', 'TOTCHG', 'NCPT_INSCOPE', 'CPTCCS1', 'CPTCCS2', 'CPTCCS3', 'CPTCCS4', 'CPTCCS5', 'CPTCCS6', 'CPTCCS7', 'CPTCCS8', 'CPTCCS9', 'CPTCCS10', 'CPTCCS11', 'CPTCCS12', 'CPTCCS13', 'CPTCCS14', 'CPTCCS15', 'CPTCCS16', 'CPTCCS17', 'CPTCCS18', 'CPTCCS19', 'CPTCCS20', 'CPTCCS21', 'CPTCCS22', 'CPTCCS23', 'CPTCCS24', 'CPTCCS25', 'CPTCCS26', 'CPTCCS27', 'CPTCCS28', 'CPTCCS29', 'CPTCCS30', 'CPT1', 'CPT2', 'CPT3', 'CPT4', 'CPT5', 'CPT6', 'CPT7', 'CPT8', 'CPT9', 'CPT10', 'CPT11', 'CPT12', 'CPT13', 'CPT14', 'CPT15', 'CPT16', 'CPT17', 'CPT18', 'CPT19', 'CPT20', 'CPT21', 'CPT22', 'CPT23', 'CPT24', 'CPT25', 'CPT26', 'CPT27', 'CPT28', 'CPT29', 'CPT30', 'I10_NDX', 'I10_DX1', 'I10_DX2', 'I10_DX3', 'I10_DX4', 'I10_DX5', 'I10_DX6', 'I10_DX7', 'I10_DX8', 'I10_DX9', 'I10_DX10', 'I10_DX11', 'I10_DX12', 'I10_DX13', 'I10_DX14', 'I10_DX15', 'I10_DX16', 'I10_DX17', 'I10_DX18', 'I10_DX19', 'I10_DX20', 'RACE', 'I10_INJURY', 'I10_MULTINJURY', 'CMR_AIDS', 'CMR_ALCOHOL', 'CMR_AUTOIMMUNE', 'CMR_CANCER_LYMPH', 'CMR_CANCER_LEUK', 'CMR_CANCER_METS', 'CMR_CANCER_NSITU', 'CMR_CANCER_SOLID', 'CMR_DEMENTIA', 'CMR_DEPRESS', 'CMR_DIAB_UNCX', 'CMR_DIAB_CX', 'CMR_DRUG_ABUSE', 'CMR_HTN_CX', 'CMR_HTN_UNCX', 'CMR_LUNG_CHRONIC', 'CMR_OBESE', 'CMR_PERIVASC', 'CMR_THYROID_HYPO', 'CMR_THYROID_OTH', 'CMR_VERSION', 'DXCCSR_Default_DX1', 'DXCCSR_BLD001', 'DXCCSR_BLD002', 'DXCCSR_BLD003', 'DXCCSR_BLD004', 'DXCCSR_BLD005', 'DXCCSR_BLD006', 'DXCCSR_BLD007', 'DXCCSR_BLD008', 'DXCCSR_BLD009', 'DXCCSR_BLD010', 'DXCCSR_CIR001', 'DXCCSR_CIR002', 'DXCCSR_CIR003', 'DXCCSR_CIR004', 'DXCCSR_CIR005', 'DXCCSR_CIR006', 'DXCCSR_CIR007', 'DXCCSR_CIR008', 'DXCCSR_CIR009', 'DXCCSR_CIR010', 'DXCCSR_CIR011', 'DXCCSR_CIR012', 'DXCCSR_CIR013', 'DXCCSR_CIR014', 'DXCCSR_CIR015', 'DXCCSR_CIR016', 'DXCCSR_CIR017', 'DXCCSR_CIR018', 'DXCCSR_CIR019', 'DXCCSR_CIR020', 'DXCCSR_CIR021', 'DXCCSR_CIR022', 'DXCCSR_CIR023', 'DXCCSR_CIR024', 'DXCCSR_CIR025', 'DXCCSR_CIR026', 'DXCCSR_CIR027', 'DXCCSR_CIR028', 'DXCCSR_CIR029', 'DXCCSR_CIR030', 'DXCCSR_CIR031', 'DXCCSR_CIR032', 'DXCCSR_CIR033', 'DXCCSR_CIR034', 'DXCCSR_CIR035', 'DXCCSR_CIR036', 'DXCCSR_CIR037', 'DXCCSR_CIR038', 'DXCCSR_CIR039', 'DXCCSR_DIG001', 'DXCCSR_DIG002', 'DXCCSR_DIG003', 'DXCCSR_DIG004', 'DXCCSR_DIG005', 'DXCCSR_DIG006', 'DXCCSR_DIG007', 'DXCCSR_DIG008', 'DXCCSR_DIG009', 'DXCCSR_DIG010', 'DXCCSR_DIG011', 'DXCCSR_DIG012', 'DXCCSR_DIG013', 'DXCCSR_DIG014', 'DXCCSR_DIG015', 'DXCCSR_DIG016', 'DXCCSR_DIG017', 'DXCCSR_DIG018', 'DXCCSR_DIG019', 'DXCCSR_DIG020', 'DXCCSR_DIG021', 'DXCCSR_DIG022', 'DXCCSR_DIG023', 'DXCCSR_DIG024', 'DXCCSR_DIG025', 'DXCCSR_EAR001', 'DXCCSR_EAR002', 'DXCCSR_EAR003', 'DXCCSR_EAR004', 'DXCCSR_EAR005', 'DXCCSR_EAR006', 'DXCCSR_END001', 'DXCCSR_END002', 'DXCCSR_END003', 'DXCCSR_END004', 'DXCCSR_END005', 'DXCCSR_END006', 'DXCCSR_END007', 'DXCCSR_END008', 'DXCCSR_END009', 'DXCCSR_END010', 'DXCCSR_END011', 'DXCCSR_END012', 'DXCCSR_END013', 'DXCCSR_END014', 'DXCCSR_END015', 'DXCCSR_END016', 'DXCCSR_END017', 'DXCCSR_EXT001', 'DXCCSR_EXT002', 'DXCCSR_EXT003', 'DXCCSR_EXT004', 'DXCCSR_EXT005', 'DXCCSR_EXT006', 'DXCCSR_EXT007', 'DXCCSR_EXT008', 'DXCCSR_EXT009', 'DXCCSR_EXT010', 'DXCCSR_EXT011', 'DXCCSR_EXT012', 'DXCCSR_EXT013', 'DXCCSR_EXT014', 'DXCCSR_EXT015', 'DXCCSR_EXT016', 'DXCCSR_EXT017', 'DXCCSR_EXT018', 'DXCCSR_EXT019', 'DXCCSR_EXT020', 'DXCCSR_EXT021', 'DXCCSR_EXT022', 'DXCCSR_EXT023', 'DXCCSR_EXT024', 'DXCCSR_EXT025', 'DXCCSR_EXT026', 'DXCCSR_EXT027', 'DXCCSR_EXT028', 'DXCCSR_EXT029', 'DXCCSR_EXT030', 'DXCCSR_EYE001', 'DXCCSR_EYE002', 'DXCCSR_EYE003', 'DXCCSR_EYE004', 'DXCCSR_EYE005', 'DXCCSR_EYE006', 'DXCCSR_EYE007', 'DXCCSR_EYE008', 'DXCCSR_EYE009', 'DXCCSR_EYE010', 'DXCCSR_EYE011', 'DXCCSR_EYE012', 'DXCCSR_FAC001', 'DXCCSR_FAC002', 'DXCCSR_FAC003', 'DXCCSR_FAC004', 'DXCCSR_FAC005', 'DXCCSR_FAC006', 'DXCCSR_FAC007', 'DXCCSR_FAC008', 'DXCCSR_FAC009', 'DXCCSR_FAC010', 'DXCCSR_FAC011', 'DXCCSR_FAC012', 'DXCCSR_FAC013', 'DXCCSR_FAC014', 'DXCCSR_FAC015', 'DXCCSR_FAC016', 'DXCCSR_FAC017', 'DXCCSR_FAC018', 'DXCCSR_FAC019', 'DXCCSR_FAC020', 'DXCCSR_FAC021', 'DXCCSR_FAC022', 'DXCCSR_FAC023', 'DXCCSR_FAC024', 'DXCCSR_FAC025', 'DXCCSR_GEN001', 'DXCCSR_GEN002', 'DXCCSR_GEN003', 'DXCCSR_GEN004', 'DXCCSR_GEN005', 'DXCCSR_GEN006', 'DXCCSR_GEN007', 'DXCCSR_GEN008', 'DXCCSR_GEN009', 'DXCCSR_GEN010', 'DXCCSR_GEN011', 'DXCCSR_GEN012', 'DXCCSR_GEN013', 'DXCCSR_GEN014', 'DXCCSR_GEN015', 'DXCCSR_GEN016', 'DXCCSR_GEN017', 'DXCCSR_GEN018', 'DXCCSR_GEN019', 'DXCCSR_GEN020', 'DXCCSR_GEN021', 'DXCCSR_GEN022', 'DXCCSR_GEN023', 'DXCCSR_GEN024', 'DXCCSR_GEN025', 'DXCCSR_GEN026', 'DXCCSR_INF001', 'DXCCSR_INF002', 'DXCCSR_INF003', 'DXCCSR_INF004', 'DXCCSR_INF005', 'DXCCSR_INF006', 'DXCCSR_INF007', 'DXCCSR_INF008', 'DXCCSR_INF009', 'DXCCSR_INF010', 'DXCCSR_INF011', 'DXCCSR_INF012', 'DXCCSR_INJ001', 'DXCCSR_INJ002', 'DXCCSR_INJ003', 'DXCCSR_INJ004', 'DXCCSR_INJ005', 'DXCCSR_INJ006', 'DXCCSR_INJ007', 'DXCCSR_INJ008', 'DXCCSR_INJ009', 'DXCCSR_INJ010', 'DXCCSR_INJ011', 'DXCCSR_INJ012', 'DXCCSR_INJ013', 'DXCCSR_INJ014', 'DXCCSR_INJ015', 'DXCCSR_INJ016', 'DXCCSR_INJ017', 'DXCCSR_INJ018', 'DXCCSR_INJ019', 'DXCCSR_INJ020', 'DXCCSR_INJ021', 'DXCCSR_INJ022', 'DXCCSR_INJ023', 'DXCCSR_INJ024', 'DXCCSR_INJ025', 'DXCCSR_INJ026', 'DXCCSR_INJ027', 'DXCCSR_INJ028', 'DXCCSR_INJ029', 'DXCCSR_INJ030', 'DXCCSR_INJ031', 'DXCCSR_INJ032', 'DXCCSR_INJ033', 'DXCCSR_INJ034', 'DXCCSR_INJ035', 'DXCCSR_INJ036', 'DXCCSR_INJ037', 'DXCCSR_INJ038', 'DXCCSR_INJ039', 'DXCCSR_INJ040', 'DXCCSR_INJ041', 'DXCCSR_INJ042', 'DXCCSR_INJ043', 'DXCCSR_INJ044', 'DXCCSR_INJ045', 'DXCCSR_INJ046', 'DXCCSR_INJ047', 'DXCCSR_INJ048', 'DXCCSR_INJ049', 'DXCCSR_INJ050', 'DXCCSR_INJ051', 'DXCCSR_INJ052', 'DXCCSR_INJ053', 'DXCCSR_INJ054', 'DXCCSR_INJ055', 'DXCCSR_INJ056', 'DXCCSR_INJ057', 'DXCCSR_INJ058', 'DXCCSR_INJ059', 'DXCCSR_INJ060', 'DXCCSR_INJ061', 'DXCCSR_INJ062', 'DXCCSR_INJ063', 'DXCCSR_INJ064', 'DXCCSR_INJ065', 'DXCCSR_INJ066', 'DXCCSR_INJ067', 'DXCCSR_INJ068', 'DXCCSR_INJ069', 'DXCCSR_INJ070', 'DXCCSR_INJ071', 'DXCCSR_INJ072', 'DXCCSR_INJ073', 'DXCCSR_INJ074', 'DXCCSR_INJ075', 'DXCCSR_INJ076', 'DXCCSR_MAL001', 'DXCCSR_MAL002', 'DXCCSR_MAL003', 'DXCCSR_MAL004', 'DXCCSR_MAL005', 'DXCCSR_MAL006', 'DXCCSR_MAL007', 'DXCCSR_MAL008', 'DXCCSR_MAL009', 'DXCCSR_MAL010', 'DXCCSR_MBD001', 'DXCCSR_MBD002', 'DXCCSR_MBD003', 'DXCCSR_MBD004', 'DXCCSR_MBD005', 'DXCCSR_MBD006', 'DXCCSR_MBD007', 'DXCCSR_MBD008', 'DXCCSR_MBD009', 'DXCCSR_MBD010', 'DXCCSR_MBD011', 'DXCCSR_MBD012', 'DXCCSR_MBD013', 'DXCCSR_MBD014', 'DXCCSR_MBD017', 'DXCCSR_MBD018', 'DXCCSR_MBD019', 'DXCCSR_MBD020', 'DXCCSR_MBD021', 'DXCCSR_MBD022', 'DXCCSR_MBD023', 'DXCCSR_MBD024', 'DXCCSR_MBD025', 'DXCCSR_MBD026', 'DXCCSR_MBD027', 'DXCCSR_MBD028', 'DXCCSR_MBD029', 'DXCCSR_MBD030', 'DXCCSR_MBD031', 'DXCCSR_MBD032', 'DXCCSR_MBD033', 'DXCCSR_MBD034', 'DXCCSR_MUS001', 'DXCCSR_MUS002', 'DXCCSR_MUS003', 'DXCCSR_MUS004', 'DXCCSR_MUS005', 'DXCCSR_MUS006', 'DXCCSR_MUS007', 'DXCCSR_MUS008', 'DXCCSR_MUS009', 'DXCCSR_MUS010', 'DXCCSR_MUS011', 'DXCCSR_MUS012', 'DXCCSR_MUS013', 'DXCCSR_MUS014', 'DXCCSR_MUS015', 'DXCCSR_MUS016', 'DXCCSR_MUS017', 'DXCCSR_MUS018', 'DXCCSR_MUS019', 'DXCCSR_MUS020', 'DXCCSR_MUS021', 'DXCCSR_MUS022', 'DXCCSR_MUS023', 'DXCCSR_MUS024', 'DXCCSR_MUS025', 'DXCCSR_MUS026', 'DXCCSR_MUS027', 'DXCCSR_MUS028', 'DXCCSR_MUS029', 'DXCCSR_MUS030', 'DXCCSR_MUS031', 'DXCCSR_MUS032', 'DXCCSR_MUS033', 'DXCCSR_MUS034', 'DXCCSR_MUS035', 'DXCCSR_MUS036', 'DXCCSR_MUS037', 'DXCCSR_MUS038', 'DXCCSR_NEO001', 'DXCCSR_NEO002', 'DXCCSR_NEO003', 'DXCCSR_NEO004', 'DXCCSR_NEO005', 'DXCCSR_NEO006', 'DXCCSR_NEO007', 'DXCCSR_NEO008', 'DXCCSR_NEO009', 'DXCCSR_NEO010', 'DXCCSR_NEO011', 'DXCCSR_NEO012', 'DXCCSR_NEO013', 'DXCCSR_NEO014', 'DXCCSR_NEO015', 'DXCCSR_NEO016', 'DXCCSR_NEO017', 'DXCCSR_NEO018', 'DXCCSR_NEO019', 'DXCCSR_NEO020', 'DXCCSR_NEO021', 'DXCCSR_NEO022', 'DXCCSR_NEO023', 'DXCCSR_NEO024', 'DXCCSR_NEO025', 'DXCCSR_NEO026', 'DXCCSR_NEO027', 'DXCCSR_NEO028', 'DXCCSR_NEO029', 'DXCCSR_NEO030', 'DXCCSR_NEO031', 'DXCCSR_NEO032', 'DXCCSR_NEO033', 'DXCCSR_NEO034', 'DXCCSR_NEO035', 'DXCCSR_NEO036', 'DXCCSR_NEO037', 'DXCCSR_NEO038', 'DXCCSR_NEO039', 'DXCCSR_NEO040', 'DXCCSR_NEO041', 'DXCCSR_NEO042', 'DXCCSR_NEO043', 'DXCCSR_NEO044', 'DXCCSR_NEO045', 'DXCCSR_NEO046', 'DXCCSR_NEO047', 'DXCCSR_NEO048', 'DXCCSR_NEO049', 'DXCCSR_NEO050', 'DXCCSR_NEO051', 'DXCCSR_NEO052', 'DXCCSR_NEO053', 'DXCCSR_NEO054', 'DXCCSR_NEO055', 'DXCCSR_NEO056', 'DXCCSR_NEO057', 'DXCCSR_NEO058', 'DXCCSR_NEO059', 'DXCCSR_NEO060', 'DXCCSR_NEO061', 'DXCCSR_NEO062', 'DXCCSR_NEO063', 'DXCCSR_NEO064', 'DXCCSR_NEO065', 'DXCCSR_NEO066', 'DXCCSR_NEO067', 'DXCCSR_NEO068', 'DXCCSR_NEO069', 'DXCCSR_NEO070', 'DXCCSR_NEO071', 'DXCCSR_NEO072', 'DXCCSR_NEO073', 'DXCCSR_NEO074', 'DXCCSR_NVS001', 'DXCCSR_NVS002', 'DXCCSR_NVS003', 'DXCCSR_NVS004', 'DXCCSR_NVS005', 'DXCCSR_NVS006', 'DXCCSR_NVS007', 'DXCCSR_NVS008', 'DXCCSR_NVS009', 'DXCCSR_NVS010', 'DXCCSR_NVS011', 'DXCCSR_NVS012', 'DXCCSR_NVS013', 'DXCCSR_NVS014', 'DXCCSR_NVS015', 'DXCCSR_NVS016', 'DXCCSR_NVS017', 'DXCCSR_NVS018', 'DXCCSR_NVS019', 'DXCCSR_NVS020', 'DXCCSR_NVS021', 'DXCCSR_NVS022', 'DXCCSR_PNL001', 'DXCCSR_PNL002', 'DXCCSR_PNL003', 'DXCCSR_PNL004', 'DXCCSR_PNL005', 'DXCCSR_PNL006', 'DXCCSR_PNL007', 'DXCCSR_PNL008', 'DXCCSR_PNL009', 'DXCCSR_PNL010', 'DXCCSR_PNL011', 'DXCCSR_PNL012', 'DXCCSR_PNL013', 'DXCCSR_PNL014', 'DXCCSR_PNL015', 'DXCCSR_PRG001', 'DXCCSR_PRG002', 'DXCCSR_PRG003', 'DXCCSR_PRG004', 'DXCCSR_PRG005', 'DXCCSR_PRG006', 'DXCCSR_PRG007', 'DXCCSR_PRG008', 'DXCCSR_PRG009', 'DXCCSR_PRG010', 'DXCCSR_PRG011', 'DXCCSR_PRG012', 'DXCCSR_PRG013', 'DXCCSR_PRG014', 'DXCCSR_PRG015', 'DXCCSR_PRG016', 'DXCCSR_PRG017', 'DXCCSR_PRG018', 'DXCCSR_PRG019', 'DXCCSR_PRG020', 'DXCCSR_PRG021', 'DXCCSR_PRG022', 'DXCCSR_PRG023', 'DXCCSR_PRG024', 'DXCCSR_PRG025', 'DXCCSR_PRG026', 'DXCCSR_PRG027', 'DXCCSR_PRG028', 'DXCCSR_PRG029', 'DXCCSR_PRG030', 'DXCCSR_RSP001', 'DXCCSR_RSP002', 'DXCCSR_RSP003', 'DXCCSR_RSP004', 'DXCCSR_RSP005', 'DXCCSR_RSP006', 'DXCCSR_RSP007', 'DXCCSR_RSP008', 'DXCCSR_RSP009', 'DXCCSR_RSP010', 'DXCCSR_RSP011', 'DXCCSR_RSP012', 'DXCCSR_RSP013', 'DXCCSR_RSP014', 'DXCCSR_RSP015', 'DXCCSR_RSP016', 'DXCCSR_RSP017', 'DXCCSR_SKN001', 'DXCCSR_SKN002', 'DXCCSR_SKN003', 'DXCCSR_SKN004', 'DXCCSR_SKN005', 'DXCCSR_SKN006', 'DXCCSR_SKN007', 'DXCCSR_SYM001', 'DXCCSR_SYM002', 'DXCCSR_SYM003', 'DXCCSR_SYM004', 'DXCCSR_SYM005', 'DXCCSR_SYM006', 'DXCCSR_SYM007', 'DXCCSR_SYM008', 'DXCCSR_SYM009', 'DXCCSR_SYM010', 'DXCCSR_SYM011', 'DXCCSR_SYM012', 'DXCCSR_SYM013', 'DXCCSR_SYM014', 'DXCCSR_SYM015', 'DXCCSR_SYM016', 'DXCCSR_SYM017', 'DXCCSR_VERSION', 'AGEGRP', 'AGEGRP2']\n",
            "\n",
            "First 3 rows:\n",
            "   KEY_NASS  HOSP_NASS  HOSP_TEACH  HOSP_LOCATION  HOSP_LOCTEACH  HOSP_REGION  \\\n",
            "0  90000001      40053           1              1              3            4   \n",
            "1  90000002      20162           0              1              2            2   \n",
            "2  90000003      30223           1              1              3            3   \n",
            "\n",
            "   HOSP_BEDSIZE_CAT    DISCWT  NASS_STRATUM  N_DISC_U  ...  DXCCSR_SYM011  \\\n",
            "0                 2  1.579073             9    321406  ...              0   \n",
            "1                 2  1.031092            49    152635  ...              0   \n",
            "2                 3  1.245274             7    837566  ...              0   \n",
            "\n",
            "   DXCCSR_SYM012  DXCCSR_SYM013  DXCCSR_SYM014  DXCCSR_SYM015  DXCCSR_SYM016  \\\n",
            "0              0              0              0              0              0   \n",
            "1              0              0              0              0              0   \n",
            "2              0              0              0              0              0   \n",
            "\n",
            "   DXCCSR_SYM017  DXCCSR_VERSION  AGEGRP  AGEGRP2  \n",
            "0              0          2022.1    0-17     0-17  \n",
            "1              0          2022.1   18-64    40-54  \n",
            "2              0          2022.1   18-64    55-64  \n",
            "\n",
            "[3 rows x 675 columns]\n",
            "   Memory: 885.2 MB\n",
            "\n",
            "Columns: ['KEY_NASS', 'HOSP_NASS', 'HOSP_TEACH', 'HOSP_LOCATION', 'HOSP_LOCTEACH', 'HOSP_REGION', 'HOSP_BEDSIZE_CAT', 'DISCWT', 'NASS_STRATUM', 'N_DISC_U', 'N_HOSP_U', 'S_DISC_U', 'S_HOSP_U', 'TOTAL_AS_ENCOUNTERS', 'YEAR', 'AGE', 'FEMALE', 'PL_NCHS', 'ZIPINC_QRTL', 'AMONTH', 'AWEEKEND', 'DQTR', 'PAY1', 'DISPUNIFORM', 'TOTCHG', 'NCPT_INSCOPE', 'CPTCCS1', 'CPTCCS2', 'CPTCCS3', 'CPTCCS4', 'CPTCCS5', 'CPTCCS6', 'CPTCCS7', 'CPTCCS8', 'CPTCCS9', 'CPTCCS10', 'CPTCCS11', 'CPTCCS12', 'CPTCCS13', 'CPTCCS14', 'CPTCCS15', 'CPTCCS16', 'CPTCCS17', 'CPTCCS18', 'CPTCCS19', 'CPTCCS20', 'CPTCCS21', 'CPTCCS22', 'CPTCCS23', 'CPTCCS24', 'CPTCCS25', 'CPTCCS26', 'CPTCCS27', 'CPTCCS28', 'CPTCCS29', 'CPTCCS30', 'CPT1', 'CPT2', 'CPT3', 'CPT4', 'CPT5', 'CPT6', 'CPT7', 'CPT8', 'CPT9', 'CPT10', 'CPT11', 'CPT12', 'CPT13', 'CPT14', 'CPT15', 'CPT16', 'CPT17', 'CPT18', 'CPT19', 'CPT20', 'CPT21', 'CPT22', 'CPT23', 'CPT24', 'CPT25', 'CPT26', 'CPT27', 'CPT28', 'CPT29', 'CPT30', 'I10_NDX', 'I10_DX1', 'I10_DX2', 'I10_DX3', 'I10_DX4', 'I10_DX5', 'I10_DX6', 'I10_DX7', 'I10_DX8', 'I10_DX9', 'I10_DX10', 'I10_DX11', 'I10_DX12', 'I10_DX13', 'I10_DX14', 'I10_DX15', 'I10_DX16', 'I10_DX17', 'I10_DX18', 'I10_DX19', 'I10_DX20', 'RACE', 'I10_INJURY', 'I10_MULTINJURY', 'CMR_AIDS', 'CMR_ALCOHOL', 'CMR_AUTOIMMUNE', 'CMR_CANCER_LYMPH', 'CMR_CANCER_LEUK', 'CMR_CANCER_METS', 'CMR_CANCER_NSITU', 'CMR_CANCER_SOLID', 'CMR_DEMENTIA', 'CMR_DEPRESS', 'CMR_DIAB_UNCX', 'CMR_DIAB_CX', 'CMR_DRUG_ABUSE', 'CMR_HTN_CX', 'CMR_HTN_UNCX', 'CMR_LUNG_CHRONIC', 'CMR_OBESE', 'CMR_PERIVASC', 'CMR_THYROID_HYPO', 'CMR_THYROID_OTH', 'CMR_VERSION', 'DXCCSR_Default_DX1', 'DXCCSR_BLD001', 'DXCCSR_BLD002', 'DXCCSR_BLD003', 'DXCCSR_BLD004', 'DXCCSR_BLD005', 'DXCCSR_BLD006', 'DXCCSR_BLD007', 'DXCCSR_BLD008', 'DXCCSR_BLD009', 'DXCCSR_BLD010', 'DXCCSR_CIR001', 'DXCCSR_CIR002', 'DXCCSR_CIR003', 'DXCCSR_CIR004', 'DXCCSR_CIR005', 'DXCCSR_CIR006', 'DXCCSR_CIR007', 'DXCCSR_CIR008', 'DXCCSR_CIR009', 'DXCCSR_CIR010', 'DXCCSR_CIR011', 'DXCCSR_CIR012', 'DXCCSR_CIR013', 'DXCCSR_CIR014', 'DXCCSR_CIR015', 'DXCCSR_CIR016', 'DXCCSR_CIR017', 'DXCCSR_CIR018', 'DXCCSR_CIR019', 'DXCCSR_CIR020', 'DXCCSR_CIR021', 'DXCCSR_CIR022', 'DXCCSR_CIR023', 'DXCCSR_CIR024', 'DXCCSR_CIR025', 'DXCCSR_CIR026', 'DXCCSR_CIR027', 'DXCCSR_CIR028', 'DXCCSR_CIR029', 'DXCCSR_CIR030', 'DXCCSR_CIR031', 'DXCCSR_CIR032', 'DXCCSR_CIR033', 'DXCCSR_CIR034', 'DXCCSR_CIR035', 'DXCCSR_CIR036', 'DXCCSR_CIR037', 'DXCCSR_CIR038', 'DXCCSR_CIR039', 'DXCCSR_DIG001', 'DXCCSR_DIG002', 'DXCCSR_DIG003', 'DXCCSR_DIG004', 'DXCCSR_DIG005', 'DXCCSR_DIG006', 'DXCCSR_DIG007', 'DXCCSR_DIG008', 'DXCCSR_DIG009', 'DXCCSR_DIG010', 'DXCCSR_DIG011', 'DXCCSR_DIG012', 'DXCCSR_DIG013', 'DXCCSR_DIG014', 'DXCCSR_DIG015', 'DXCCSR_DIG016', 'DXCCSR_DIG017', 'DXCCSR_DIG018', 'DXCCSR_DIG019', 'DXCCSR_DIG020', 'DXCCSR_DIG021', 'DXCCSR_DIG022', 'DXCCSR_DIG023', 'DXCCSR_DIG024', 'DXCCSR_DIG025', 'DXCCSR_EAR001', 'DXCCSR_EAR002', 'DXCCSR_EAR003', 'DXCCSR_EAR004', 'DXCCSR_EAR005', 'DXCCSR_EAR006', 'DXCCSR_END001', 'DXCCSR_END002', 'DXCCSR_END003', 'DXCCSR_END004', 'DXCCSR_END005', 'DXCCSR_END006', 'DXCCSR_END007', 'DXCCSR_END008', 'DXCCSR_END009', 'DXCCSR_END010', 'DXCCSR_END011', 'DXCCSR_END012', 'DXCCSR_END013', 'DXCCSR_END014', 'DXCCSR_END015', 'DXCCSR_END016', 'DXCCSR_END017', 'DXCCSR_EXT001', 'DXCCSR_EXT002', 'DXCCSR_EXT003', 'DXCCSR_EXT004', 'DXCCSR_EXT005', 'DXCCSR_EXT006', 'DXCCSR_EXT007', 'DXCCSR_EXT008', 'DXCCSR_EXT009', 'DXCCSR_EXT010', 'DXCCSR_EXT011', 'DXCCSR_EXT012', 'DXCCSR_EXT013', 'DXCCSR_EXT014', 'DXCCSR_EXT015', 'DXCCSR_EXT016', 'DXCCSR_EXT017', 'DXCCSR_EXT018', 'DXCCSR_EXT019', 'DXCCSR_EXT020', 'DXCCSR_EXT021', 'DXCCSR_EXT022', 'DXCCSR_EXT023', 'DXCCSR_EXT024', 'DXCCSR_EXT025', 'DXCCSR_EXT026', 'DXCCSR_EXT027', 'DXCCSR_EXT028', 'DXCCSR_EXT029', 'DXCCSR_EXT030', 'DXCCSR_EYE001', 'DXCCSR_EYE002', 'DXCCSR_EYE003', 'DXCCSR_EYE004', 'DXCCSR_EYE005', 'DXCCSR_EYE006', 'DXCCSR_EYE007', 'DXCCSR_EYE008', 'DXCCSR_EYE009', 'DXCCSR_EYE010', 'DXCCSR_EYE011', 'DXCCSR_EYE012', 'DXCCSR_FAC001', 'DXCCSR_FAC002', 'DXCCSR_FAC003', 'DXCCSR_FAC004', 'DXCCSR_FAC005', 'DXCCSR_FAC006', 'DXCCSR_FAC007', 'DXCCSR_FAC008', 'DXCCSR_FAC009', 'DXCCSR_FAC010', 'DXCCSR_FAC011', 'DXCCSR_FAC012', 'DXCCSR_FAC013', 'DXCCSR_FAC014', 'DXCCSR_FAC015', 'DXCCSR_FAC016', 'DXCCSR_FAC017', 'DXCCSR_FAC018', 'DXCCSR_FAC019', 'DXCCSR_FAC020', 'DXCCSR_FAC021', 'DXCCSR_FAC022', 'DXCCSR_FAC023', 'DXCCSR_FAC024', 'DXCCSR_FAC025', 'DXCCSR_GEN001', 'DXCCSR_GEN002', 'DXCCSR_GEN003', 'DXCCSR_GEN004', 'DXCCSR_GEN005', 'DXCCSR_GEN006', 'DXCCSR_GEN007', 'DXCCSR_GEN008', 'DXCCSR_GEN009', 'DXCCSR_GEN010', 'DXCCSR_GEN011', 'DXCCSR_GEN012', 'DXCCSR_GEN013', 'DXCCSR_GEN014', 'DXCCSR_GEN015', 'DXCCSR_GEN016', 'DXCCSR_GEN017', 'DXCCSR_GEN018', 'DXCCSR_GEN019', 'DXCCSR_GEN020', 'DXCCSR_GEN021', 'DXCCSR_GEN022', 'DXCCSR_GEN023', 'DXCCSR_GEN024', 'DXCCSR_GEN025', 'DXCCSR_GEN026', 'DXCCSR_INF001', 'DXCCSR_INF002', 'DXCCSR_INF003', 'DXCCSR_INF004', 'DXCCSR_INF005', 'DXCCSR_INF006', 'DXCCSR_INF007', 'DXCCSR_INF008', 'DXCCSR_INF009', 'DXCCSR_INF010', 'DXCCSR_INF011', 'DXCCSR_INF012', 'DXCCSR_INJ001', 'DXCCSR_INJ002', 'DXCCSR_INJ003', 'DXCCSR_INJ004', 'DXCCSR_INJ005', 'DXCCSR_INJ006', 'DXCCSR_INJ007', 'DXCCSR_INJ008', 'DXCCSR_INJ009', 'DXCCSR_INJ010', 'DXCCSR_INJ011', 'DXCCSR_INJ012', 'DXCCSR_INJ013', 'DXCCSR_INJ014', 'DXCCSR_INJ015', 'DXCCSR_INJ016', 'DXCCSR_INJ017', 'DXCCSR_INJ018', 'DXCCSR_INJ019', 'DXCCSR_INJ020', 'DXCCSR_INJ021', 'DXCCSR_INJ022', 'DXCCSR_INJ023', 'DXCCSR_INJ024', 'DXCCSR_INJ025', 'DXCCSR_INJ026', 'DXCCSR_INJ027', 'DXCCSR_INJ028', 'DXCCSR_INJ029', 'DXCCSR_INJ030', 'DXCCSR_INJ031', 'DXCCSR_INJ032', 'DXCCSR_INJ033', 'DXCCSR_INJ034', 'DXCCSR_INJ035', 'DXCCSR_INJ036', 'DXCCSR_INJ037', 'DXCCSR_INJ038', 'DXCCSR_INJ039', 'DXCCSR_INJ040', 'DXCCSR_INJ041', 'DXCCSR_INJ042', 'DXCCSR_INJ043', 'DXCCSR_INJ044', 'DXCCSR_INJ045', 'DXCCSR_INJ046', 'DXCCSR_INJ047', 'DXCCSR_INJ048', 'DXCCSR_INJ049', 'DXCCSR_INJ050', 'DXCCSR_INJ051', 'DXCCSR_INJ052', 'DXCCSR_INJ053', 'DXCCSR_INJ054', 'DXCCSR_INJ055', 'DXCCSR_INJ056', 'DXCCSR_INJ057', 'DXCCSR_INJ058', 'DXCCSR_INJ059', 'DXCCSR_INJ060', 'DXCCSR_INJ061', 'DXCCSR_INJ062', 'DXCCSR_INJ063', 'DXCCSR_INJ064', 'DXCCSR_INJ065', 'DXCCSR_INJ066', 'DXCCSR_INJ067', 'DXCCSR_INJ068', 'DXCCSR_INJ069', 'DXCCSR_INJ070', 'DXCCSR_INJ071', 'DXCCSR_INJ072', 'DXCCSR_INJ073', 'DXCCSR_INJ074', 'DXCCSR_INJ075', 'DXCCSR_INJ076', 'DXCCSR_MAL001', 'DXCCSR_MAL002', 'DXCCSR_MAL003', 'DXCCSR_MAL004', 'DXCCSR_MAL005', 'DXCCSR_MAL006', 'DXCCSR_MAL007', 'DXCCSR_MAL008', 'DXCCSR_MAL009', 'DXCCSR_MAL010', 'DXCCSR_MBD001', 'DXCCSR_MBD002', 'DXCCSR_MBD003', 'DXCCSR_MBD004', 'DXCCSR_MBD005', 'DXCCSR_MBD006', 'DXCCSR_MBD007', 'DXCCSR_MBD008', 'DXCCSR_MBD009', 'DXCCSR_MBD010', 'DXCCSR_MBD011', 'DXCCSR_MBD012', 'DXCCSR_MBD013', 'DXCCSR_MBD014', 'DXCCSR_MBD017', 'DXCCSR_MBD018', 'DXCCSR_MBD019', 'DXCCSR_MBD020', 'DXCCSR_MBD021', 'DXCCSR_MBD022', 'DXCCSR_MBD023', 'DXCCSR_MBD024', 'DXCCSR_MBD025', 'DXCCSR_MBD026', 'DXCCSR_MBD027', 'DXCCSR_MBD028', 'DXCCSR_MBD029', 'DXCCSR_MBD030', 'DXCCSR_MBD031', 'DXCCSR_MBD032', 'DXCCSR_MBD033', 'DXCCSR_MBD034', 'DXCCSR_MUS001', 'DXCCSR_MUS002', 'DXCCSR_MUS003', 'DXCCSR_MUS004', 'DXCCSR_MUS005', 'DXCCSR_MUS006', 'DXCCSR_MUS007', 'DXCCSR_MUS008', 'DXCCSR_MUS009', 'DXCCSR_MUS010', 'DXCCSR_MUS011', 'DXCCSR_MUS012', 'DXCCSR_MUS013', 'DXCCSR_MUS014', 'DXCCSR_MUS015', 'DXCCSR_MUS016', 'DXCCSR_MUS017', 'DXCCSR_MUS018', 'DXCCSR_MUS019', 'DXCCSR_MUS020', 'DXCCSR_MUS021', 'DXCCSR_MUS022', 'DXCCSR_MUS023', 'DXCCSR_MUS024', 'DXCCSR_MUS025', 'DXCCSR_MUS026', 'DXCCSR_MUS027', 'DXCCSR_MUS028', 'DXCCSR_MUS029', 'DXCCSR_MUS030', 'DXCCSR_MUS031', 'DXCCSR_MUS032', 'DXCCSR_MUS033', 'DXCCSR_MUS034', 'DXCCSR_MUS035', 'DXCCSR_MUS036', 'DXCCSR_MUS037', 'DXCCSR_MUS038', 'DXCCSR_NEO001', 'DXCCSR_NEO002', 'DXCCSR_NEO003', 'DXCCSR_NEO004', 'DXCCSR_NEO005', 'DXCCSR_NEO006', 'DXCCSR_NEO007', 'DXCCSR_NEO008', 'DXCCSR_NEO009', 'DXCCSR_NEO010', 'DXCCSR_NEO011', 'DXCCSR_NEO012', 'DXCCSR_NEO013', 'DXCCSR_NEO014', 'DXCCSR_NEO015', 'DXCCSR_NEO016', 'DXCCSR_NEO017', 'DXCCSR_NEO018', 'DXCCSR_NEO019', 'DXCCSR_NEO020', 'DXCCSR_NEO021', 'DXCCSR_NEO022', 'DXCCSR_NEO023', 'DXCCSR_NEO024', 'DXCCSR_NEO025', 'DXCCSR_NEO026', 'DXCCSR_NEO027', 'DXCCSR_NEO028', 'DXCCSR_NEO029', 'DXCCSR_NEO030', 'DXCCSR_NEO031', 'DXCCSR_NEO032', 'DXCCSR_NEO033', 'DXCCSR_NEO034', 'DXCCSR_NEO035', 'DXCCSR_NEO036', 'DXCCSR_NEO037', 'DXCCSR_NEO038', 'DXCCSR_NEO039', 'DXCCSR_NEO040', 'DXCCSR_NEO041', 'DXCCSR_NEO042', 'DXCCSR_NEO043', 'DXCCSR_NEO044', 'DXCCSR_NEO045', 'DXCCSR_NEO046', 'DXCCSR_NEO047', 'DXCCSR_NEO048', 'DXCCSR_NEO049', 'DXCCSR_NEO050', 'DXCCSR_NEO051', 'DXCCSR_NEO052', 'DXCCSR_NEO053', 'DXCCSR_NEO054', 'DXCCSR_NEO055', 'DXCCSR_NEO056', 'DXCCSR_NEO057', 'DXCCSR_NEO058', 'DXCCSR_NEO059', 'DXCCSR_NEO060', 'DXCCSR_NEO061', 'DXCCSR_NEO062', 'DXCCSR_NEO063', 'DXCCSR_NEO064', 'DXCCSR_NEO065', 'DXCCSR_NEO066', 'DXCCSR_NEO067', 'DXCCSR_NEO068', 'DXCCSR_NEO069', 'DXCCSR_NEO070', 'DXCCSR_NEO071', 'DXCCSR_NEO072', 'DXCCSR_NEO073', 'DXCCSR_NEO074', 'DXCCSR_NVS001', 'DXCCSR_NVS002', 'DXCCSR_NVS003', 'DXCCSR_NVS004', 'DXCCSR_NVS005', 'DXCCSR_NVS006', 'DXCCSR_NVS007', 'DXCCSR_NVS008', 'DXCCSR_NVS009', 'DXCCSR_NVS010', 'DXCCSR_NVS011', 'DXCCSR_NVS012', 'DXCCSR_NVS013', 'DXCCSR_NVS014', 'DXCCSR_NVS015', 'DXCCSR_NVS016', 'DXCCSR_NVS017', 'DXCCSR_NVS018', 'DXCCSR_NVS019', 'DXCCSR_NVS020', 'DXCCSR_NVS021', 'DXCCSR_NVS022', 'DXCCSR_PNL001', 'DXCCSR_PNL002', 'DXCCSR_PNL003', 'DXCCSR_PNL004', 'DXCCSR_PNL005', 'DXCCSR_PNL006', 'DXCCSR_PNL007', 'DXCCSR_PNL008', 'DXCCSR_PNL009', 'DXCCSR_PNL010', 'DXCCSR_PNL011', 'DXCCSR_PNL012', 'DXCCSR_PNL013', 'DXCCSR_PNL014', 'DXCCSR_PNL015', 'DXCCSR_PRG001', 'DXCCSR_PRG002', 'DXCCSR_PRG003', 'DXCCSR_PRG004', 'DXCCSR_PRG005', 'DXCCSR_PRG006', 'DXCCSR_PRG007', 'DXCCSR_PRG008', 'DXCCSR_PRG009', 'DXCCSR_PRG010', 'DXCCSR_PRG011', 'DXCCSR_PRG012', 'DXCCSR_PRG013', 'DXCCSR_PRG014', 'DXCCSR_PRG015', 'DXCCSR_PRG016', 'DXCCSR_PRG017', 'DXCCSR_PRG018', 'DXCCSR_PRG019', 'DXCCSR_PRG020', 'DXCCSR_PRG021', 'DXCCSR_PRG022', 'DXCCSR_PRG023', 'DXCCSR_PRG024', 'DXCCSR_PRG025', 'DXCCSR_PRG026', 'DXCCSR_PRG027', 'DXCCSR_PRG028', 'DXCCSR_PRG029', 'DXCCSR_PRG030', 'DXCCSR_RSP001', 'DXCCSR_RSP002', 'DXCCSR_RSP003', 'DXCCSR_RSP004', 'DXCCSR_RSP005', 'DXCCSR_RSP006', 'DXCCSR_RSP007', 'DXCCSR_RSP008', 'DXCCSR_RSP009', 'DXCCSR_RSP010', 'DXCCSR_RSP011', 'DXCCSR_RSP012', 'DXCCSR_RSP013', 'DXCCSR_RSP014', 'DXCCSR_RSP015', 'DXCCSR_RSP016', 'DXCCSR_RSP017', 'DXCCSR_SKN001', 'DXCCSR_SKN002', 'DXCCSR_SKN003', 'DXCCSR_SKN004', 'DXCCSR_SKN005', 'DXCCSR_SKN006', 'DXCCSR_SKN007', 'DXCCSR_SYM001', 'DXCCSR_SYM002', 'DXCCSR_SYM003', 'DXCCSR_SYM004', 'DXCCSR_SYM005', 'DXCCSR_SYM006', 'DXCCSR_SYM007', 'DXCCSR_SYM008', 'DXCCSR_SYM009', 'DXCCSR_SYM010', 'DXCCSR_SYM011', 'DXCCSR_SYM012', 'DXCCSR_SYM013', 'DXCCSR_SYM014', 'DXCCSR_SYM015', 'DXCCSR_SYM016', 'DXCCSR_SYM017', 'DXCCSR_VERSION', 'AGEGRP', 'AGEGRP2']\n",
            "\n",
            "First 3 rows:\n",
            "   KEY_NASS  HOSP_NASS  HOSP_TEACH  HOSP_LOCATION  HOSP_LOCTEACH  HOSP_REGION  \\\n",
            "0  90000001      40053           1              1              3            4   \n",
            "1  90000002      20162           0              1              2            2   \n",
            "2  90000003      30223           1              1              3            3   \n",
            "\n",
            "   HOSP_BEDSIZE_CAT    DISCWT  NASS_STRATUM  N_DISC_U  ...  DXCCSR_SYM011  \\\n",
            "0                 2  1.579073             9    321406  ...              0   \n",
            "1                 2  1.031092            49    152635  ...              0   \n",
            "2                 3  1.245274             7    837566  ...              0   \n",
            "\n",
            "   DXCCSR_SYM012  DXCCSR_SYM013  DXCCSR_SYM014  DXCCSR_SYM015  DXCCSR_SYM016  \\\n",
            "0              0              0              0              0              0   \n",
            "1              0              0              0              0              0   \n",
            "2              0              0              0              0              0   \n",
            "\n",
            "   DXCCSR_SYM017  DXCCSR_VERSION  AGEGRP  AGEGRP2  \n",
            "0              0          2022.1    0-17     0-17  \n",
            "1              0          2022.1   18-64    40-54  \n",
            "2              0          2022.1   18-64    55-64  \n",
            "\n",
            "[3 rows x 675 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "class DataLoader:\n",
        "    def __init__(self):\n",
        "        self.base_path = Path('/content') if env_manager.is_colab else Path.home()\n",
        "        self.data_dir = self.base_path / 'data'\n",
        "        self.data_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    def load_data(self):\n",
        "        \"\"\"Load data based on configuration\"\"\"\n",
        "        loaders = {\n",
        "            'github': self._load_github,\n",
        "            'local': self._load_local,\n",
        "            'gcs': self._load_gcs,\n",
        "            'drive': self._load_drive\n",
        "        }\n",
        "\n",
        "        if DATA_SOURCE not in loaders:\n",
        "            raise ValueError(f\"Invalid DATA_SOURCE: {DATA_SOURCE}\")\n",
        "\n",
        "        print(f\"Loading data from: {DATA_SOURCE.upper()}\")\n",
        "        return loaders[DATA_SOURCE]()\n",
        "\n",
        "    def _load_github(self):\n",
        "        \"\"\"Load from GitHub releases\"\"\"\n",
        "        response = requests.get(GITHUB_URL, timeout=60)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        data_path = self.data_dir / \"nass_data.csv\"\n",
        "        data_path.write_bytes(response.content)\n",
        "\n",
        "        print(f\"✓ Downloaded from GitHub ({response.headers.get('content-length', 'unknown')} bytes)\")\n",
        "        return pd.read_csv(data_path)\n",
        "\n",
        "    def _load_local(self):\n",
        "        \"\"\"Load from local file\"\"\"\n",
        "        search_paths = [\n",
        "            self.base_path / LOCAL_FILENAME,\n",
        "            self.data_dir / LOCAL_FILENAME,\n",
        "            Path.cwd() / LOCAL_FILENAME\n",
        "        ]\n",
        "\n",
        "        for path in search_paths:\n",
        "            if path.exists():\n",
        "                print(f\"✓ Found local file: {path}\")\n",
        "                return pd.read_csv(path)\n",
        "\n",
        "        raise FileNotFoundError(f\"File not found in: {[str(p) for p in search_paths]}\")\n",
        "\n",
        "    def _load_gcs(self):\n",
        "        \"\"\"Load from Google Cloud Storage\"\"\"\n",
        "        from google.cloud import storage\n",
        "\n",
        "        # Smart authentication\n",
        "        if Path(GCS_SERVICE_ACCOUNT_KEY).exists():\n",
        "            client = storage.Client.from_service_account_json(GCS_SERVICE_ACCOUNT_KEY)\n",
        "        else:\n",
        "            client = storage.Client()  # Use default credentials\n",
        "\n",
        "        bucket = client.bucket(GCS_BUCKET)\n",
        "        blob = bucket.blob(GCS_BLOB)\n",
        "\n",
        "        data_path = self.data_dir / \"nass_data.csv\"\n",
        "        blob.download_to_filename(data_path)\n",
        "\n",
        "        print(f\"✓ Downloaded from GCS: {GCS_BUCKET}/{GCS_BLOB}\")\n",
        "        return pd.read_csv(data_path)\n",
        "\n",
        "    def _load_drive(self):\n",
        "        \"\"\"Load from Google Drive (Colab only)\"\"\"\n",
        "        if not env_manager.is_colab:\n",
        "            raise RuntimeError(\"Drive loading only available in Google Colab\")\n",
        "\n",
        "        drive_path = Path(DRIVE_PATH)\n",
        "        if not drive_path.exists():\n",
        "            raise FileNotFoundError(f\"Drive file not found: {DRIVE_PATH}\")\n",
        "\n",
        "        print(f\"✓ Loading from Google Drive: {DRIVE_PATH}\")\n",
        "        return pd.read_csv(drive_path)\n",
        "\n",
        "# Load data\n",
        "try:\n",
        "    loader = DataLoader()\n",
        "    df = loader.load_data()\n",
        "\n",
        "    print(f\"✅ Data loaded successfully!\")\n",
        "    print(f\"   Shape: {df.shape}\")\n",
        "    print(f\"   Memory: {df.memory_usage(deep=True).sum() / 1e6:.1f} MB\")\n",
        "\n",
        "    if VERBOSE_PRINTS:\n",
        "        print(f\"\\nColumns: {list(df.columns)}\")\n",
        "        print(f\"\\nFirst 3 rows:\")\n",
        "        print(df.head(3))\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Data loading failed: {e}\")\n",
        "    print(f\"💡 Try changing DATA_SOURCE or check file paths\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxQ5fG5grPrj"
      },
      "source": [
        "Check if data has been loaded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "FqUzCuZOrPrj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Data verified: 139,233 rows x 675 columns\n",
            "✅ Ready for R analysis\n"
          ]
        }
      ],
      "source": [
        "# Verify data is available before R processing\n",
        "try:\n",
        "    if 'df' not in globals():\n",
        "        print(\"❌ Data not loaded!\")\n",
        "        print(\"💡 Please run the 'Data Loading' section first (cell 12)\")\n",
        "        print(\"   This will create the 'df' variable needed for R analysis\")\n",
        "        raise NameError(\"df variable not found - run data loading first\")\n",
        "\n",
        "    print(f\"✅ Data verified: {df.shape[0]:,} rows x {df.shape[1]} columns\")\n",
        "    print(\"✅ Ready for R analysis\")\n",
        "\n",
        "except NameError as e:\n",
        "    print(f\"❌ {e}\")\n",
        "    print(\"\\n🔄 Quick fix: Run these cells in order:\")\n",
        "    print(\"   1. Configuration (cell 5)\")\n",
        "    print(\"   2. Environment Setup (cell 7)\")\n",
        "    print(\"   3. Data Loading (cell 12)\")\n",
        "    print(\"   4. Then continue with R analysis\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3j3Ms-OArPrj"
      },
      "source": [
        "## 5. Complete Data Preprocessing\n",
        "\n",
        "Streamlined preprocessing: remove variables, clean data types, and create new variables - in Python prior to passing to R for efficiency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "GQzhWzohrPrj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Complete preprocessing: removing variables + cleaning data types...\n",
            "Original shape: (139233, 675)\n",
            "\n",
            "1 Removing unnecessary variables...\n",
            "   📊 Found 600 columns to drop\n",
            "   🗑️  Patterns: CPTCCS2-30, CPT2-30, all DXCCSR_*\n",
            "   ✅ Reduced from 675 to 75 columns\n",
            "\n",
            "2️⃣ Cleaning data types for rpy2 compatibility...\n",
            "   ✅ Converted 23 object columns to strings\n",
            "   ✅ Converted 23 object columns to strings\n",
            "   ✅ Cleaned inf values in 3 float columns\n",
            "\n",
            "3️⃣ Creating analytical variables...\n",
            "   ✅ Created a race indicator boolean\n",
            "   ✅ Created AGE_GROUP categories\n",
            "   ✅ Created INCOME_LEVEL labels\n",
            "\n",
            "✅ PREPROCESSING COMPLETE!\n",
            "📊 Final shape: (139233, 78)\n",
            "💾 Ready for R transfer!\n",
            "   ✅ Cleaned inf values in 3 float columns\n",
            "\n",
            "3️⃣ Creating analytical variables...\n",
            "   ✅ Created a race indicator boolean\n",
            "   ✅ Created AGE_GROUP categories\n",
            "   ✅ Created INCOME_LEVEL labels\n",
            "\n",
            "✅ PREPROCESSING COMPLETE!\n",
            "📊 Final shape: (139233, 78)\n",
            "💾 Ready for R transfer!\n"
          ]
        }
      ],
      "source": [
        "# Data Preprocessing in Python (before R transfer)\n",
        "print(\"Complete preprocessing: removing variables + cleaning data types...\")\n",
        "print(f\"Original shape: {df.shape}\")\n",
        "\n",
        "# ===== 1. REMOVE UNNECESSARY VARIABLES =====\n",
        "print(\"\\n1 Removing unnecessary variables...\")\n",
        "\n",
        "# Smart pattern-based removal in pandas (much faster than R)\n",
        "drop_patterns = [\n",
        "    r'^CPTCCS[2-9]$',      # CPTCCS2-CPTCCS9\n",
        "    r'^CPTCCS[1-3][0-9]$', # CPTCCS10-30\n",
        "    r'^CPT[2-9]$',         # CPT2-CPT9\n",
        "    r'^CPT[1-3][0-9]$',    # CPT10-30\n",
        "    r'^DXCCSR_',           # All DXCCSR columns (500+)\n",
        "]\n",
        "\n",
        "# Find columns to drop using vectorized operations\n",
        "drop_cols = []\n",
        "for pattern in drop_patterns:\n",
        "    matches = df.columns[df.columns.str.match(pattern)].tolist()\n",
        "    drop_cols.extend(matches)\n",
        "\n",
        "# Remove duplicates\n",
        "drop_cols = list(set(drop_cols))\n",
        "\n",
        "print(f\"   📊 Found {len(drop_cols)} columns to drop\")\n",
        "print(f\"   🗑️  Patterns: CPTCCS2-30, CPT2-30, all DXCCSR_*\")\n",
        "\n",
        "# Drop the columns\n",
        "df = df.drop(columns=drop_cols)\n",
        "print(f\"   ✅ Reduced from {df.shape[1] + len(drop_cols)} to {df.shape[1]} columns\")\n",
        "\n",
        "# ===== 2. CLEAN DATA TYPES FOR rpy2 =====\n",
        "print(\"\\n2️⃣ Cleaning data types for rpy2 compatibility...\")\n",
        "\n",
        "# Convert all object columns to strings (prevents mixed-type issues)\n",
        "object_columns = df.select_dtypes(include=['object']).columns\n",
        "if len(object_columns) > 0:\n",
        "    for col in object_columns:\n",
        "        df[col] = df[col].astype(str)\n",
        "    print(f\"   ✅ Converted {len(object_columns)} object columns to strings\")\n",
        "\n",
        "# Handle NaN/inf values consistently\n",
        "df = df.fillna('')  # Replace NaN with empty strings\n",
        "float_cols = df.select_dtypes(include=['float64']).columns\n",
        "if len(float_cols) > 0:\n",
        "    df[float_cols] = df[float_cols].replace([float('inf'), float('-inf')], '')\n",
        "    print(f\"   ✅ Cleaned inf values in {len(float_cols)} float columns\")\n",
        "\n",
        "# ===== 3. CREATE KEY ANALYTICAL VARIABLES IN PANDAS =====\n",
        "print(\"\\n3️⃣ Creating analytical variables...\")\n",
        "\n",
        "# Create WHITE indicator (1=White, 0=Non-White)\n",
        "if 'RACE' in df.columns:\n",
        "    df['WHITE'] = (df['RACE'].astype(str) == '1').astype(int)\n",
        "    print(\"   ✅ Created a race indicator boolean\")\n",
        "\n",
        "# Create age groups\n",
        "if 'AGE' in df.columns:\n",
        "    df['AGE'] = pd.to_numeric(df['AGE'], errors='coerce')  # Ensure numeric\n",
        "    df['AGE_GROUP'] = pd.cut(df['AGE'],\n",
        "                            bins=[0, 18, 30, 45, 65, float('inf')],\n",
        "                            labels=['0-17', '18-29', '30-44', '45-64', '65+'],\n",
        "                            right=False)\n",
        "    df['AGE_GROUP'] = df['AGE_GROUP'].astype(str)  # Convert to string for R\n",
        "    print(\"   ✅ Created AGE_GROUP categories\")\n",
        "\n",
        "# Create income level labels\n",
        "if 'ZIPINC_QRTL' in df.columns:\n",
        "    income_map = {1: 'Q1-Lowest', 2: 'Q2', 3: 'Q3', 4: 'Q4-Highest'}\n",
        "    df['INCOME_LEVEL'] = df['ZIPINC_QRTL'].astype(str).map(lambda x: income_map.get(int(x) if x.isdigit() else 0, 'Unknown'))\n",
        "    print(\"   ✅ Created INCOME_LEVEL labels\")\n",
        "\n",
        "# Ensure key numeric variables are properly typed\n",
        "numeric_vars = ['AGE', 'DISCWT', 'TOTCHG']\n",
        "for var in numeric_vars:\n",
        "    if var in df.columns:\n",
        "        df[var] = pd.to_numeric(df[var], errors='coerce')\n",
        "\n",
        "print(f\"\\n✅ PREPROCESSING COMPLETE!\")\n",
        "print(f\"📊 Final shape: {df.shape}\")\n",
        "print(f\"💾 Ready for R transfer!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1smsFldXrPrj"
      },
      "source": [
        "## 6. Final R Transfer & Processing\n",
        "\n",
        "Transfer the clean data to R and apply any final R-specific formatting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "10dad708"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<U+2705> R Complete: 139233 rows, 78 cols, 58.4 MB\n",
            "Converted 9 factors + 2 booleans\n",
            "\n",
            "Columns:\n",
            " [1] \"KEY_NASS\"            \"HOSP_NASS\"           \"HOSP_TEACH\"         \n",
            " [4] \"HOSP_LOCATION\"       139233 rows, 78 cols, 58.4 MB\n",
            "Converted 9 factors + 2 booleans\n",
            "\n",
            "Columns:\n",
            " [1] \"KEY_NASS\"            \"HOSP_NASS\"           \"HOSP_TEACH\"         \n",
            " [4] \"HOSP_LOCATION\"       \"HOSP_LOCTEACH\"       \"HOSP_REGION\"        \n",
            " [7] \"HOSP_BEDSIZE_CAT\"    \"DISCWT\"              \"NASS_STRATUM\"       \n",
            "[10] \"N_DISC_U\"            \"N_HOSP_U\"            \"S_DISC_U\"            \"HOSP_LOCTEACH\"       \"HOSP_REGION\"        \n",
            " [7] \"HOSP_BEDSIZE_CAT\"    \"DISCWT\"              \"NASS_STRATUM\"       \n",
            "[10] \"N_DISC_U\"            \"N_HOSP_U\"            \"S_DISC_U\"           \n",
            "[13] \"S_HOSP_U\"            \"TOTAL_AS_ENCOUNTERS\" \"YEAR\"               \n",
            "[16] \"AGE\"                 \"FEMALE\"              \"PL_NCHS\"            \n",
            "[19] \"ZIPINC_QRTL\"         \"AMONTH\"              \"AWEEKEND\"           \n",
            "[22] \"DQTR\"                \"PAY1\"                \"DISPUNIFORM\"        \n",
            "[25] \"TOTCHG\"             \n",
            "[13] \"S_HOSP_U\"            \"TOTAL_AS_ENCOUNTERS\" \"YEAR\"               \n",
            "[16] \"AGE\"                 \"FEMALE\"              \"PL_NCHS\"            \n",
            "[19] \"ZIPINC_QRTL\"         \"AMONTH\"              \"AWEEKEND\"           \n",
            "[22] \"DQTR\"                \"PAY1\"                \"DISPUNIFORM\"        \n",
            "[25] \"TOTCHG\"              \"NCPT_INSCOPE\"        \"CPTCCS1\"            \n",
            "[28] \"CPT1\"                \"I10_NDX\"             \"I10_DX1\"            \n",
            "[31] \"I10_DX2\"             \"I10_DX3\"             \"I10_DX4\"            \n",
            "[34] \"I10_DX5\"             \"I10_DX6\"             \"I10_DX7\"            \n",
            "[37] \"NCPT_INSCOPE\"        \"CPTCCS1\"            \n",
            "[28] \"CPT1\"                \"I10_NDX\"             \"I10_DX1\"            \n",
            "[31] \"I10_DX2\"             \"I10_DX3\"             \"I10_DX4\"            \n",
            "[34] \"I10_DX5\"             \"I10_DX6\"             \"I10_DX7\"            \n",
            "[37] \"I10_DX8\"             \"I10_DX9\"             \"I10_DX10\"           \n",
            "[40] \"I10_DX11\"            \"I10_DX12\"            \"I10_DX13\"           \n",
            "[43] \"I10_DX14\"            \"I10_DX15\"            \"I10_DX16\"           \n",
            "[46] \"I10_DX17\"            \"I10_DX18\"            \"I10_DX19\"            \"I10_DX8\"             \"I10_DX9\"             \"I10_DX10\"           \n",
            "[40] \"I10_DX11\"            \"I10_DX12\"            \"I10_DX13\"           \n",
            "[43] \"I10_DX14\"            \"I10_DX15\"            \"I10_DX16\"           \n",
            "[46] \"I10_DX17\"            \"I10_DX18\"            \"I10_DX19\"           \n",
            "[49] \"I10_DX20\"            \"RACE\"                \"I10_INJURY\"         \n",
            "[52] \"I10_MULTINJURY\"      \"CMR_AIDS\"            \"CMR_ALCOHOL\"        \n",
            "[55] \"CMR_AUTOIMMUNE\"      \"CMR_CANCER_LYMPH\"    \"CMR_CANCER_LEUK\"    \n",
            "[58] \"CMR_CANCER_METS\"    \n",
            "[49] \"I10_DX20\"            \"RACE\"                \"I10_INJURY\"         \n",
            "[52] \"I10_MULTINJURY\"      \"CMR_AIDS\"            \"CMR_ALCOHOL\"        \n",
            "[55] \"CMR_AUTOIMMUNE\"      \"CMR_CANCER_LYMPH\"    \"CMR_CANCER_LEUK\"    \n",
            "[58] \"CMR_CANCER_METS\"     \"CMR_CANCER_NSITU\"    \"CMR_CANCER_SOLID\"   \n",
            "[61] \"CMR_DEMENTIA\"        \"CMR_DEPRESS\"         \"CMR_DIAB_UNCX\"      \n",
            "[64] \"CMR_DIAB_CX\"         \"CMR_DRUG_ABUSE\"      \"CMR_HTN_CX\"         \n",
            "[67] \"CMR_HTN_UNCX\"        \"CMR_CANCER_NSITU\"    \"CMR_CANCER_SOLID\"   \n",
            "[61] \"CMR_DEMENTIA\"        \"CMR_DEPRESS\"         \"CMR_DIAB_UNCX\"      \n",
            "[64] \"CMR_DIAB_CX\"         \"CMR_DRUG_ABUSE\"      \"CMR_HTN_CX\"         \n",
            "[67] \"CMR_HTN_UNCX\"        \"CMR_LUNG_CHRONIC\"    \"CMR_OBESE\"          \n",
            "[70] \"CMR_PERIVASC\"        \"CMR_THYROID_HYPO\"    \"CMR_THYROID_OTH\"    \n",
            "[73] \"CMR_VERSION\"         \"AGEGRP\"              \"AGEGRP2\"            \n",
            "[76] \"WHITE\"               \"AGE_GROUP\"           \"INCOME_LEVEL\"       \n",
            "Ready for analysis!\n",
            " \"CMR_LUNG_CHRONIC\"    \"CMR_OBESE\"          \n",
            "[70] \"CMR_PERIVASC\"        \"CMR_THYROID_HYPO\"    \"CMR_THYROID_OTH\"    \n",
            "[73] \"CMR_VERSION\"         \"AGEGRP\"              \"AGEGRP2\"            \n",
            "[76] \"WHITE\"               \"AGE_GROUP\"           \"INCOME_LEVEL\"       \n",
            "Ready for analysis!\n"
          ]
        }
      ],
      "source": [
        "%%R -i df -i VERBOSE_PRINTS\n",
        "\n",
        "# Convert to data.table and apply R types\n",
        "NASS <- as.data.table(df)\n",
        "\n",
        "# Factor variables\n",
        "factor_vars <- c(\"ZIPINC_QRTL\", \"PAY1\", \"CPTCCS1\", \"HOSP_LOCATION\",\n",
        "                 \"HOSP_TEACH\", \"HOSP_NASS\", \"RACE\", \"AGE_GROUP\", \"INCOME_LEVEL\")\n",
        "existing_factors <- factor_vars[factor_vars %in% names(NASS)]\n",
        "NASS[, (existing_factors) := lapply(.SD, as.factor), .SDcols = existing_factors]\n",
        "\n",
        "# Boolean variables\n",
        "if(\"FEMALE\" %in% names(NASS)) NASS[, FEMALE := as.logical(as.numeric(FEMALE))]\n",
        "if(\"WHITE\" %in% names(NASS)) NASS[, WHITE := as.logical(as.numeric(WHITE))]\n",
        "\n",
        "# Compact output\n",
        "cat(\"✅ R Complete:\", nrow(NASS), \"rows,\", ncol(NASS), \"cols,\",\n",
        "    round(object.size(NASS)/1024^2, 1), \"MB\\n\")\n",
        "cat(\"Converted\", length(existing_factors), \"factors + 2 booleans\\n\")\n",
        "\n",
        "if(VERBOSE_PRINTS) {\n",
        "  cat(\"\\nColumns:\\n\")\n",
        "  print(colnames(NASS))\n",
        "}\n",
        "\n",
        "cat(\"Ready for analysis!\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbLoLZoAsHKG"
      },
      "source": [
        "# Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43230586"
      },
      "source": [
        "---\n",
        "## 1. R Analysis - Income Quartile vs Procedure\n",
        "\n",
        "Visualize income distribution within the most common procedures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ee3556ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== DATASET ANALYSIS SUMMARY ===\n",
            "<U+0001F4CA> Data shape: 139233 rows x 78 columns\n",
            "<U+0001F4CA> Data shape: 139233 rows x 78 columns\n",
            "\n",
            "<U+0001F51D> Top 10 procedures (CPTCCS1):\n",
            "    CPTCCS1     N\n",
            "     <fctr> <int>\n",
            " 1:      15 11335\n",
            " 2:     160  8579\n",
            "<U+0001F51D> Top 10 procedures (CPTCCS1):\n",
            "    CPTCCS1     N\n",
            "     <fctr> <int>\n",
            " 1:      15 11335\n",
            " 2:     160  8579\n",
            " 3:      84  7056\n",
            " 4:     152  5198\n",
            " 5:      85\n",
            " 3:      84  7056\n",
            " 4:     152  5198\n",
            " 5:      85  5066\n",
            " 6:     162  4269\n",
            " 7:      86  4260\n",
            " 8:     124  4154\n",
            " 9:     175  3813\n",
            "10:       6  3715\n",
            "\n",
            "<U+0001F465> Race: White = 72.1 %, Non-White =  5066\n",
            " 6:     162  4269\n",
            " 7:      86  4260\n",
            " 8:     124  4154\n",
            " 9:     175  3813\n",
            "10:       6  3715\n",
            "\n",
            "<U+0001F465> Race: White = 72.1 %, Non-White = 27.9 %\n",
            " 27.9 %\n",
            "\n",
            "<U+0001F4C5> Age distribution:\n",
            "   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n",
            "   0.00   38.00   56.00   52.06   68.00  104.00 \n",
            "\n",
            "<U+0001F4B0> Income quartiles:\n",
            "  \n",
            "<U+0001F4C5> Age distribution:\n",
            "   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n",
            "   0.00   38.00   56.00   52.06   68.00  104.00 \n",
            "\n",
            "<U+0001F4B0> Income quartiles:\n",
            "   INCOME_LEVEL     N\n",
            "         <fctr> <int>\n",
            "1:    Q1-Lowest 31913\n",
            "2:           Q2 39311\n",
            "3:           Q3 34833\n",
            "4:   Q4-Highest 31625\n",
            "5:      Unknown  1551\n",
            "\n",
            "<U+2705> Summary complete - ready for analysis!\n",
            " INCOME_LEVEL     N\n",
            "         <fctr> <int>\n",
            "1:    Q1-Lowest 31913\n",
            "2:           Q2 39311\n",
            "3:           Q3 34833\n",
            "4:   Q4-Highest 31625\n",
            "5:      Unknown  1551\n",
            "\n",
            "<U+2705> Summary complete - ready for analysis!\n"
          ]
        }
      ],
      "source": [
        "%%R\n",
        "\n",
        "# ===== GENERATE SUMMARY STATISTICS =====\n",
        "cat(\"\\n=== DATASET ANALYSIS SUMMARY ===\\n\")\n",
        "cat(\"📊 Data shape:\", nrow(NASS), \"rows x\", ncol(NASS), \"columns\\n\")\n",
        "flush.console()\n",
        "\n",
        "# Create top 10 procedures table\n",
        "if(\"CPTCCS1\" %in% names(NASS)) {\n",
        "  top10 <- NASS[, .N, by = CPTCCS1][order(-N)][1:10]\n",
        "  cat(\"\\n🔝 Top 10 procedures (CPTCCS1):\\n\")\n",
        "  print(top10)\n",
        "} else {\n",
        "  cat(\"⚠️ CPTCCS1 variable not found\\n\")\n",
        "}\n",
        "\n",
        "# Basic demographic summary\n",
        "if(\"WHITE\" %in% names(NASS)) {\n",
        "  white_pct <- round(mean(NASS$WHITE, na.rm = TRUE) * 100, 1)\n",
        "  cat(\"\\n👥 Race: White =\", white_pct, \"%, Non-White =\", 100 - white_pct, \"%\\n\")\n",
        "}\n",
        "\n",
        "if(\"AGE\" %in% names(NASS)) {\n",
        "  age_summary <- summary(NASS$AGE)\n",
        "  cat(\"\\n📅 Age distribution:\\n\")\n",
        "  print(age_summary)\n",
        "}\n",
        "\n",
        "if(\"INCOME_LEVEL\" %in% names(NASS)) {\n",
        "  income_dist <- NASS[, .N, by = INCOME_LEVEL][order(INCOME_LEVEL)]\n",
        "  cat(\"\\n💰 Income quartiles:\\n\")\n",
        "  print(income_dist)\n",
        "}\n",
        "\n",
        "cat(\"\\n✅ Summary complete - ready for analysis!\\n\")\n",
        "flush.console()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20a6a8a8"
      },
      "source": [
        "---\n",
        "## 10. Census API Setup\n",
        "\n",
        "Set up environment variable for Census API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6d0c69b9"
      },
      "outputs": [],
      "source": [
        "import getpass, os, json, textwrap\n",
        "os.environ[\"CENSUS_API_KEY\"] = getpass.getpass(\"Enter your Census API key (will not echo):\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c39ad38"
      },
      "source": [
        "---\n",
        "## 11. R | Set Census Key & Pull 2020 DHC Totals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "240fd569"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'character()' is not defined.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\laure\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rpy2\\ipython\\rmagic.py:557\u001b[39m, in \u001b[36m_find\u001b[39m\u001b[34m(name, ns)\u001b[39m\n\u001b[32m    556\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m557\u001b[39m     obj = \u001b[43mns\u001b[49m\u001b[43m[\u001b[49m\u001b[43mobj_path\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlook_for_i\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    558\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[31mKeyError\u001b[39m: 'character()'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\laure\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rpy2\\ipython\\rmagic.py:802\u001b[39m, in \u001b[36mRMagics._import_name_into_r\u001b[39m\u001b[34m(self, arg, env, local_ns)\u001b[39m\n\u001b[32m    801\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m802\u001b[39m     val = \u001b[43m_find\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrhs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_ns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    803\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNameError\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\laure\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rpy2\\ipython\\rmagic.py:563\u001b[39m, in \u001b[36m_find\u001b[39m\u001b[34m(name, ns)\u001b[39m\n\u001b[32m    561\u001b[39m         message += (\u001b[33m'\u001b[39m\u001b[33m Did you forget to remove trailing comma `,` \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    562\u001b[39m                     \u001b[33m'\u001b[39m\u001b[33mor included spaces?\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m563\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNameError\u001b[39;00m(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    564\u001b[39m look_for_i += \u001b[32m1\u001b[39m\n",
            "\u001b[31mNameError\u001b[39m: name 'character()' is not defined.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\laure\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rpy2\\ipython\\rmagic.py:557\u001b[39m, in \u001b[36m_find\u001b[39m\u001b[34m(name, ns)\u001b[39m\n\u001b[32m    556\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m557\u001b[39m     obj = \u001b[43mns\u001b[49m\u001b[43m[\u001b[49m\u001b[43mobj_path\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlook_for_i\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    558\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[31mKeyError\u001b[39m: 'character()'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mR\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m-i states_in_nass=character() -i VERBOSE_PRINTS\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m# If you\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43mve already installed the key once, this is a no-op\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mtidycensus::census_api_key(Sys.getenv(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCENSUS_API_KEY\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m), overwrite = FALSE, install = FALSE)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mget_vars <- function(base) sprintf(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[33;43m_\u001b[39;49m\u001b[38;5;132;43;01m%03d\u001b[39;49;00m\u001b[33;43mN\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, base, 1:49)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mvars_total <- get_vars(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mP12\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mvars_white <- get_vars(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mP12I\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mpull_state_totals <- function(vars)\u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m  get_decennial(geography = \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstate\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                variables = vars,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                year = 2020, sumfile = \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdhc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m) |>\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m  group_by(NAME) |> summarise(total = sum(value))\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m}\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mtotal_pop  <- pull_state_totals(vars_total)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mwhite_pop  <- pull_state_totals(vars_white)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mcensus_prop <- merge(total_pop, white_pop, by = \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mNAME\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                     suffixes = c(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m_all\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m_white\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m))\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mcensus_prop[, prop_white := total_white / total_all]\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mif (VERBOSE_PRINTS) head(census_prop)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:2565\u001b[39m, in \u001b[36mInteractiveShell.run_cell_magic\u001b[39m\u001b[34m(self, magic_name, line, cell)\u001b[39m\n\u001b[32m   2563\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.builtin_trap:\n\u001b[32m   2564\u001b[39m     args = (magic_arg_s, cell)\n\u001b[32m-> \u001b[39m\u001b[32m2565\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2567\u001b[39m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[32m   2568\u001b[39m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[32m   2569\u001b[39m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[32m   2570\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\laure\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rpy2\\ipython\\rmagic.py:1246\u001b[39m, in \u001b[36mRMagics.R\u001b[39m\u001b[34m(self, line, cell, local_ns)\u001b[39m\n\u001b[32m   1244\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m converter.context() \u001b[38;5;28;01mas\u001b[39;00m cv:\n\u001b[32m   1245\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m,\u001b[39m\u001b[33m'\u001b[39m.join(args.input).split(\u001b[33m'\u001b[39m\u001b[33m,\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1246\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_import_name_into_r\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mro\u001b[49m\u001b[43m.\u001b[49m\u001b[43mglobalenv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_ns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m args.display:\n\u001b[32m   1249\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\laure\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rpy2\\ipython\\rmagic.py:809\u001b[39m, in \u001b[36mRMagics._import_name_into_r\u001b[39m\u001b[34m(self, arg, env, local_ns)\u001b[39m\n\u001b[32m    805\u001b[39m         warnings.warn(\n\u001b[32m    806\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mThe shell is None. Unable to look for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrhs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    807\u001b[39m         )\n\u001b[32m    808\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m809\u001b[39m         val = \u001b[43m_find\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrhs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshell\u001b[49m\u001b[43m.\u001b[49m\u001b[43muser_ns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    810\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    811\u001b[39m     env[lhs] = val\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\laure\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rpy2\\ipython\\rmagic.py:563\u001b[39m, in \u001b[36m_find\u001b[39m\u001b[34m(name, ns)\u001b[39m\n\u001b[32m    560\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m obj_path[look_for_i] == \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    561\u001b[39m         message += (\u001b[33m'\u001b[39m\u001b[33m Did you forget to remove trailing comma `,` \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    562\u001b[39m                     \u001b[33m'\u001b[39m\u001b[33mor included spaces?\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m563\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNameError\u001b[39;00m(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    564\u001b[39m look_for_i += \u001b[32m1\u001b[39m\n\u001b[32m    565\u001b[39m \u001b[38;5;66;03m# Subsequent lookups are through the chain of namespace in the\u001b[39;00m\n\u001b[32m    566\u001b[39m \u001b[38;5;66;03m# argument \"name\"\u001b[39;00m\n",
            "\u001b[31mNameError\u001b[39m: name 'character()' is not defined."
          ]
        }
      ],
      "source": [
        "%%R -i states_in_nass=character() -i VERBOSE_PRINTS\n",
        "# If you've already installed the key once, this is a no-op\n",
        "tidycensus::census_api_key(Sys.getenv(\"CENSUS_API_KEY\"), overwrite = FALSE, install = FALSE)\n",
        "\n",
        "get_vars <- function(base) sprintf(\"%s_%03dN\", base, 1:49)\n",
        "\n",
        "vars_total <- get_vars(\"P12\")\n",
        "vars_white <- get_vars(\"P12I\")\n",
        "\n",
        "pull_state_totals <- function(vars){\n",
        "  get_decennial(geography = \"state\",\n",
        "                variables = vars,\n",
        "                year = 2020, sumfile = \"dhc\") |>\n",
        "  group_by(NAME) |> summarise(total = sum(value))\n",
        "}\n",
        "\n",
        "total_pop  <- pull_state_totals(vars_total)\n",
        "white_pop  <- pull_state_totals(vars_white)\n",
        "\n",
        "census_prop <- merge(total_pop, white_pop, by = \"NAME\",\n",
        "                     suffixes = c(\"_all\",\"_white\"))\n",
        "census_prop[, prop_white := total_white / total_all]\n",
        "\n",
        "if (VERBOSE_PRINTS) head(census_prop)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6239ac5"
      },
      "source": [
        "---\n",
        "## 12. R | Weighted vs Unweighted Proportion Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9a539f9"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "library(survey)\n",
        "\n",
        "# Survey design using provided discharge weight\n",
        "des <- svydesign(ids = ~1, weights = ~DISCWT, data = NASS)\n",
        "\n",
        "unweighted_hat <- mean(NASS$WHITE)\n",
        "weighted_hat   <- svymean(~WHITE, des)[1]\n",
        "\n",
        "us_prop <- weighted.mean(census_prop$prop_white,\n",
        "                         w = census_prop$total_all)\n",
        "\n",
        "cat(sprintf(\"Unweighted NASS white %%: %.3f\\n\", unweighted_hat))\n",
        "cat(sprintf(\"Weighted   NASS white %%: %.3f\\n\", weighted_hat))\n",
        "cat(sprintf(\"2020 Census (all NASS states) white %%: %.3f\\n\", us_prop))\n",
        "\n",
        "svytest <- svyciprop(~WHITE, des,\n",
        "                     method = \"likelihood\", level = 0.95)\n",
        "print(svytest)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d30e6ec7"
      },
      "source": [
        "---\n",
        "## 13. R | Age-by-sex plot vs Census (adapted from `agesociodiv.r`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfb4756f"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "age_breaks <- c(-Inf,4,9,14,17,19,20,21,24,29,34,39,44,49,54,59,61,64,\n",
        "                66,69,74,79,84,Inf)\n",
        "age_labels <- c(\"U5\",\"5-9\",\"10-14\",\"15-17\",\"18-19\",\"20\",\"21\",\n",
        "                \"22-24\",\"25-29\",\"30-34\",\"35-39\",\"40-44\",\"45-49\",\n",
        "                \"50-54\",\"55-59\",\"60-61\",\"62-64\",\"65-66\",\"67-69\",\n",
        "                \"70-74\",\"75-79\",\"80-84\",\"85+\")\n",
        "\n",
        "NASS[, AGE_GROUP := cut(AGE, breaks = age_breaks,\n",
        "                        labels = age_labels, right = TRUE)]\n",
        "\n",
        "plot_df <- NASS[, .(white = sum(WHITE),\n",
        "                    n     = .N),\n",
        "                by = .(SEX = factor(FEMALE, labels=c(\"Male\",\"Female\")),\n",
        "                       AGE_GROUP)]\n",
        "plot_df[, prop := white/n]\n",
        "\n",
        "# Create plot with intelligent fallback\n",
        "if(require(\"ggplot2\", quietly = TRUE) && require(\"scales\", quietly = TRUE)) {\n",
        "  # Primary: ggplot2 with scales\n",
        "  gg_gender <- ggplot(plot_df, aes(x = AGE_GROUP, y = prop,\n",
        "                                   group = SEX, color = SEX)) +\n",
        "    geom_line(linewidth=1) +\n",
        "    geom_point() +\n",
        "    scale_y_continuous(labels = scales::percent) +\n",
        "    labs(y = \"% White (NASS, simulated)\", x = \"Age-group\",\n",
        "         title = \"Crude white proportion by age & sex\") +\n",
        "    theme_minimal() +\n",
        "    theme(axis.text.x = element_text(angle=45, hjust=1))\n",
        "  print(gg_gender)\n",
        "  cat(\"📊 ggplot2 plot generated\\n\")\n",
        "\n",
        "} else if(require(\"ggplot2\", quietly = TRUE)) {\n",
        "  # Fallback: ggplot2 without scales\n",
        "  gg_gender <- ggplot(plot_df, aes(x = AGE_GROUP, y = prop,\n",
        "                                   group = SEX, color = SEX)) +\n",
        "    geom_line(linewidth=1) +\n",
        "    geom_point() +\n",
        "    labs(y = \"Proportion White (NASS, simulated)\", x = \"Age-group\",\n",
        "         title = \"Crude white proportion by age & sex\") +\n",
        "    theme_minimal() +\n",
        "    theme(axis.text.x = element_text(angle=45, hjust=1))\n",
        "  print(gg_gender)\n",
        "  cat(\"📊 ggplot2 plot generated (without percentage scaling)\\n\")\n",
        "\n",
        "} else {\n",
        "  # Base R fallback\n",
        "  cat(\"📊 Using base R plotting (ggplot2 not available)\\n\")\n",
        "\n",
        "  male_data <- plot_df[SEX == \"Male\"]\n",
        "  female_data <- plot_df[SEX == \"Female\"]\n",
        "\n",
        "  plot(1:nrow(male_data), male_data$prop, type = \"b\", col = \"blue\",\n",
        "       xlab = \"Age Group\", ylab = \"Proportion White\",\n",
        "       main = \"Crude white proportion by age & sex\",\n",
        "       ylim = c(0, 1), xaxt = \"n\")\n",
        "  lines(1:nrow(female_data), female_data$prop, type = \"b\", col = \"red\")\n",
        "  axis(1, at = 1:nrow(male_data), labels = male_data$AGE_GROUP, las = 2)\n",
        "  legend(\"topright\", legend = c(\"Male\", \"Female\"), col = c(\"blue\", \"red\"), lty = 1)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "add395e2"
      },
      "source": [
        "---\n",
        "## 14. R | Multilevel logistic models (hospital nested, 3 tiers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8574bf3a"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "features <- NASS[, .(WHITE,\n",
        "                     FEMALE,\n",
        "                     ZIPINC_QRTL,\n",
        "                     PAY1,\n",
        "                     CPTCCS1,\n",
        "                     HOSP_LOCATION,\n",
        "                     HOSP_TEACH,\n",
        "                     HOSP_NASS)]\n",
        "\n",
        "features[, c(names(features)) := lapply(.SD, as.factor)]\n",
        "\n",
        "formulas <- list(\n",
        "  m1 = WHITE ~ FEMALE + (1|HOSP_NASS),\n",
        "  m2 = WHITE ~ FEMALE + ZIPINC_QRTL + (1|HOSP_NASS),\n",
        "  m3 = WHITE ~ FEMALE + ZIPINC_QRTL + PAY1 + CPTCCS1 +\n",
        "                    HOSP_LOCATION + HOSP_TEACH + (1|HOSP_NASS)\n",
        ")\n",
        "\n",
        "fit <- lapply(formulas, glmer, family = binomial, data = features,\n",
        "              control = glmerControl(optimizer=\"bobyqa\", optCtrl=list(maxfun=2e4)))\n",
        "\n",
        "sapply(fit, function(m) broom::tidy(m, effects = \"fixed\")[1:5,])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa999863"
      },
      "source": [
        "---\n",
        "## 15. R | Compare AUC across the three models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9781417"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "library(pROC)\n",
        "auc_vals <- sapply(fit, function(m){\n",
        "  preds <- predict(m, type=\"response\")\n",
        "  roc(features$WHITE, preds)$auc\n",
        "})\n",
        "knitr::kable(data.frame(model = names(auc_vals), AUC = auc_vals),\n",
        "             caption = \"AUC (in-sample, simulated data)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8L7G5GKSsSX3"
      },
      "source": [
        "# Poster Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOTnhQoRse_k"
      },
      "source": [
        "Poster genreated here\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
