{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open on GitHub](https://img.shields.io/badge/GitHub-View%20Source-181717?style=for-the-badge&logo=github)](https://github.com/SeenaKhosravi/NASS/blob/main/Analysis_NASS.ipynb)\n",
    "[![Open In Colab](https://img.shields.io/badge/Colab-Open%20Notebook-F9AB00?style=for-the-badge&logo=google-colab)](https://colab.research.google.com/github/SeenaKhosravi/NASS/blob/main/Analysis_NASS.ipynb)\n",
    "[![Open in Vertex AI](https://img.shields.io/badge/Vertex%20AI-Open%20Workbench-4285F4?style=for-the-badge&logo=google-cloud)](https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/SeenaKhosravi/NASS/main/Analysis_NASS.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbe6c3e6"
   },
   "source": [
    "# Socioeconomic and Demographic Drivers of Ambulatory Surgery Usage\n",
    "### HCUP NASS 2020 – Reproducible Pipeline (Python + R)\n",
    "\n",
    "**Author:** Seena Khosravi, MD  \n",
    "**LLMs Utilized:** Claude Sonnet 4, Opus 4; ChatGPT 4o, o4; Deepseek 3.1; Gemini 2.5 Pro  \n",
    "**Last Updated:** September 13, 2025  \n",
    "\n",
    "**Data Source:**  \n",
    "Department of Health & Human Services (HHS)  \n",
    "Agency for Healthcare Research and Quality (AHRQ)  \n",
    "Healthcare Cost and Utilization Project (HCUP)  \n",
    "National Ambulatory Surgical Sample (NASS)\n",
    "Year - 2020\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aOmuZCsusrTj"
   },
   "source": [
    "## Overview\n",
    "This notebook provides a reproducible analysis pipeline for examining socioeconomic and demographic factors influencing ambulatory surgery usage patterns. The analysis combines Python for data processing and R for statistical modeling.\n",
    "\n",
    "### Data Usage Agreement\n",
    "**DUA Compliant Online Implementation** — This notebook uses a simulated, artificial, smaller dataset with identical structure to the file created by [Raw_NASS_Processing.R](https://github.com/SeenaKhosravi/NASS/blob/a7764ce80be8a82fc449831821c27d957176c410/Raw%20NASS%20%20Processing.R). The simulated dataset production methodology is found in [Generate_Simulated_NASS.R](https://github.com/SeenaKhosravi/NASS/blob/161bf2b5c149da9654c0e887655b361fa2176db0/Generate_Simulated_NASS.R). If DUA signed and data purchased from HCUP, this notebook can run on full dataset loaded from your local or cloud storage.\n",
    "\n",
    "[Please see the DUA Agreement here.](https://hcup-us.ahrq.gov/team/NationwideDUA.jsp)\n",
    "\n",
    "### Key Features\n",
    "- **Multiple Platform:** Works on jupyter implementations via local environments, server, cloud VM instance, or platform as a service.\n",
    "- **Flexible Data Storage:** GitHub (simulated, static, open access), Google Drive, Google Cloud Storage, or local file\n",
    "- **Reproducible:** All dependencies and environment setup included; assumes new, unmodified colab/vertex instances\n",
    "- **Scalable:** Handles both simulated (0.2GB, 139k rows) and full dataset (12 GB, 7.8M rows). Scalable cloud options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "019b6fe9"
   },
   "source": [
    "---\n",
    "\n",
    "## Design Notes\n",
    "\n",
    "### Architecture\n",
    "- **Python primary, w/ R run via rpy2 python extension**\n",
    "- **Python cells** handle \"plumbing\" (file I/O, environment setup, rpy2 configuration, data previews)\n",
    "- **R cells** (prefixed by `%%R`) perform statistical analysis: survey weights, Census lookups, multilevel models, plots, classifiers, etc.\n",
    "\n",
    "### Data Sources\n",
    "- **Default:** Simulated dataset (1GB) from GitHub releases\n",
    "- **Local:** Switch to locally stored files via configuration\n",
    "- **Drive:** Google Drive (Only availble in Colab)\n",
    "- **Cloud:** Google Cloud Storage support for large datasets\n",
    "\n",
    "\n",
    "### Environment Support\n",
    "- Local (Jupyterlab w/ Python 3.11.5 kernel)\n",
    "- Jupyter Server (may require some configuring depending on your implementation)\n",
    "- Google Colab (Pro recommended, high-ram option)\n",
    "- Vertex AI Workbench (JupyterLab 3, Python 3 kernel) (used for full analysis)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IvQPKX8GrfZr"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yUEIOQlXrPrd"
   },
   "source": [
    "---\n",
    "## 1. Configuration\n",
    "\n",
    "Configure all settings here prior to run - data sources, debugging options, and file paths. Defaults to simulated dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "KUU1wwMKrPre"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Configuration loaded\n",
      "  Data source: github\n",
      "  Verbose mode: True\n"
     ]
    }
   ],
   "source": [
    "# ==================== CONFIGURATION ====================\n",
    "# Data Source Options\n",
    "DATA_SOURCE = \"github\"      # Options: \"github\", \"local\", \"gcs\", \"drive\"\n",
    "VERBOSE_PRINTS = True       # False → suppress debug output\n",
    "\n",
    "# GitHub source (default - simulated data)\n",
    "GITHUB_URL = \"https://github.com/SeenaKhosravi/NASS/releases/download/v1.0.0/nass_2020_simulated.csv\"\n",
    "\n",
    "# Local file options\n",
    "LOCAL_FILENAME = \"nass_2020_local.csv\"\n",
    "\n",
    "# Google Cloud Storage options\n",
    "GCS_BUCKET = \"nass_2020\"\n",
    "GCS_BLOB = \"nass_2020_all.csv\"\n",
    "GCS_SERVICE_ACCOUNT_KEY = \"/path/to/service-account-key.json\"  # Optional\n",
    "\n",
    "# Google Drive options (for Colab)\n",
    "DRIVE_PATH = \"/content/drive/MyDrive/NASS/nass_2020_full.csv\"\n",
    "# ======================================================\n",
    "\n",
    "print(\"✓ Configuration loaded\")\n",
    "print(f\"  Data source: {DATA_SOURCE}\")\n",
    "print(f\"  Verbose mode: {VERBOSE_PRINTS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8WJ8_5sRrPre"
   },
   "source": [
    "---\n",
    "## 2. Environment Setup & Package Installation\n",
    "\n",
    "Detect environment and install Python packages via Conda if available, with fallbacks. If in Google Colab, mount Google Drive.\n",
    "\n",
    "**Note:** If running in Vertex AI Workbench for the first time, you need additional R setup prior to loading rpy2. Please skip the following cell and return after completing the subsequent cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "x9RcJjrWrPrf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment detected: Local/Jupyter\n",
      "Installing and checking packages...\n",
      "All packages ready\n",
      "All packages ready\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "class EnvironmentManager:\n",
    "    def __init__(self):\n",
    "        self.detect_environment()\n",
    "        self.setup_packages()\n",
    "\n",
    "    def detect_environment(self):\n",
    "        \"\"\"Detect runtime environment\"\"\"\n",
    "        self.is_colab = 'COLAB_GPU' in os.environ or 'google.colab' in sys.modules\n",
    "        self.is_vertex = 'DL_ANACONDA_HOME' in os.environ\n",
    "\n",
    "        if self.is_colab:\n",
    "            self.env_type = \"Google Colab\"\n",
    "        elif self.is_vertex:\n",
    "            self.env_type = \"Vertex AI\"\n",
    "        else:\n",
    "            self.env_type = \"Local/Jupyter\"\n",
    "\n",
    "        print(f\"Environment detected: {self.env_type}\")\n",
    "\n",
    "    def check_conda_available(self):\n",
    "        \"\"\"Check if conda is available\"\"\"\n",
    "        try:\n",
    "            subprocess.check_call(['conda', '--version'],\n",
    "                                stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "            return True\n",
    "        except (subprocess.CalledProcessError, FileNotFoundError):\n",
    "            return False\n",
    "\n",
    "    def install_package(self, package, conda_name=None):\n",
    "        \"\"\"Smart package installation with fallback\"\"\"\n",
    "        try:\n",
    "            __import__(package)\n",
    "            return True\n",
    "        except ImportError:\n",
    "            print(f\"Installing {package}...\")\n",
    "\n",
    "            # Try conda first if available and not in Colab\n",
    "            if conda_name and not self.is_colab and self.check_conda_available():\n",
    "                try:\n",
    "                    subprocess.check_call(['conda', 'install', '-y', conda_name],\n",
    "                                        stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "                    return True\n",
    "                except subprocess.CalledProcessError:\n",
    "                    print(f\"  Conda install failed for {conda_name}, trying pip...\")\n",
    "\n",
    "            # Fallback to pip\n",
    "            try:\n",
    "                subprocess.check_call([sys.executable, '-m', 'pip', 'install', package],\n",
    "                                    stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "                return True\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                print(f\"  Pip install failed for {package}: {e}\")\n",
    "                return False\n",
    "\n",
    "    def setup_packages(self):\n",
    "        \"\"\"Install required packages efficiently\"\"\"\n",
    "        packages = {\n",
    "            'pandas': 'pandas',\n",
    "            'requests': 'requests',\n",
    "            'rpy2': 'rpy2',\n",
    "            'google.cloud.storage': 'google-cloud-storage'\n",
    "        }\n",
    "\n",
    "        print(\"Installing and checking packages...\")\n",
    "        failed = []\n",
    "\n",
    "        for pkg, install_name in packages.items():\n",
    "            if not self.install_package(pkg, install_name):\n",
    "                failed.append(pkg)\n",
    "\n",
    "        # Store failed packages globally for recovery\n",
    "        globals()['failed_packages'] = failed\n",
    "\n",
    "        if failed:\n",
    "            print(f\"Warning: Failed to install: {', '.join(failed)}\")\n",
    "            print(\"Some features may not work\")\n",
    "\n",
    "            # Provide specific guidance for rpy2\n",
    "            if 'rpy2' in failed:\n",
    "                print(\"\\nFor rpy2 installation issues:\")\n",
    "                if self.is_vertex:\n",
    "                    print(\"   - Vertex AI: R may not be installed by default\")\n",
    "                    print(\"   - Run the next cell for automated R setup\")\n",
    "                else:\n",
    "                    print(\"   - On Windows: May need Visual Studio Build Tools\")\n",
    "                    print(\"   - Try: conda install -c conda-forge rpy2\")\n",
    "                    print(\"   - Or: pip install rpy2 (requires R to be installed)\")\n",
    "        else:\n",
    "            print(\"All packages ready\")\n",
    "\n",
    "        # Mount Google Drive if needed (check if DATA_SOURCE exists)\n",
    "        try:\n",
    "            if globals().get('DATA_SOURCE') == \"drive\" and self.is_colab:\n",
    "                self.mount_drive()\n",
    "        except NameError:\n",
    "            pass  # DATA_SOURCE not defined yet\n",
    "\n",
    "    def mount_drive(self):\n",
    "        \"\"\"Mount Google Drive in Colab\"\"\"\n",
    "        try:\n",
    "            from google.colab import drive\n",
    "            drive.mount('/content/drive')\n",
    "            print(\"Google Drive mounted successfully\")\n",
    "        except:\n",
    "            print(\"Error: Failed to mount Google Drive\")\n",
    "\n",
    "# Initialize environment\n",
    "env_manager = EnvironmentManager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SyZ9A_kurPrf"
   },
   "source": [
    "If running in Vertex AI Workbench for the first time (or if the previous cell gave an error), run this cell to install R and setup essential dependencies, then re-run the previous cell for rpy2.\n",
    "\n",
    "Otherwise, skip this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-4eMeiiMrPrg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Environment setup for Vertex AI - implementation pending\n"
     ]
    }
   ],
   "source": [
    "print(\"R Environment setup for Vertex AI - implementation pending\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mm4dTQb1rPrh"
   },
   "source": [
    "---\n",
    "## 3. R Environment Setup\n",
    "\n",
    "Load R integration and install R packages efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7wpUbizDrPrh"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error importing in API mode: ImportError('On Windows, cffi mode \"ANY\" is only \"ABI\".')\n",
      "Trying to import in ABI mode.\n",
      "Trying to import in ABI mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R integration loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Load rpy2 extension for R integration\n",
    "try:\n",
    "    %load_ext rpy2.ipython\n",
    "    print(\"R integration loaded successfully\")\n",
    "    globals()['R_AVAILABLE'] = True\n",
    "except Exception as e:\n",
    "    print(f\"Error: Failed to load R integration: {e}\")\n",
    "\n",
    "    # Windows-specific troubleshooting\n",
    "    if \"R.dll\" in str(e) or \"error 0x7e\" in str(e):\n",
    "        print(\"\\nWindows R.dll loading issue detected:\")\n",
    "        print(\"   This is a common Windows + rpy2 compatibility issue\")\n",
    "        print(\"   Solutions:\")\n",
    "        print(\"   1. Restart Python kernel and try again\")\n",
    "        print(\"   2. Check R version compatibility with rpy2\")\n",
    "        print(\"   3. Try reinstalling R and rpy2\")\n",
    "        print(\"   4. Use Python-only analysis (fallback available)\")\n",
    "        globals()['R_AVAILABLE'] = False\n",
    "    else:\n",
    "        print(\"Install rpy2: pip install rpy2\")\n",
    "        globals()['R_AVAILABLE'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J5iP0V_1rPri"
   },
   "source": [
    "Install essential R packages and attempt installation of optional packages.\n",
    "\n",
    "**Note:** Other packages needed for specific analysis (advanced modeling packages) will be installed and called as needed later in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local environment detected\n",
      "Essential packages loaded: 3 / 3 \n",
      "Essential packages loaded: 3 / 3 \n",
      "Optional packages loaded: 2 / 2 \n",
      "Core environment ready! (data.table + ggplot2)\n",
      "Optional packages loaded: 2 / 2 \n",
      "Core environment ready! (data.table + ggplot2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "In addition: Warning messages:\n",
       "1: package 'data.table' was built under R version 4.4.3 \n",
       "2: package 'ggplot2' was built under R version 4.4.2 \n",
       "3: package 'survey' was built under R version 4.4.3 \n",
       "4: package 'broom' was built under R version 4.4.2 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R -i VERBOSE_PRINTS\n",
    "\n",
    "# Environment-aware R package setup\n",
    "# Standard approach, then Vertex AI fallback if needed\n",
    "\n",
    "# Detect environment\n",
    "is_vertex <- Sys.getenv(\"DL_ANACONDA_HOME\") != \"\"\n",
    "is_colab <- Sys.getenv(\"COLAB_GPU\") != \"\"\n",
    "\n",
    "if(is_colab) {\n",
    "  cat(\"Google Colab detected\\n\")\n",
    "} else if(is_vertex) {\n",
    "  cat(\"Vertex AI detected\\n\")\n",
    "} else {\n",
    "  cat(\"Local environment detected\\n\")\n",
    "}\n",
    "\n",
    "# Standard clean setup (for all environments initially)\n",
    "essential_packages <- c(\n",
    "  \"data.table\",    # Fast data manipulation\n",
    "  \"ggplot2\",       # Plotting\n",
    "  \"scales\"         # For ggplot2 percentage scales\n",
    ")\n",
    "\n",
    "optional_packages <- c(\n",
    "  \"survey\",        # Survey statistics\n",
    "  \"broom\"          # Model tidying\n",
    ")\n",
    "\n",
    "# Fast installation settings\n",
    "repos <- \"https://cloud.r-project.org\"\n",
    "options(repos = repos)\n",
    "Sys.setenv(MAKEFLAGS = paste0(\"-j\", parallel::detectCores()))\n",
    "\n",
    "# Package check and load functions\n",
    "pkg_available <- function(pkg) {\n",
    "  tryCatch({\n",
    "    find.package(pkg, quiet = TRUE)\n",
    "    TRUE\n",
    "  }, error = function(e) FALSE)\n",
    "}\n",
    "\n",
    "load_pkg <- function(pkg) {\n",
    "  tryCatch({\n",
    "    suppressMessages(library(pkg, character.only = TRUE, quietly = TRUE))\n",
    "    TRUE\n",
    "  }, error = function(e) FALSE)\n",
    "}\n",
    "\n",
    "# Install missing essential packages\n",
    "missing_essential <- essential_packages[!sapply(essential_packages, pkg_available)]\n",
    "\n",
    "if(length(missing_essential) > 0) {\n",
    "  cat(\"Installing essential packages:\", paste(missing_essential, collapse = \", \"), \"\\n\")\n",
    "\n",
    "  tryCatch({\n",
    "    install.packages(missing_essential,\n",
    "                    repos = repos,\n",
    "                    type = getOption(\"pkgType\"),\n",
    "                    dependencies = FALSE,\n",
    "                    quiet = !VERBOSE_PRINTS,\n",
    "                    Ncpus = parallel::detectCores())\n",
    "  }, error = function(e) {\n",
    "    cat(\"Binary install failed, trying source...\\n\")\n",
    "    install.packages(missing_essential,\n",
    "                    repos = repos,\n",
    "                    type = \"source\",\n",
    "                    dependencies = FALSE,\n",
    "                    quiet = !VERBOSE_PRINTS)\n",
    "  })\n",
    "}\n",
    "\n",
    "# Load essential packages with error handling\n",
    "essential_loaded <- sapply(essential_packages, load_pkg)\n",
    "essential_success <- sum(essential_loaded)\n",
    "\n",
    "cat(\"Essential packages loaded:\", essential_success, \"/\", length(essential_packages), \"\\n\")\n",
    "\n",
    "# Quick install optional packages (30s timeout)\n",
    "missing_optional <- optional_packages[!sapply(optional_packages, pkg_available)]\n",
    "\n",
    "if(length(missing_optional) > 0) {\n",
    "  cat(\"Installing optional packages...\\n\")\n",
    "\n",
    "  for(pkg in missing_optional) {\n",
    "    tryCatch({\n",
    "      R.utils::withTimeout({\n",
    "        install.packages(pkg, repos = repos,\n",
    "                        type = getOption(\"pkgType\"),\n",
    "                        dependencies = FALSE,\n",
    "                        quiet = TRUE)\n",
    "      }, timeout = 30)\n",
    "      cat(\"Installed:\", pkg, \"\\n\")\n",
    "    }, error = function(e) {\n",
    "      cat(\"Skipped (timeout/error):\", pkg, \"\\n\")\n",
    "    })\n",
    "  }\n",
    "}\n",
    "\n",
    "# Load optional packages\n",
    "optional_loaded <- sapply(optional_packages, load_pkg)\n",
    "optional_success <- sum(optional_loaded)\n",
    "\n",
    "cat(\"Optional packages loaded:\", optional_success, \"/\", length(optional_packages), \"\\n\")\n",
    "\n",
    "# Check if we need Vertex AI aggressive installation\n",
    "has_datatable <- require(\"data.table\", quietly = TRUE)\n",
    "has_ggplot <- require(\"ggplot2\", quietly = TRUE)\n",
    "\n",
    "if(is_vertex && (!has_datatable || !has_ggplot)) {\n",
    "  cat(\"\\nStandard installation incomplete on Vertex AI - using aggressive method...\\n\")\n",
    "\n",
    "  # Check R version for compatibility\n",
    "  r_version <- R.version.string\n",
    "  r_numeric <- as.numeric(R.version$major) + as.numeric(R.version$minor)/10\n",
    "  cat(\"R version:\", r_version, \"(numeric:\", r_numeric, \")\\n\")\n",
    "\n",
    "  # System dependencies for Vertex AI\n",
    "  system_deps <- c(\n",
    "    \"apt-get update -qq\",\n",
    "    \"apt-get install -y libfontconfig1-dev libcairo2-dev\",\n",
    "    \"apt-get install -y libxml2-dev libcurl4-openssl-dev libssl-dev\",\n",
    "    \"apt-get install -y libharfbuzz-dev libfribidi-dev\",\n",
    "    \"apt-get install -y libfreetype6-dev libpng-dev libtiff5-dev libjpeg-dev\"\n",
    "  )\n",
    "\n",
    "  cat(\"Installing system dependencies...\\n\")\n",
    "  for(cmd in system_deps) {\n",
    "    system(paste(\"sudo\", cmd), ignore.stdout = TRUE, ignore.stderr = TRUE)\n",
    "  }\n",
    "\n",
    "  # Aggressive package installation for failed packages\n",
    "  failed_packages <- c()\n",
    "  if(!has_datatable) failed_packages <- c(failed_packages, \"data.table\")\n",
    "  if(!has_ggplot) failed_packages <- c(failed_packages, \"ggplot2\", \"scales\")\n",
    "\n",
    "  repos_vertex <- c(\"https://cran.rstudio.com/\", \"https://cloud.r-project.org\")\n",
    "\n",
    "  for(pkg in failed_packages) {\n",
    "    cat(\"Aggressively installing\", pkg, \"...\")\n",
    "    installed <- FALSE\n",
    "\n",
    "    # For ggplot2/scales, try version-specific installation if R < 4.1\n",
    "    if((pkg == \"ggplot2\" || pkg == \"scales\") && r_numeric < 4.1) {\n",
    "      cat(\"(R < 4.1 detected - trying compatible versions)...\")\n",
    "\n",
    "      # First try to install remotes if not available\n",
    "      if(!require(\"remotes\", quietly = TRUE)) {\n",
    "        tryCatch({\n",
    "          install.packages(\"remotes\", repos = repos_vertex[1], quiet = TRUE)\n",
    "        }, error = function(e) NULL)\n",
    "      }\n",
    "\n",
    "      # Try installing older compatible versions\n",
    "      if(pkg == \"ggplot2\" && require(\"remotes\", quietly = TRUE)) {\n",
    "        # Try ggplot2 versions compatible with older R\n",
    "        old_versions <- c(\"3.4.4\", \"3.4.3\", \"3.4.2\", \"3.4.0\", \"3.3.6\")\n",
    "        for(ver in old_versions) {\n",
    "          tryCatch({\n",
    "            remotes::install_version(\"ggplot2\", version = ver, repos = repos_vertex[1], quiet = TRUE)\n",
    "            if(require(\"ggplot2\", quietly = TRUE)) {\n",
    "              cat(\" Success (v\", ver, \")\\n\")\n",
    "              installed <- TRUE\n",
    "              break\n",
    "            }\n",
    "          }, error = function(e) NULL)\n",
    "        }\n",
    "      } else if(pkg == \"scales\" && require(\"remotes\", quietly = TRUE)) {\n",
    "        # Try scales versions compatible with older R\n",
    "        old_versions <- c(\"1.3.0\", \"1.2.1\", \"1.2.0\", \"1.1.1\")\n",
    "        for(ver in old_versions) {\n",
    "          tryCatch({\n",
    "            remotes::install_version(\"scales\", version = ver, repos = repos_vertex[1], quiet = TRUE)\n",
    "            if(require(\"scales\", quietly = TRUE)) {\n",
    "              cat(\" Success (v\", ver, \")\\n\")\n",
    "              installed <- TRUE\n",
    "              break\n",
    "            }\n",
    "          }, error = function(e) NULL)\n",
    "        }\n",
    "      }\n",
    "\n",
    "      # Fallback: try archived CRAN packages if remotes failed\n",
    "      if(!installed && pkg == \"ggplot2\") {\n",
    "        cat(\"(trying archived versions)...\")\n",
    "        archived_urls <- c(\n",
    "          \"https://cran.r-project.org/src/contrib/Archive/ggplot2/ggplot2_3.4.4.tar.gz\",\n",
    "          \"https://cran.r-project.org/src/contrib/Archive/ggplot2/ggplot2_3.4.0.tar.gz\",\n",
    "          \"https://cran.r-project.org/src/contrib/Archive/ggplot2/ggplot2_3.3.6.tar.gz\"\n",
    "        )\n",
    "        for(url in archived_urls) {\n",
    "          tryCatch({\n",
    "            install.packages(url, repos = NULL, type = \"source\", quiet = TRUE)\n",
    "            if(require(\"ggplot2\", quietly = TRUE)) {\n",
    "              cat(\" Success (archived)\\n\")\n",
    "              installed <- TRUE\n",
    "              break\n",
    "            }\n",
    "          }, error = function(e) NULL)\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "\n",
    "    # Standard installation if version-specific didn't work\n",
    "    if(!installed) {\n",
    "      for(repo in repos_vertex) {\n",
    "        tryCatch({\n",
    "          install.packages(pkg, repos = repo, dependencies = TRUE, quiet = TRUE)\n",
    "          if(require(pkg, character.only = TRUE, quietly = TRUE)) {\n",
    "            cat(\" Success\\n\")\n",
    "            installed <- TRUE\n",
    "            break\n",
    "          }\n",
    "        }, error = function(e) NULL)\n",
    "      }\n",
    "    }\n",
    "\n",
    "    if(!installed) cat(\" FAILED\\n\")\n",
    "  }\n",
    "\n",
    "  # Re-check after aggressive installation\n",
    "  has_datatable <- require(\"data.table\", quietly = TRUE)\n",
    "  has_ggplot <- require(\"ggplot2\", quietly = TRUE)\n",
    "\n",
    "  cat(\"After aggressive installation: data.table =\", has_datatable, \"| ggplot2 =\", has_ggplot, \"\\n\")\n",
    "}\n",
    "\n",
    "# Final status check (universal)\n",
    "if(has_datatable && has_ggplot) {\n",
    "  cat(\"Core environment ready! (data.table + ggplot2)\\n\")\n",
    "  if(has_datatable) setDTthreads(0)  # Use all cores\n",
    "} else if(has_datatable) {\n",
    "  cat(\"Warning: Partial setup - data.table ready, plotting may be limited\\n\")\n",
    "  if(has_datatable) setDTthreads(0)\n",
    "} else {\n",
    "  cat(\"Error: Critical failure - data.table not available\\n\")\n",
    "  stop(\"Cannot proceed without data.table\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAtjPad_rPri"
   },
   "source": [
    "Verify R setup is complete and ready for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "WMh-C5gvrPrj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying R environment...\n",
      "data.table ready\n",
      "ggplot2 ready\n",
      "R environment optimized and ready!\n",
      "data.table ready\n",
      "ggplot2 ready\n",
      "R environment optimized and ready!\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "# Quick verification and setup\n",
    "cat(\"Verifying R environment...\\n\")\n",
    "\n",
    "# Test core functionality\n",
    "tryCatch({\n",
    "  # Test data.table (essential)\n",
    "  dt_test <- data.table(x = 1:3, y = letters[1:3])\n",
    "  cat(\"data.table ready\\n\")\n",
    "\n",
    "  # Test ggplot2 (optional)\n",
    "  if(require(\"ggplot2\", quietly = TRUE)) {\n",
    "    cat(\"ggplot2 ready\\n\")\n",
    "  } else {\n",
    "    cat(\"Warning: ggplot2 not available (plots disabled)\\n\")\n",
    "  }\n",
    "\n",
    "  # Set up data.table options for performance\n",
    "  setDTthreads(0)  # Use all cores\n",
    "\n",
    "  cat(\"R environment optimized and ready!\\n\")\n",
    "\n",
    "}, error = function(e) {\n",
    "  cat(\"Error: R environment verification failed:\", e$message, \"\\n\")\n",
    "  stop(\"R setup incomplete\")\n",
    "})\n",
    "\n",
    "# Clean up test objects\n",
    "rm(list = ls()[!ls() %in% c(\"VERBOSE_PRINTS\")])\n",
    "invisible(gc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N8pUXVbsrPrg"
   },
   "source": [
    "---\n",
    "## 4. Data Loading\n",
    "\n",
    "Config based data loader with error handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "s-KUtlK-rPrh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: GITHUB\n",
      "✓ Downloaded from GitHub (213436933 bytes)\n",
      "✓ Downloaded from GitHub (213436933 bytes)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laure\\AppData\\Local\\Temp\\ipykernel_19968\\2490609550.py:35: DtypeWarning: Columns (56,57,58,59) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(data_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data loaded successfully!\n",
      "   Shape: (139233, 675)\n",
      "   Memory: 885.2 MB\n",
      "\n",
      "Columns: ['KEY_NASS', 'HOSP_NASS', 'HOSP_TEACH', 'HOSP_LOCATION', 'HOSP_LOCTEACH', 'HOSP_REGION', 'HOSP_BEDSIZE_CAT', 'DISCWT', 'NASS_STRATUM', 'N_DISC_U', 'N_HOSP_U', 'S_DISC_U', 'S_HOSP_U', 'TOTAL_AS_ENCOUNTERS', 'YEAR', 'AGE', 'FEMALE', 'PL_NCHS', 'ZIPINC_QRTL', 'AMONTH', 'AWEEKEND', 'DQTR', 'PAY1', 'DISPUNIFORM', 'TOTCHG', 'NCPT_INSCOPE', 'CPTCCS1', 'CPTCCS2', 'CPTCCS3', 'CPTCCS4', 'CPTCCS5', 'CPTCCS6', 'CPTCCS7', 'CPTCCS8', 'CPTCCS9', 'CPTCCS10', 'CPTCCS11', 'CPTCCS12', 'CPTCCS13', 'CPTCCS14', 'CPTCCS15', 'CPTCCS16', 'CPTCCS17', 'CPTCCS18', 'CPTCCS19', 'CPTCCS20', 'CPTCCS21', 'CPTCCS22', 'CPTCCS23', 'CPTCCS24', 'CPTCCS25', 'CPTCCS26', 'CPTCCS27', 'CPTCCS28', 'CPTCCS29', 'CPTCCS30', 'CPT1', 'CPT2', 'CPT3', 'CPT4', 'CPT5', 'CPT6', 'CPT7', 'CPT8', 'CPT9', 'CPT10', 'CPT11', 'CPT12', 'CPT13', 'CPT14', 'CPT15', 'CPT16', 'CPT17', 'CPT18', 'CPT19', 'CPT20', 'CPT21', 'CPT22', 'CPT23', 'CPT24', 'CPT25', 'CPT26', 'CPT27', 'CPT28', 'CPT29', 'CPT30', 'I10_NDX', 'I10_DX1', 'I10_DX2', 'I10_DX3', 'I10_DX4', 'I10_DX5', 'I10_DX6', 'I10_DX7', 'I10_DX8', 'I10_DX9', 'I10_DX10', 'I10_DX11', 'I10_DX12', 'I10_DX13', 'I10_DX14', 'I10_DX15', 'I10_DX16', 'I10_DX17', 'I10_DX18', 'I10_DX19', 'I10_DX20', 'RACE', 'I10_INJURY', 'I10_MULTINJURY', 'CMR_AIDS', 'CMR_ALCOHOL', 'CMR_AUTOIMMUNE', 'CMR_CANCER_LYMPH', 'CMR_CANCER_LEUK', 'CMR_CANCER_METS', 'CMR_CANCER_NSITU', 'CMR_CANCER_SOLID', 'CMR_DEMENTIA', 'CMR_DEPRESS', 'CMR_DIAB_UNCX', 'CMR_DIAB_CX', 'CMR_DRUG_ABUSE', 'CMR_HTN_CX', 'CMR_HTN_UNCX', 'CMR_LUNG_CHRONIC', 'CMR_OBESE', 'CMR_PERIVASC', 'CMR_THYROID_HYPO', 'CMR_THYROID_OTH', 'CMR_VERSION', 'DXCCSR_Default_DX1', 'DXCCSR_BLD001', 'DXCCSR_BLD002', 'DXCCSR_BLD003', 'DXCCSR_BLD004', 'DXCCSR_BLD005', 'DXCCSR_BLD006', 'DXCCSR_BLD007', 'DXCCSR_BLD008', 'DXCCSR_BLD009', 'DXCCSR_BLD010', 'DXCCSR_CIR001', 'DXCCSR_CIR002', 'DXCCSR_CIR003', 'DXCCSR_CIR004', 'DXCCSR_CIR005', 'DXCCSR_CIR006', 'DXCCSR_CIR007', 'DXCCSR_CIR008', 'DXCCSR_CIR009', 'DXCCSR_CIR010', 'DXCCSR_CIR011', 'DXCCSR_CIR012', 'DXCCSR_CIR013', 'DXCCSR_CIR014', 'DXCCSR_CIR015', 'DXCCSR_CIR016', 'DXCCSR_CIR017', 'DXCCSR_CIR018', 'DXCCSR_CIR019', 'DXCCSR_CIR020', 'DXCCSR_CIR021', 'DXCCSR_CIR022', 'DXCCSR_CIR023', 'DXCCSR_CIR024', 'DXCCSR_CIR025', 'DXCCSR_CIR026', 'DXCCSR_CIR027', 'DXCCSR_CIR028', 'DXCCSR_CIR029', 'DXCCSR_CIR030', 'DXCCSR_CIR031', 'DXCCSR_CIR032', 'DXCCSR_CIR033', 'DXCCSR_CIR034', 'DXCCSR_CIR035', 'DXCCSR_CIR036', 'DXCCSR_CIR037', 'DXCCSR_CIR038', 'DXCCSR_CIR039', 'DXCCSR_DIG001', 'DXCCSR_DIG002', 'DXCCSR_DIG003', 'DXCCSR_DIG004', 'DXCCSR_DIG005', 'DXCCSR_DIG006', 'DXCCSR_DIG007', 'DXCCSR_DIG008', 'DXCCSR_DIG009', 'DXCCSR_DIG010', 'DXCCSR_DIG011', 'DXCCSR_DIG012', 'DXCCSR_DIG013', 'DXCCSR_DIG014', 'DXCCSR_DIG015', 'DXCCSR_DIG016', 'DXCCSR_DIG017', 'DXCCSR_DIG018', 'DXCCSR_DIG019', 'DXCCSR_DIG020', 'DXCCSR_DIG021', 'DXCCSR_DIG022', 'DXCCSR_DIG023', 'DXCCSR_DIG024', 'DXCCSR_DIG025', 'DXCCSR_EAR001', 'DXCCSR_EAR002', 'DXCCSR_EAR003', 'DXCCSR_EAR004', 'DXCCSR_EAR005', 'DXCCSR_EAR006', 'DXCCSR_END001', 'DXCCSR_END002', 'DXCCSR_END003', 'DXCCSR_END004', 'DXCCSR_END005', 'DXCCSR_END006', 'DXCCSR_END007', 'DXCCSR_END008', 'DXCCSR_END009', 'DXCCSR_END010', 'DXCCSR_END011', 'DXCCSR_END012', 'DXCCSR_END013', 'DXCCSR_END014', 'DXCCSR_END015', 'DXCCSR_END016', 'DXCCSR_END017', 'DXCCSR_EXT001', 'DXCCSR_EXT002', 'DXCCSR_EXT003', 'DXCCSR_EXT004', 'DXCCSR_EXT005', 'DXCCSR_EXT006', 'DXCCSR_EXT007', 'DXCCSR_EXT008', 'DXCCSR_EXT009', 'DXCCSR_EXT010', 'DXCCSR_EXT011', 'DXCCSR_EXT012', 'DXCCSR_EXT013', 'DXCCSR_EXT014', 'DXCCSR_EXT015', 'DXCCSR_EXT016', 'DXCCSR_EXT017', 'DXCCSR_EXT018', 'DXCCSR_EXT019', 'DXCCSR_EXT020', 'DXCCSR_EXT021', 'DXCCSR_EXT022', 'DXCCSR_EXT023', 'DXCCSR_EXT024', 'DXCCSR_EXT025', 'DXCCSR_EXT026', 'DXCCSR_EXT027', 'DXCCSR_EXT028', 'DXCCSR_EXT029', 'DXCCSR_EXT030', 'DXCCSR_EYE001', 'DXCCSR_EYE002', 'DXCCSR_EYE003', 'DXCCSR_EYE004', 'DXCCSR_EYE005', 'DXCCSR_EYE006', 'DXCCSR_EYE007', 'DXCCSR_EYE008', 'DXCCSR_EYE009', 'DXCCSR_EYE010', 'DXCCSR_EYE011', 'DXCCSR_EYE012', 'DXCCSR_FAC001', 'DXCCSR_FAC002', 'DXCCSR_FAC003', 'DXCCSR_FAC004', 'DXCCSR_FAC005', 'DXCCSR_FAC006', 'DXCCSR_FAC007', 'DXCCSR_FAC008', 'DXCCSR_FAC009', 'DXCCSR_FAC010', 'DXCCSR_FAC011', 'DXCCSR_FAC012', 'DXCCSR_FAC013', 'DXCCSR_FAC014', 'DXCCSR_FAC015', 'DXCCSR_FAC016', 'DXCCSR_FAC017', 'DXCCSR_FAC018', 'DXCCSR_FAC019', 'DXCCSR_FAC020', 'DXCCSR_FAC021', 'DXCCSR_FAC022', 'DXCCSR_FAC023', 'DXCCSR_FAC024', 'DXCCSR_FAC025', 'DXCCSR_GEN001', 'DXCCSR_GEN002', 'DXCCSR_GEN003', 'DXCCSR_GEN004', 'DXCCSR_GEN005', 'DXCCSR_GEN006', 'DXCCSR_GEN007', 'DXCCSR_GEN008', 'DXCCSR_GEN009', 'DXCCSR_GEN010', 'DXCCSR_GEN011', 'DXCCSR_GEN012', 'DXCCSR_GEN013', 'DXCCSR_GEN014', 'DXCCSR_GEN015', 'DXCCSR_GEN016', 'DXCCSR_GEN017', 'DXCCSR_GEN018', 'DXCCSR_GEN019', 'DXCCSR_GEN020', 'DXCCSR_GEN021', 'DXCCSR_GEN022', 'DXCCSR_GEN023', 'DXCCSR_GEN024', 'DXCCSR_GEN025', 'DXCCSR_GEN026', 'DXCCSR_INF001', 'DXCCSR_INF002', 'DXCCSR_INF003', 'DXCCSR_INF004', 'DXCCSR_INF005', 'DXCCSR_INF006', 'DXCCSR_INF007', 'DXCCSR_INF008', 'DXCCSR_INF009', 'DXCCSR_INF010', 'DXCCSR_INF011', 'DXCCSR_INF012', 'DXCCSR_INJ001', 'DXCCSR_INJ002', 'DXCCSR_INJ003', 'DXCCSR_INJ004', 'DXCCSR_INJ005', 'DXCCSR_INJ006', 'DXCCSR_INJ007', 'DXCCSR_INJ008', 'DXCCSR_INJ009', 'DXCCSR_INJ010', 'DXCCSR_INJ011', 'DXCCSR_INJ012', 'DXCCSR_INJ013', 'DXCCSR_INJ014', 'DXCCSR_INJ015', 'DXCCSR_INJ016', 'DXCCSR_INJ017', 'DXCCSR_INJ018', 'DXCCSR_INJ019', 'DXCCSR_INJ020', 'DXCCSR_INJ021', 'DXCCSR_INJ022', 'DXCCSR_INJ023', 'DXCCSR_INJ024', 'DXCCSR_INJ025', 'DXCCSR_INJ026', 'DXCCSR_INJ027', 'DXCCSR_INJ028', 'DXCCSR_INJ029', 'DXCCSR_INJ030', 'DXCCSR_INJ031', 'DXCCSR_INJ032', 'DXCCSR_INJ033', 'DXCCSR_INJ034', 'DXCCSR_INJ035', 'DXCCSR_INJ036', 'DXCCSR_INJ037', 'DXCCSR_INJ038', 'DXCCSR_INJ039', 'DXCCSR_INJ040', 'DXCCSR_INJ041', 'DXCCSR_INJ042', 'DXCCSR_INJ043', 'DXCCSR_INJ044', 'DXCCSR_INJ045', 'DXCCSR_INJ046', 'DXCCSR_INJ047', 'DXCCSR_INJ048', 'DXCCSR_INJ049', 'DXCCSR_INJ050', 'DXCCSR_INJ051', 'DXCCSR_INJ052', 'DXCCSR_INJ053', 'DXCCSR_INJ054', 'DXCCSR_INJ055', 'DXCCSR_INJ056', 'DXCCSR_INJ057', 'DXCCSR_INJ058', 'DXCCSR_INJ059', 'DXCCSR_INJ060', 'DXCCSR_INJ061', 'DXCCSR_INJ062', 'DXCCSR_INJ063', 'DXCCSR_INJ064', 'DXCCSR_INJ065', 'DXCCSR_INJ066', 'DXCCSR_INJ067', 'DXCCSR_INJ068', 'DXCCSR_INJ069', 'DXCCSR_INJ070', 'DXCCSR_INJ071', 'DXCCSR_INJ072', 'DXCCSR_INJ073', 'DXCCSR_INJ074', 'DXCCSR_INJ075', 'DXCCSR_INJ076', 'DXCCSR_MAL001', 'DXCCSR_MAL002', 'DXCCSR_MAL003', 'DXCCSR_MAL004', 'DXCCSR_MAL005', 'DXCCSR_MAL006', 'DXCCSR_MAL007', 'DXCCSR_MAL008', 'DXCCSR_MAL009', 'DXCCSR_MAL010', 'DXCCSR_MBD001', 'DXCCSR_MBD002', 'DXCCSR_MBD003', 'DXCCSR_MBD004', 'DXCCSR_MBD005', 'DXCCSR_MBD006', 'DXCCSR_MBD007', 'DXCCSR_MBD008', 'DXCCSR_MBD009', 'DXCCSR_MBD010', 'DXCCSR_MBD011', 'DXCCSR_MBD012', 'DXCCSR_MBD013', 'DXCCSR_MBD014', 'DXCCSR_MBD017', 'DXCCSR_MBD018', 'DXCCSR_MBD019', 'DXCCSR_MBD020', 'DXCCSR_MBD021', 'DXCCSR_MBD022', 'DXCCSR_MBD023', 'DXCCSR_MBD024', 'DXCCSR_MBD025', 'DXCCSR_MBD026', 'DXCCSR_MBD027', 'DXCCSR_MBD028', 'DXCCSR_MBD029', 'DXCCSR_MBD030', 'DXCCSR_MBD031', 'DXCCSR_MBD032', 'DXCCSR_MBD033', 'DXCCSR_MBD034', 'DXCCSR_MUS001', 'DXCCSR_MUS002', 'DXCCSR_MUS003', 'DXCCSR_MUS004', 'DXCCSR_MUS005', 'DXCCSR_MUS006', 'DXCCSR_MUS007', 'DXCCSR_MUS008', 'DXCCSR_MUS009', 'DXCCSR_MUS010', 'DXCCSR_MUS011', 'DXCCSR_MUS012', 'DXCCSR_MUS013', 'DXCCSR_MUS014', 'DXCCSR_MUS015', 'DXCCSR_MUS016', 'DXCCSR_MUS017', 'DXCCSR_MUS018', 'DXCCSR_MUS019', 'DXCCSR_MUS020', 'DXCCSR_MUS021', 'DXCCSR_MUS022', 'DXCCSR_MUS023', 'DXCCSR_MUS024', 'DXCCSR_MUS025', 'DXCCSR_MUS026', 'DXCCSR_MUS027', 'DXCCSR_MUS028', 'DXCCSR_MUS029', 'DXCCSR_MUS030', 'DXCCSR_MUS031', 'DXCCSR_MUS032', 'DXCCSR_MUS033', 'DXCCSR_MUS034', 'DXCCSR_MUS035', 'DXCCSR_MUS036', 'DXCCSR_MUS037', 'DXCCSR_MUS038', 'DXCCSR_NEO001', 'DXCCSR_NEO002', 'DXCCSR_NEO003', 'DXCCSR_NEO004', 'DXCCSR_NEO005', 'DXCCSR_NEO006', 'DXCCSR_NEO007', 'DXCCSR_NEO008', 'DXCCSR_NEO009', 'DXCCSR_NEO010', 'DXCCSR_NEO011', 'DXCCSR_NEO012', 'DXCCSR_NEO013', 'DXCCSR_NEO014', 'DXCCSR_NEO015', 'DXCCSR_NEO016', 'DXCCSR_NEO017', 'DXCCSR_NEO018', 'DXCCSR_NEO019', 'DXCCSR_NEO020', 'DXCCSR_NEO021', 'DXCCSR_NEO022', 'DXCCSR_NEO023', 'DXCCSR_NEO024', 'DXCCSR_NEO025', 'DXCCSR_NEO026', 'DXCCSR_NEO027', 'DXCCSR_NEO028', 'DXCCSR_NEO029', 'DXCCSR_NEO030', 'DXCCSR_NEO031', 'DXCCSR_NEO032', 'DXCCSR_NEO033', 'DXCCSR_NEO034', 'DXCCSR_NEO035', 'DXCCSR_NEO036', 'DXCCSR_NEO037', 'DXCCSR_NEO038', 'DXCCSR_NEO039', 'DXCCSR_NEO040', 'DXCCSR_NEO041', 'DXCCSR_NEO042', 'DXCCSR_NEO043', 'DXCCSR_NEO044', 'DXCCSR_NEO045', 'DXCCSR_NEO046', 'DXCCSR_NEO047', 'DXCCSR_NEO048', 'DXCCSR_NEO049', 'DXCCSR_NEO050', 'DXCCSR_NEO051', 'DXCCSR_NEO052', 'DXCCSR_NEO053', 'DXCCSR_NEO054', 'DXCCSR_NEO055', 'DXCCSR_NEO056', 'DXCCSR_NEO057', 'DXCCSR_NEO058', 'DXCCSR_NEO059', 'DXCCSR_NEO060', 'DXCCSR_NEO061', 'DXCCSR_NEO062', 'DXCCSR_NEO063', 'DXCCSR_NEO064', 'DXCCSR_NEO065', 'DXCCSR_NEO066', 'DXCCSR_NEO067', 'DXCCSR_NEO068', 'DXCCSR_NEO069', 'DXCCSR_NEO070', 'DXCCSR_NEO071', 'DXCCSR_NEO072', 'DXCCSR_NEO073', 'DXCCSR_NEO074', 'DXCCSR_NVS001', 'DXCCSR_NVS002', 'DXCCSR_NVS003', 'DXCCSR_NVS004', 'DXCCSR_NVS005', 'DXCCSR_NVS006', 'DXCCSR_NVS007', 'DXCCSR_NVS008', 'DXCCSR_NVS009', 'DXCCSR_NVS010', 'DXCCSR_NVS011', 'DXCCSR_NVS012', 'DXCCSR_NVS013', 'DXCCSR_NVS014', 'DXCCSR_NVS015', 'DXCCSR_NVS016', 'DXCCSR_NVS017', 'DXCCSR_NVS018', 'DXCCSR_NVS019', 'DXCCSR_NVS020', 'DXCCSR_NVS021', 'DXCCSR_NVS022', 'DXCCSR_PNL001', 'DXCCSR_PNL002', 'DXCCSR_PNL003', 'DXCCSR_PNL004', 'DXCCSR_PNL005', 'DXCCSR_PNL006', 'DXCCSR_PNL007', 'DXCCSR_PNL008', 'DXCCSR_PNL009', 'DXCCSR_PNL010', 'DXCCSR_PNL011', 'DXCCSR_PNL012', 'DXCCSR_PNL013', 'DXCCSR_PNL014', 'DXCCSR_PNL015', 'DXCCSR_PRG001', 'DXCCSR_PRG002', 'DXCCSR_PRG003', 'DXCCSR_PRG004', 'DXCCSR_PRG005', 'DXCCSR_PRG006', 'DXCCSR_PRG007', 'DXCCSR_PRG008', 'DXCCSR_PRG009', 'DXCCSR_PRG010', 'DXCCSR_PRG011', 'DXCCSR_PRG012', 'DXCCSR_PRG013', 'DXCCSR_PRG014', 'DXCCSR_PRG015', 'DXCCSR_PRG016', 'DXCCSR_PRG017', 'DXCCSR_PRG018', 'DXCCSR_PRG019', 'DXCCSR_PRG020', 'DXCCSR_PRG021', 'DXCCSR_PRG022', 'DXCCSR_PRG023', 'DXCCSR_PRG024', 'DXCCSR_PRG025', 'DXCCSR_PRG026', 'DXCCSR_PRG027', 'DXCCSR_PRG028', 'DXCCSR_PRG029', 'DXCCSR_PRG030', 'DXCCSR_RSP001', 'DXCCSR_RSP002', 'DXCCSR_RSP003', 'DXCCSR_RSP004', 'DXCCSR_RSP005', 'DXCCSR_RSP006', 'DXCCSR_RSP007', 'DXCCSR_RSP008', 'DXCCSR_RSP009', 'DXCCSR_RSP010', 'DXCCSR_RSP011', 'DXCCSR_RSP012', 'DXCCSR_RSP013', 'DXCCSR_RSP014', 'DXCCSR_RSP015', 'DXCCSR_RSP016', 'DXCCSR_RSP017', 'DXCCSR_SKN001', 'DXCCSR_SKN002', 'DXCCSR_SKN003', 'DXCCSR_SKN004', 'DXCCSR_SKN005', 'DXCCSR_SKN006', 'DXCCSR_SKN007', 'DXCCSR_SYM001', 'DXCCSR_SYM002', 'DXCCSR_SYM003', 'DXCCSR_SYM004', 'DXCCSR_SYM005', 'DXCCSR_SYM006', 'DXCCSR_SYM007', 'DXCCSR_SYM008', 'DXCCSR_SYM009', 'DXCCSR_SYM010', 'DXCCSR_SYM011', 'DXCCSR_SYM012', 'DXCCSR_SYM013', 'DXCCSR_SYM014', 'DXCCSR_SYM015', 'DXCCSR_SYM016', 'DXCCSR_SYM017', 'DXCCSR_VERSION', 'AGEGRP', 'AGEGRP2']\n",
      "\n",
      "First 3 rows:\n",
      "   KEY_NASS  HOSP_NASS  HOSP_TEACH  HOSP_LOCATION  HOSP_LOCTEACH  HOSP_REGION  \\\n",
      "0  90000001      40053           1              1              3            4   \n",
      "1  90000002      20162           0              1              2            2   \n",
      "2  90000003      30223           1              1              3            3   \n",
      "\n",
      "   HOSP_BEDSIZE_CAT    DISCWT  NASS_STRATUM  N_DISC_U  ...  DXCCSR_SYM011  \\\n",
      "0                 2  1.579073             9    321406  ...              0   \n",
      "1                 2  1.031092            49    152635  ...              0   \n",
      "2                 3  1.245274             7    837566  ...              0   \n",
      "\n",
      "   DXCCSR_SYM012  DXCCSR_SYM013  DXCCSR_SYM014  DXCCSR_SYM015  DXCCSR_SYM016  \\\n",
      "0              0              0              0              0              0   \n",
      "1              0              0              0              0              0   \n",
      "2              0              0              0              0              0   \n",
      "\n",
      "   DXCCSR_SYM017  DXCCSR_VERSION  AGEGRP  AGEGRP2  \n",
      "0              0          2022.1    0-17     0-17  \n",
      "1              0          2022.1   18-64    40-54  \n",
      "2              0          2022.1   18-64    55-64  \n",
      "\n",
      "[3 rows x 675 columns]\n",
      "   Memory: 885.2 MB\n",
      "\n",
      "Columns: ['KEY_NASS', 'HOSP_NASS', 'HOSP_TEACH', 'HOSP_LOCATION', 'HOSP_LOCTEACH', 'HOSP_REGION', 'HOSP_BEDSIZE_CAT', 'DISCWT', 'NASS_STRATUM', 'N_DISC_U', 'N_HOSP_U', 'S_DISC_U', 'S_HOSP_U', 'TOTAL_AS_ENCOUNTERS', 'YEAR', 'AGE', 'FEMALE', 'PL_NCHS', 'ZIPINC_QRTL', 'AMONTH', 'AWEEKEND', 'DQTR', 'PAY1', 'DISPUNIFORM', 'TOTCHG', 'NCPT_INSCOPE', 'CPTCCS1', 'CPTCCS2', 'CPTCCS3', 'CPTCCS4', 'CPTCCS5', 'CPTCCS6', 'CPTCCS7', 'CPTCCS8', 'CPTCCS9', 'CPTCCS10', 'CPTCCS11', 'CPTCCS12', 'CPTCCS13', 'CPTCCS14', 'CPTCCS15', 'CPTCCS16', 'CPTCCS17', 'CPTCCS18', 'CPTCCS19', 'CPTCCS20', 'CPTCCS21', 'CPTCCS22', 'CPTCCS23', 'CPTCCS24', 'CPTCCS25', 'CPTCCS26', 'CPTCCS27', 'CPTCCS28', 'CPTCCS29', 'CPTCCS30', 'CPT1', 'CPT2', 'CPT3', 'CPT4', 'CPT5', 'CPT6', 'CPT7', 'CPT8', 'CPT9', 'CPT10', 'CPT11', 'CPT12', 'CPT13', 'CPT14', 'CPT15', 'CPT16', 'CPT17', 'CPT18', 'CPT19', 'CPT20', 'CPT21', 'CPT22', 'CPT23', 'CPT24', 'CPT25', 'CPT26', 'CPT27', 'CPT28', 'CPT29', 'CPT30', 'I10_NDX', 'I10_DX1', 'I10_DX2', 'I10_DX3', 'I10_DX4', 'I10_DX5', 'I10_DX6', 'I10_DX7', 'I10_DX8', 'I10_DX9', 'I10_DX10', 'I10_DX11', 'I10_DX12', 'I10_DX13', 'I10_DX14', 'I10_DX15', 'I10_DX16', 'I10_DX17', 'I10_DX18', 'I10_DX19', 'I10_DX20', 'RACE', 'I10_INJURY', 'I10_MULTINJURY', 'CMR_AIDS', 'CMR_ALCOHOL', 'CMR_AUTOIMMUNE', 'CMR_CANCER_LYMPH', 'CMR_CANCER_LEUK', 'CMR_CANCER_METS', 'CMR_CANCER_NSITU', 'CMR_CANCER_SOLID', 'CMR_DEMENTIA', 'CMR_DEPRESS', 'CMR_DIAB_UNCX', 'CMR_DIAB_CX', 'CMR_DRUG_ABUSE', 'CMR_HTN_CX', 'CMR_HTN_UNCX', 'CMR_LUNG_CHRONIC', 'CMR_OBESE', 'CMR_PERIVASC', 'CMR_THYROID_HYPO', 'CMR_THYROID_OTH', 'CMR_VERSION', 'DXCCSR_Default_DX1', 'DXCCSR_BLD001', 'DXCCSR_BLD002', 'DXCCSR_BLD003', 'DXCCSR_BLD004', 'DXCCSR_BLD005', 'DXCCSR_BLD006', 'DXCCSR_BLD007', 'DXCCSR_BLD008', 'DXCCSR_BLD009', 'DXCCSR_BLD010', 'DXCCSR_CIR001', 'DXCCSR_CIR002', 'DXCCSR_CIR003', 'DXCCSR_CIR004', 'DXCCSR_CIR005', 'DXCCSR_CIR006', 'DXCCSR_CIR007', 'DXCCSR_CIR008', 'DXCCSR_CIR009', 'DXCCSR_CIR010', 'DXCCSR_CIR011', 'DXCCSR_CIR012', 'DXCCSR_CIR013', 'DXCCSR_CIR014', 'DXCCSR_CIR015', 'DXCCSR_CIR016', 'DXCCSR_CIR017', 'DXCCSR_CIR018', 'DXCCSR_CIR019', 'DXCCSR_CIR020', 'DXCCSR_CIR021', 'DXCCSR_CIR022', 'DXCCSR_CIR023', 'DXCCSR_CIR024', 'DXCCSR_CIR025', 'DXCCSR_CIR026', 'DXCCSR_CIR027', 'DXCCSR_CIR028', 'DXCCSR_CIR029', 'DXCCSR_CIR030', 'DXCCSR_CIR031', 'DXCCSR_CIR032', 'DXCCSR_CIR033', 'DXCCSR_CIR034', 'DXCCSR_CIR035', 'DXCCSR_CIR036', 'DXCCSR_CIR037', 'DXCCSR_CIR038', 'DXCCSR_CIR039', 'DXCCSR_DIG001', 'DXCCSR_DIG002', 'DXCCSR_DIG003', 'DXCCSR_DIG004', 'DXCCSR_DIG005', 'DXCCSR_DIG006', 'DXCCSR_DIG007', 'DXCCSR_DIG008', 'DXCCSR_DIG009', 'DXCCSR_DIG010', 'DXCCSR_DIG011', 'DXCCSR_DIG012', 'DXCCSR_DIG013', 'DXCCSR_DIG014', 'DXCCSR_DIG015', 'DXCCSR_DIG016', 'DXCCSR_DIG017', 'DXCCSR_DIG018', 'DXCCSR_DIG019', 'DXCCSR_DIG020', 'DXCCSR_DIG021', 'DXCCSR_DIG022', 'DXCCSR_DIG023', 'DXCCSR_DIG024', 'DXCCSR_DIG025', 'DXCCSR_EAR001', 'DXCCSR_EAR002', 'DXCCSR_EAR003', 'DXCCSR_EAR004', 'DXCCSR_EAR005', 'DXCCSR_EAR006', 'DXCCSR_END001', 'DXCCSR_END002', 'DXCCSR_END003', 'DXCCSR_END004', 'DXCCSR_END005', 'DXCCSR_END006', 'DXCCSR_END007', 'DXCCSR_END008', 'DXCCSR_END009', 'DXCCSR_END010', 'DXCCSR_END011', 'DXCCSR_END012', 'DXCCSR_END013', 'DXCCSR_END014', 'DXCCSR_END015', 'DXCCSR_END016', 'DXCCSR_END017', 'DXCCSR_EXT001', 'DXCCSR_EXT002', 'DXCCSR_EXT003', 'DXCCSR_EXT004', 'DXCCSR_EXT005', 'DXCCSR_EXT006', 'DXCCSR_EXT007', 'DXCCSR_EXT008', 'DXCCSR_EXT009', 'DXCCSR_EXT010', 'DXCCSR_EXT011', 'DXCCSR_EXT012', 'DXCCSR_EXT013', 'DXCCSR_EXT014', 'DXCCSR_EXT015', 'DXCCSR_EXT016', 'DXCCSR_EXT017', 'DXCCSR_EXT018', 'DXCCSR_EXT019', 'DXCCSR_EXT020', 'DXCCSR_EXT021', 'DXCCSR_EXT022', 'DXCCSR_EXT023', 'DXCCSR_EXT024', 'DXCCSR_EXT025', 'DXCCSR_EXT026', 'DXCCSR_EXT027', 'DXCCSR_EXT028', 'DXCCSR_EXT029', 'DXCCSR_EXT030', 'DXCCSR_EYE001', 'DXCCSR_EYE002', 'DXCCSR_EYE003', 'DXCCSR_EYE004', 'DXCCSR_EYE005', 'DXCCSR_EYE006', 'DXCCSR_EYE007', 'DXCCSR_EYE008', 'DXCCSR_EYE009', 'DXCCSR_EYE010', 'DXCCSR_EYE011', 'DXCCSR_EYE012', 'DXCCSR_FAC001', 'DXCCSR_FAC002', 'DXCCSR_FAC003', 'DXCCSR_FAC004', 'DXCCSR_FAC005', 'DXCCSR_FAC006', 'DXCCSR_FAC007', 'DXCCSR_FAC008', 'DXCCSR_FAC009', 'DXCCSR_FAC010', 'DXCCSR_FAC011', 'DXCCSR_FAC012', 'DXCCSR_FAC013', 'DXCCSR_FAC014', 'DXCCSR_FAC015', 'DXCCSR_FAC016', 'DXCCSR_FAC017', 'DXCCSR_FAC018', 'DXCCSR_FAC019', 'DXCCSR_FAC020', 'DXCCSR_FAC021', 'DXCCSR_FAC022', 'DXCCSR_FAC023', 'DXCCSR_FAC024', 'DXCCSR_FAC025', 'DXCCSR_GEN001', 'DXCCSR_GEN002', 'DXCCSR_GEN003', 'DXCCSR_GEN004', 'DXCCSR_GEN005', 'DXCCSR_GEN006', 'DXCCSR_GEN007', 'DXCCSR_GEN008', 'DXCCSR_GEN009', 'DXCCSR_GEN010', 'DXCCSR_GEN011', 'DXCCSR_GEN012', 'DXCCSR_GEN013', 'DXCCSR_GEN014', 'DXCCSR_GEN015', 'DXCCSR_GEN016', 'DXCCSR_GEN017', 'DXCCSR_GEN018', 'DXCCSR_GEN019', 'DXCCSR_GEN020', 'DXCCSR_GEN021', 'DXCCSR_GEN022', 'DXCCSR_GEN023', 'DXCCSR_GEN024', 'DXCCSR_GEN025', 'DXCCSR_GEN026', 'DXCCSR_INF001', 'DXCCSR_INF002', 'DXCCSR_INF003', 'DXCCSR_INF004', 'DXCCSR_INF005', 'DXCCSR_INF006', 'DXCCSR_INF007', 'DXCCSR_INF008', 'DXCCSR_INF009', 'DXCCSR_INF010', 'DXCCSR_INF011', 'DXCCSR_INF012', 'DXCCSR_INJ001', 'DXCCSR_INJ002', 'DXCCSR_INJ003', 'DXCCSR_INJ004', 'DXCCSR_INJ005', 'DXCCSR_INJ006', 'DXCCSR_INJ007', 'DXCCSR_INJ008', 'DXCCSR_INJ009', 'DXCCSR_INJ010', 'DXCCSR_INJ011', 'DXCCSR_INJ012', 'DXCCSR_INJ013', 'DXCCSR_INJ014', 'DXCCSR_INJ015', 'DXCCSR_INJ016', 'DXCCSR_INJ017', 'DXCCSR_INJ018', 'DXCCSR_INJ019', 'DXCCSR_INJ020', 'DXCCSR_INJ021', 'DXCCSR_INJ022', 'DXCCSR_INJ023', 'DXCCSR_INJ024', 'DXCCSR_INJ025', 'DXCCSR_INJ026', 'DXCCSR_INJ027', 'DXCCSR_INJ028', 'DXCCSR_INJ029', 'DXCCSR_INJ030', 'DXCCSR_INJ031', 'DXCCSR_INJ032', 'DXCCSR_INJ033', 'DXCCSR_INJ034', 'DXCCSR_INJ035', 'DXCCSR_INJ036', 'DXCCSR_INJ037', 'DXCCSR_INJ038', 'DXCCSR_INJ039', 'DXCCSR_INJ040', 'DXCCSR_INJ041', 'DXCCSR_INJ042', 'DXCCSR_INJ043', 'DXCCSR_INJ044', 'DXCCSR_INJ045', 'DXCCSR_INJ046', 'DXCCSR_INJ047', 'DXCCSR_INJ048', 'DXCCSR_INJ049', 'DXCCSR_INJ050', 'DXCCSR_INJ051', 'DXCCSR_INJ052', 'DXCCSR_INJ053', 'DXCCSR_INJ054', 'DXCCSR_INJ055', 'DXCCSR_INJ056', 'DXCCSR_INJ057', 'DXCCSR_INJ058', 'DXCCSR_INJ059', 'DXCCSR_INJ060', 'DXCCSR_INJ061', 'DXCCSR_INJ062', 'DXCCSR_INJ063', 'DXCCSR_INJ064', 'DXCCSR_INJ065', 'DXCCSR_INJ066', 'DXCCSR_INJ067', 'DXCCSR_INJ068', 'DXCCSR_INJ069', 'DXCCSR_INJ070', 'DXCCSR_INJ071', 'DXCCSR_INJ072', 'DXCCSR_INJ073', 'DXCCSR_INJ074', 'DXCCSR_INJ075', 'DXCCSR_INJ076', 'DXCCSR_MAL001', 'DXCCSR_MAL002', 'DXCCSR_MAL003', 'DXCCSR_MAL004', 'DXCCSR_MAL005', 'DXCCSR_MAL006', 'DXCCSR_MAL007', 'DXCCSR_MAL008', 'DXCCSR_MAL009', 'DXCCSR_MAL010', 'DXCCSR_MBD001', 'DXCCSR_MBD002', 'DXCCSR_MBD003', 'DXCCSR_MBD004', 'DXCCSR_MBD005', 'DXCCSR_MBD006', 'DXCCSR_MBD007', 'DXCCSR_MBD008', 'DXCCSR_MBD009', 'DXCCSR_MBD010', 'DXCCSR_MBD011', 'DXCCSR_MBD012', 'DXCCSR_MBD013', 'DXCCSR_MBD014', 'DXCCSR_MBD017', 'DXCCSR_MBD018', 'DXCCSR_MBD019', 'DXCCSR_MBD020', 'DXCCSR_MBD021', 'DXCCSR_MBD022', 'DXCCSR_MBD023', 'DXCCSR_MBD024', 'DXCCSR_MBD025', 'DXCCSR_MBD026', 'DXCCSR_MBD027', 'DXCCSR_MBD028', 'DXCCSR_MBD029', 'DXCCSR_MBD030', 'DXCCSR_MBD031', 'DXCCSR_MBD032', 'DXCCSR_MBD033', 'DXCCSR_MBD034', 'DXCCSR_MUS001', 'DXCCSR_MUS002', 'DXCCSR_MUS003', 'DXCCSR_MUS004', 'DXCCSR_MUS005', 'DXCCSR_MUS006', 'DXCCSR_MUS007', 'DXCCSR_MUS008', 'DXCCSR_MUS009', 'DXCCSR_MUS010', 'DXCCSR_MUS011', 'DXCCSR_MUS012', 'DXCCSR_MUS013', 'DXCCSR_MUS014', 'DXCCSR_MUS015', 'DXCCSR_MUS016', 'DXCCSR_MUS017', 'DXCCSR_MUS018', 'DXCCSR_MUS019', 'DXCCSR_MUS020', 'DXCCSR_MUS021', 'DXCCSR_MUS022', 'DXCCSR_MUS023', 'DXCCSR_MUS024', 'DXCCSR_MUS025', 'DXCCSR_MUS026', 'DXCCSR_MUS027', 'DXCCSR_MUS028', 'DXCCSR_MUS029', 'DXCCSR_MUS030', 'DXCCSR_MUS031', 'DXCCSR_MUS032', 'DXCCSR_MUS033', 'DXCCSR_MUS034', 'DXCCSR_MUS035', 'DXCCSR_MUS036', 'DXCCSR_MUS037', 'DXCCSR_MUS038', 'DXCCSR_NEO001', 'DXCCSR_NEO002', 'DXCCSR_NEO003', 'DXCCSR_NEO004', 'DXCCSR_NEO005', 'DXCCSR_NEO006', 'DXCCSR_NEO007', 'DXCCSR_NEO008', 'DXCCSR_NEO009', 'DXCCSR_NEO010', 'DXCCSR_NEO011', 'DXCCSR_NEO012', 'DXCCSR_NEO013', 'DXCCSR_NEO014', 'DXCCSR_NEO015', 'DXCCSR_NEO016', 'DXCCSR_NEO017', 'DXCCSR_NEO018', 'DXCCSR_NEO019', 'DXCCSR_NEO020', 'DXCCSR_NEO021', 'DXCCSR_NEO022', 'DXCCSR_NEO023', 'DXCCSR_NEO024', 'DXCCSR_NEO025', 'DXCCSR_NEO026', 'DXCCSR_NEO027', 'DXCCSR_NEO028', 'DXCCSR_NEO029', 'DXCCSR_NEO030', 'DXCCSR_NEO031', 'DXCCSR_NEO032', 'DXCCSR_NEO033', 'DXCCSR_NEO034', 'DXCCSR_NEO035', 'DXCCSR_NEO036', 'DXCCSR_NEO037', 'DXCCSR_NEO038', 'DXCCSR_NEO039', 'DXCCSR_NEO040', 'DXCCSR_NEO041', 'DXCCSR_NEO042', 'DXCCSR_NEO043', 'DXCCSR_NEO044', 'DXCCSR_NEO045', 'DXCCSR_NEO046', 'DXCCSR_NEO047', 'DXCCSR_NEO048', 'DXCCSR_NEO049', 'DXCCSR_NEO050', 'DXCCSR_NEO051', 'DXCCSR_NEO052', 'DXCCSR_NEO053', 'DXCCSR_NEO054', 'DXCCSR_NEO055', 'DXCCSR_NEO056', 'DXCCSR_NEO057', 'DXCCSR_NEO058', 'DXCCSR_NEO059', 'DXCCSR_NEO060', 'DXCCSR_NEO061', 'DXCCSR_NEO062', 'DXCCSR_NEO063', 'DXCCSR_NEO064', 'DXCCSR_NEO065', 'DXCCSR_NEO066', 'DXCCSR_NEO067', 'DXCCSR_NEO068', 'DXCCSR_NEO069', 'DXCCSR_NEO070', 'DXCCSR_NEO071', 'DXCCSR_NEO072', 'DXCCSR_NEO073', 'DXCCSR_NEO074', 'DXCCSR_NVS001', 'DXCCSR_NVS002', 'DXCCSR_NVS003', 'DXCCSR_NVS004', 'DXCCSR_NVS005', 'DXCCSR_NVS006', 'DXCCSR_NVS007', 'DXCCSR_NVS008', 'DXCCSR_NVS009', 'DXCCSR_NVS010', 'DXCCSR_NVS011', 'DXCCSR_NVS012', 'DXCCSR_NVS013', 'DXCCSR_NVS014', 'DXCCSR_NVS015', 'DXCCSR_NVS016', 'DXCCSR_NVS017', 'DXCCSR_NVS018', 'DXCCSR_NVS019', 'DXCCSR_NVS020', 'DXCCSR_NVS021', 'DXCCSR_NVS022', 'DXCCSR_PNL001', 'DXCCSR_PNL002', 'DXCCSR_PNL003', 'DXCCSR_PNL004', 'DXCCSR_PNL005', 'DXCCSR_PNL006', 'DXCCSR_PNL007', 'DXCCSR_PNL008', 'DXCCSR_PNL009', 'DXCCSR_PNL010', 'DXCCSR_PNL011', 'DXCCSR_PNL012', 'DXCCSR_PNL013', 'DXCCSR_PNL014', 'DXCCSR_PNL015', 'DXCCSR_PRG001', 'DXCCSR_PRG002', 'DXCCSR_PRG003', 'DXCCSR_PRG004', 'DXCCSR_PRG005', 'DXCCSR_PRG006', 'DXCCSR_PRG007', 'DXCCSR_PRG008', 'DXCCSR_PRG009', 'DXCCSR_PRG010', 'DXCCSR_PRG011', 'DXCCSR_PRG012', 'DXCCSR_PRG013', 'DXCCSR_PRG014', 'DXCCSR_PRG015', 'DXCCSR_PRG016', 'DXCCSR_PRG017', 'DXCCSR_PRG018', 'DXCCSR_PRG019', 'DXCCSR_PRG020', 'DXCCSR_PRG021', 'DXCCSR_PRG022', 'DXCCSR_PRG023', 'DXCCSR_PRG024', 'DXCCSR_PRG025', 'DXCCSR_PRG026', 'DXCCSR_PRG027', 'DXCCSR_PRG028', 'DXCCSR_PRG029', 'DXCCSR_PRG030', 'DXCCSR_RSP001', 'DXCCSR_RSP002', 'DXCCSR_RSP003', 'DXCCSR_RSP004', 'DXCCSR_RSP005', 'DXCCSR_RSP006', 'DXCCSR_RSP007', 'DXCCSR_RSP008', 'DXCCSR_RSP009', 'DXCCSR_RSP010', 'DXCCSR_RSP011', 'DXCCSR_RSP012', 'DXCCSR_RSP013', 'DXCCSR_RSP014', 'DXCCSR_RSP015', 'DXCCSR_RSP016', 'DXCCSR_RSP017', 'DXCCSR_SKN001', 'DXCCSR_SKN002', 'DXCCSR_SKN003', 'DXCCSR_SKN004', 'DXCCSR_SKN005', 'DXCCSR_SKN006', 'DXCCSR_SKN007', 'DXCCSR_SYM001', 'DXCCSR_SYM002', 'DXCCSR_SYM003', 'DXCCSR_SYM004', 'DXCCSR_SYM005', 'DXCCSR_SYM006', 'DXCCSR_SYM007', 'DXCCSR_SYM008', 'DXCCSR_SYM009', 'DXCCSR_SYM010', 'DXCCSR_SYM011', 'DXCCSR_SYM012', 'DXCCSR_SYM013', 'DXCCSR_SYM014', 'DXCCSR_SYM015', 'DXCCSR_SYM016', 'DXCCSR_SYM017', 'DXCCSR_VERSION', 'AGEGRP', 'AGEGRP2']\n",
      "\n",
      "First 3 rows:\n",
      "   KEY_NASS  HOSP_NASS  HOSP_TEACH  HOSP_LOCATION  HOSP_LOCTEACH  HOSP_REGION  \\\n",
      "0  90000001      40053           1              1              3            4   \n",
      "1  90000002      20162           0              1              2            2   \n",
      "2  90000003      30223           1              1              3            3   \n",
      "\n",
      "   HOSP_BEDSIZE_CAT    DISCWT  NASS_STRATUM  N_DISC_U  ...  DXCCSR_SYM011  \\\n",
      "0                 2  1.579073             9    321406  ...              0   \n",
      "1                 2  1.031092            49    152635  ...              0   \n",
      "2                 3  1.245274             7    837566  ...              0   \n",
      "\n",
      "   DXCCSR_SYM012  DXCCSR_SYM013  DXCCSR_SYM014  DXCCSR_SYM015  DXCCSR_SYM016  \\\n",
      "0              0              0              0              0              0   \n",
      "1              0              0              0              0              0   \n",
      "2              0              0              0              0              0   \n",
      "\n",
      "   DXCCSR_SYM017  DXCCSR_VERSION  AGEGRP  AGEGRP2  \n",
      "0              0          2022.1    0-17     0-17  \n",
      "1              0          2022.1   18-64    40-54  \n",
      "2              0          2022.1   18-64    55-64  \n",
      "\n",
      "[3 rows x 675 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self):\n",
    "        self.base_path = Path('/content') if env_manager.is_colab else Path.home()\n",
    "        self.data_dir = self.base_path / 'data'\n",
    "        self.data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"Load data based on configuration\"\"\"\n",
    "        loaders = {\n",
    "            'github': self._load_github,\n",
    "            'local': self._load_local,\n",
    "            'gcs': self._load_gcs,\n",
    "            'drive': self._load_drive\n",
    "        }\n",
    "\n",
    "        if DATA_SOURCE not in loaders:\n",
    "            raise ValueError(f\"Invalid DATA_SOURCE: {DATA_SOURCE}\")\n",
    "\n",
    "        print(f\"Loading data from: {DATA_SOURCE.upper()}\")\n",
    "        return loaders[DATA_SOURCE]()\n",
    "\n",
    "    def _load_github(self):\n",
    "        \"\"\"Load from GitHub releases\"\"\"\n",
    "        response = requests.get(GITHUB_URL, timeout=60)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        data_path = self.data_dir / \"nass_data.csv\"\n",
    "        data_path.write_bytes(response.content)\n",
    "\n",
    "        print(f\"✓ Downloaded from GitHub ({response.headers.get('content-length', 'unknown')} bytes)\")\n",
    "        return pd.read_csv(data_path)\n",
    "\n",
    "    def _load_local(self):\n",
    "        \"\"\"Load from local file\"\"\"\n",
    "        search_paths = [\n",
    "            self.base_path / LOCAL_FILENAME,\n",
    "            self.data_dir / LOCAL_FILENAME,\n",
    "            Path.cwd() / LOCAL_FILENAME\n",
    "        ]\n",
    "\n",
    "        for path in search_paths:\n",
    "            if path.exists():\n",
    "                print(f\"✓ Found local file: {path}\")\n",
    "                return pd.read_csv(path)\n",
    "\n",
    "        raise FileNotFoundError(f\"File not found in: {[str(p) for p in search_paths]}\")\n",
    "\n",
    "    def _load_gcs(self):\n",
    "        \"\"\"Load from Google Cloud Storage\"\"\"\n",
    "        from google.cloud import storage\n",
    "\n",
    "        # Smart authentication\n",
    "        if Path(GCS_SERVICE_ACCOUNT_KEY).exists():\n",
    "            client = storage.Client.from_service_account_json(GCS_SERVICE_ACCOUNT_KEY)\n",
    "        else:\n",
    "            client = storage.Client()  # Use default credentials\n",
    "\n",
    "        bucket = client.bucket(GCS_BUCKET)\n",
    "        blob = bucket.blob(GCS_BLOB)\n",
    "\n",
    "        data_path = self.data_dir / \"nass_data.csv\"\n",
    "        blob.download_to_filename(data_path)\n",
    "\n",
    "        print(f\"✓ Downloaded from GCS: {GCS_BUCKET}/{GCS_BLOB}\")\n",
    "        return pd.read_csv(data_path)\n",
    "\n",
    "    def _load_drive(self):\n",
    "        \"\"\"Load from Google Drive (Colab only)\"\"\"\n",
    "        if not env_manager.is_colab:\n",
    "            raise RuntimeError(\"Drive loading only available in Google Colab\")\n",
    "\n",
    "        drive_path = Path(DRIVE_PATH)\n",
    "        if not drive_path.exists():\n",
    "            raise FileNotFoundError(f\"Drive file not found: {DRIVE_PATH}\")\n",
    "\n",
    "        print(f\"✓ Loading from Google Drive: {DRIVE_PATH}\")\n",
    "        return pd.read_csv(drive_path)\n",
    "\n",
    "# Load data\n",
    "try:\n",
    "    loader = DataLoader()\n",
    "    df = loader.load_data()\n",
    "\n",
    "    print(f\"✅ Data loaded successfully!\")\n",
    "    print(f\"   Shape: {df.shape}\")\n",
    "    print(f\"   Memory: {df.memory_usage(deep=True).sum() / 1e6:.1f} MB\")\n",
    "\n",
    "    if VERBOSE_PRINTS:\n",
    "        print(f\"\\nColumns: {list(df.columns)}\")\n",
    "        print(f\"\\nFirst 3 rows:\")\n",
    "        print(df.head(3))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Data loading failed: {e}\")\n",
    "    print(f\"💡 Try changing DATA_SOURCE or check file paths\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HxQ5fG5grPrj"
   },
   "source": [
    "Check if data has been loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "FqUzCuZOrPrj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data verified: 139,233 rows x 675 columns\n",
      "✅ Ready for R analysis\n"
     ]
    }
   ],
   "source": [
    "# Verify data is available before R processing\n",
    "try:\n",
    "    if 'df' not in globals():\n",
    "        print(\"❌ Data not loaded!\")\n",
    "        print(\"💡 Please run the 'Data Loading' section first (cell 12)\")\n",
    "        print(\"   This will create the 'df' variable needed for R analysis\")\n",
    "        raise NameError(\"df variable not found - run data loading first\")\n",
    "\n",
    "    print(f\"✅ Data verified: {df.shape[0]:,} rows x {df.shape[1]} columns\")\n",
    "    print(\"✅ Ready for R analysis\")\n",
    "\n",
    "except NameError as e:\n",
    "    print(f\"❌ {e}\")\n",
    "    print(\"\\n🔄 Quick fix: Run these cells in order:\")\n",
    "    print(\"   1. Configuration (cell 5)\")\n",
    "    print(\"   2. Environment Setup (cell 7)\")\n",
    "    print(\"   3. Data Loading (cell 12)\")\n",
    "    print(\"   4. Then continue with R analysis\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3j3Ms-OArPrj"
   },
   "source": [
    "## 5. Complete Data Preprocessing\n",
    "\n",
    "Streamlined preprocessing: remove variables, clean data types, and create new variables - in Python prior to passing to R for efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "GQzhWzohrPrj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete preprocessing: removing variables + cleaning data types...\n",
      "Original shape: (139233, 675)\n",
      "\n",
      "1 Removing unnecessary variables...\n",
      "   📊 Found 600 columns to drop\n",
      "   🗑️  Patterns: CPTCCS2-30, CPT2-30, all DXCCSR_*\n",
      "   ✅ Reduced from 675 to 75 columns\n",
      "\n",
      "2️⃣ Cleaning data types for rpy2 compatibility...\n",
      "   ✅ Converted 23 object columns to strings\n",
      "   ✅ Cleaned inf values in 3 float columns\n",
      "\n",
      "3️⃣ Creating analytical variables...\n",
      "   ✅ Converted 23 object columns to strings\n",
      "   ✅ Cleaned inf values in 3 float columns\n",
      "\n",
      "3️⃣ Creating analytical variables...\n",
      "   ✅ Created a race indicator boolean\n",
      "   ✅ Created AGE_GROUP categories\n",
      "   ✅ Created INCOME_LEVEL labels\n",
      "\n",
      "✅ PREPROCESSING COMPLETE!\n",
      "📊 Final shape: (139233, 78)\n",
      "💾 Ready for R transfer!\n",
      "   ✅ Created a race indicator boolean\n",
      "   ✅ Created AGE_GROUP categories\n",
      "   ✅ Created INCOME_LEVEL labels\n",
      "\n",
      "✅ PREPROCESSING COMPLETE!\n",
      "📊 Final shape: (139233, 78)\n",
      "💾 Ready for R transfer!\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing in Python (before R transfer)\n",
    "print(\"Complete preprocessing: removing variables + cleaning data types...\")\n",
    "print(f\"Original shape: {df.shape}\")\n",
    "\n",
    "# ===== 1. REMOVE UNNECESSARY VARIABLES =====\n",
    "print(\"\\n1 Removing unnecessary variables...\")\n",
    "\n",
    "# Smart pattern-based removal in pandas (much faster than R)\n",
    "drop_patterns = [\n",
    "    r'^CPTCCS[2-9]$',      # CPTCCS2-CPTCCS9\n",
    "    r'^CPTCCS[1-3][0-9]$', # CPTCCS10-30\n",
    "    r'^CPT[2-9]$',         # CPT2-CPT9\n",
    "    r'^CPT[1-3][0-9]$',    # CPT10-30\n",
    "    r'^DXCCSR_',           # All DXCCSR columns (500+)\n",
    "]\n",
    "\n",
    "# Find columns to drop using vectorized operations\n",
    "drop_cols = []\n",
    "for pattern in drop_patterns:\n",
    "    matches = df.columns[df.columns.str.match(pattern)].tolist()\n",
    "    drop_cols.extend(matches)\n",
    "\n",
    "# Remove duplicates\n",
    "drop_cols = list(set(drop_cols))\n",
    "\n",
    "print(f\"   📊 Found {len(drop_cols)} columns to drop\")\n",
    "print(f\"   🗑️  Patterns: CPTCCS2-30, CPT2-30, all DXCCSR_*\")\n",
    "\n",
    "# Drop the columns\n",
    "df = df.drop(columns=drop_cols)\n",
    "print(f\"   ✅ Reduced from {df.shape[1] + len(drop_cols)} to {df.shape[1]} columns\")\n",
    "\n",
    "# ===== 2. CLEAN DATA TYPES FOR rpy2 =====\n",
    "print(\"\\n2️⃣ Cleaning data types for rpy2 compatibility...\")\n",
    "\n",
    "# Convert all object columns to strings (prevents mixed-type issues)\n",
    "object_columns = df.select_dtypes(include=['object']).columns\n",
    "if len(object_columns) > 0:\n",
    "    for col in object_columns:\n",
    "        df[col] = df[col].astype(str)\n",
    "    print(f\"   ✅ Converted {len(object_columns)} object columns to strings\")\n",
    "\n",
    "# Handle NaN/inf values consistently\n",
    "df = df.fillna('')  # Replace NaN with empty strings\n",
    "float_cols = df.select_dtypes(include=['float64']).columns\n",
    "if len(float_cols) > 0:\n",
    "    df[float_cols] = df[float_cols].replace([float('inf'), float('-inf')], '')\n",
    "    print(f\"   ✅ Cleaned inf values in {len(float_cols)} float columns\")\n",
    "\n",
    "# ===== 3. CREATE KEY ANALYTICAL VARIABLES IN PANDAS =====\n",
    "print(\"\\n3️⃣ Creating analytical variables...\")\n",
    "\n",
    "# Create WHITE indicator (1=White, 0=Non-White)\n",
    "if 'RACE' in df.columns:\n",
    "    df['WHITE'] = (df['RACE'].astype(str) == '1').astype(int)\n",
    "    print(\"   ✅ Created a race indicator boolean\")\n",
    "\n",
    "# Create age groups\n",
    "if 'AGE' in df.columns:\n",
    "    df['AGE'] = pd.to_numeric(df['AGE'], errors='coerce')  # Ensure numeric\n",
    "    df['AGE_GROUP'] = pd.cut(df['AGE'],\n",
    "                            bins=[0, 18, 30, 45, 65, float('inf')],\n",
    "                            labels=['0-17', '18-29', '30-44', '45-64', '65+'],\n",
    "                            right=False)\n",
    "    df['AGE_GROUP'] = df['AGE_GROUP'].astype(str)  # Convert to string for R\n",
    "    print(\"   ✅ Created AGE_GROUP categories\")\n",
    "\n",
    "# Create income level labels\n",
    "if 'ZIPINC_QRTL' in df.columns:\n",
    "    income_map = {1: 'Q1-Lowest', 2: 'Q2', 3: 'Q3', 4: 'Q4-Highest'}\n",
    "    df['INCOME_LEVEL'] = df['ZIPINC_QRTL'].astype(str).map(lambda x: income_map.get(int(x) if x.isdigit() else 0, 'Unknown'))\n",
    "    print(\"   ✅ Created INCOME_LEVEL labels\")\n",
    "\n",
    "# Ensure key numeric variables are properly typed\n",
    "numeric_vars = ['AGE', 'DISCWT', 'TOTCHG']\n",
    "for var in numeric_vars:\n",
    "    if var in df.columns:\n",
    "        df[var] = pd.to_numeric(df[var], errors='coerce')\n",
    "\n",
    "print(f\"\\n✅ PREPROCESSING COMPLETE!\")\n",
    "print(f\"📊 Final shape: {df.shape}\")\n",
    "print(f\"💾 Ready for R transfer!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1smsFldXrPrj"
   },
   "source": [
    "## 6. Final R Transfer & Processing\n",
    "\n",
    "Transfer the clean data to R and apply any final R-specific formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "10dad708"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<U+2705> R Complete: 139233 rows, 78 cols, 58.4 MB\n",
      "Converted 9 factors + 2 booleans\n",
      "\n",
      "Columns:\n",
      " [1] \"KEY_NASS\"            \"HOSP_NASS\"           \"HOSP_TEACH\"          139233 rows, 78 cols, 58.4 MB\n",
      "Converted 9 factors + 2 booleans\n",
      "\n",
      "Columns:\n",
      " [1] \"KEY_NASS\"            \"HOSP_NASS\"           \"HOSP_TEACH\"         \n",
      " [4] \"HOSP_LOCATION\"      \n",
      " [4] \"HOSP_LOCATION\"       \"HOSP_LOCTEACH\"       \"HOSP_REGION\"        \n",
      " [7] \"HOSP_BEDSIZE_CAT\"    \"DISCWT\"              \"NASS_STRATUM\"       \n",
      "[10] \"N_DISC_U\"            \"N_HOSP_U\"            \"S_DISC_U\"           \n",
      "[13] \"S_HOSP_U\"            \"TOTAL_AS_ENCOUNTERS\" \"YEAR\"               \n",
      "[16] \"AGE\"                 \"FEMALE\"              \"PL_NCHS\"            \n",
      "[19] \"ZIPINC_QRTL\"         \"AMONTH\"              \"AWEEKEND\"           \n",
      "[22] \"DQTR\"                \"PAY1\"                \"DISPUNIFORM\"        \n",
      "[25] \"TOTCHG\"              \"NCPT_INSCOPE\"        \"CPTCCS1\"            \n",
      "[28] \"CPT1\"                \"HOSP_LOCTEACH\"       \"HOSP_REGION\"        \n",
      " [7] \"HOSP_BEDSIZE_CAT\"    \"DISCWT\"              \"NASS_STRATUM\"       \n",
      "[10] \"N_DISC_U\"            \"N_HOSP_U\"            \"S_DISC_U\"           \n",
      "[13] \"S_HOSP_U\"            \"TOTAL_AS_ENCOUNTERS\" \"YEAR\"               \n",
      "[16] \"AGE\"                 \"FEMALE\"              \"PL_NCHS\"            \n",
      "[19] \"ZIPINC_QRTL\"         \"AMONTH\"              \"AWEEKEND\"           \n",
      "[22] \"DQTR\"                \"PAY1\"                \"DISPUNIFORM\"        \n",
      "[25] \"TOTCHG\"              \"NCPT_INSCOPE\"        \"CPTCCS1\"            \n",
      "[28] \"CPT1\"                \"I10_NDX\"             \"I10_DX1\"            \n",
      "[31] \"I10_DX2\"             \"I10_DX3\"             \"I10_DX4\"            \n",
      "[34] \"I10_NDX\"             \"I10_DX1\"            \n",
      "[31] \"I10_DX2\"             \"I10_DX3\"             \"I10_DX4\"            \n",
      "[34] \"I10_DX5\"             \"I10_DX6\"             \"I10_DX7\"            \n",
      "[37] \"I10_DX5\"             \"I10_DX6\"             \"I10_DX7\"            \n",
      "[37] \"I10_DX8\"             \"I10_DX9\"             \"I10_DX10\"           \n",
      "[40] \"I10_DX11\"            \"I10_DX12\"            \"I10_DX13\"           \n",
      "[43] \"I10_DX14\"            \"I10_DX15\"            \"I10_DX16\"           \n",
      "[46] \"I10_DX17\"            \"I10_DX18\"            \"I10_DX19\"           \n",
      "[49] \"I10_DX20\"            \"RACE\"                \"I10_INJURY\"         \n",
      "[52] \"I10_MULTINJURY\"      \"CMR_AIDS\"            \"CMR_ALCOHOL\"        \n",
      "[55] \"CMR_AUTOIMMUNE\"      \"CMR_CANCER_LYMPH\"    \"CMR_CANCER_LEUK\"    \n",
      "[58] \"CMR_CANCER_METS\"     \"CMR_CANCER_NSITU\"    \"CMR_CANCER_SOLID\"   \n",
      "[61] \"CMR_DEMENTIA\"        \"CMR_DEPRESS\"         \"CMR_DIAB_UNCX\"      \n",
      "[64] \"CMR_DIAB_CX\"         \"CMR_DRUG_ABUSE\"      \"CMR_HTN_CX\"         \n",
      "[67] \"CMR_HTN_UNCX\"        \"CMR_LUNG_CHRONIC\"    \"CMR_OBESE\"          \n",
      "[70] \"CMR_PERIVASC\"        \"CMR_THYROID_HYPO\"    \"CMR_THYROID_OTH\"    \n",
      "[73] \"CMR_VERSION\"         \"AGEGRP\"              \"AGEGRP2\"            \n",
      "[76] \"WHITE\"               \"AGE_GROUP\"           \"INCOME_LEVEL\"       \n",
      "Ready for analysis!\n",
      " \"I10_DX8\"             \"I10_DX9\"             \"I10_DX10\"           \n",
      "[40] \"I10_DX11\"            \"I10_DX12\"            \"I10_DX13\"           \n",
      "[43] \"I10_DX14\"            \"I10_DX15\"            \"I10_DX16\"           \n",
      "[46] \"I10_DX17\"            \"I10_DX18\"            \"I10_DX19\"           \n",
      "[49] \"I10_DX20\"            \"RACE\"                \"I10_INJURY\"         \n",
      "[52] \"I10_MULTINJURY\"      \"CMR_AIDS\"            \"CMR_ALCOHOL\"        \n",
      "[55] \"CMR_AUTOIMMUNE\"      \"CMR_CANCER_LYMPH\"    \"CMR_CANCER_LEUK\"    \n",
      "[58] \"CMR_CANCER_METS\"     \"CMR_CANCER_NSITU\"    \"CMR_CANCER_SOLID\"   \n",
      "[61] \"CMR_DEMENTIA\"        \"CMR_DEPRESS\"         \"CMR_DIAB_UNCX\"      \n",
      "[64] \"CMR_DIAB_CX\"         \"CMR_DRUG_ABUSE\"      \"CMR_HTN_CX\"         \n",
      "[67] \"CMR_HTN_UNCX\"        \"CMR_LUNG_CHRONIC\"    \"CMR_OBESE\"          \n",
      "[70] \"CMR_PERIVASC\"        \"CMR_THYROID_HYPO\"    \"CMR_THYROID_OTH\"    \n",
      "[73] \"CMR_VERSION\"         \"AGEGRP\"              \"AGEGRP2\"            \n",
      "[76] \"WHITE\"               \"AGE_GROUP\"           \"INCOME_LEVEL\"       \n",
      "Ready for analysis!\n"
     ]
    }
   ],
   "source": [
    "%%R -i df -i VERBOSE_PRINTS\n",
    "\n",
    "# Convert to data.table and apply R types\n",
    "NASS <- as.data.table(df)\n",
    "\n",
    "# Factor variables\n",
    "factor_vars <- c(\"ZIPINC_QRTL\", \"PAY1\", \"CPTCCS1\", \"HOSP_LOCATION\",\n",
    "                 \"HOSP_TEACH\", \"HOSP_NASS\", \"RACE\", \"AGE_GROUP\", \"INCOME_LEVEL\")\n",
    "existing_factors <- factor_vars[factor_vars %in% names(NASS)]\n",
    "NASS[, (existing_factors) := lapply(.SD, as.factor), .SDcols = existing_factors]\n",
    "\n",
    "# Boolean variables\n",
    "if(\"FEMALE\" %in% names(NASS)) NASS[, FEMALE := as.logical(as.numeric(FEMALE))]\n",
    "if(\"WHITE\" %in% names(NASS)) NASS[, WHITE := as.logical(as.numeric(WHITE))]\n",
    "\n",
    "# Compact output\n",
    "cat(\"✅ R Complete:\", nrow(NASS), \"rows,\", ncol(NASS), \"cols,\",\n",
    "    round(object.size(NASS)/1024^2, 1), \"MB\\n\")\n",
    "cat(\"Converted\", length(existing_factors), \"factors + 2 booleans\\n\")\n",
    "\n",
    "if(VERBOSE_PRINTS) {\n",
    "  cat(\"\\nColumns:\\n\")\n",
    "  print(colnames(NASS))\n",
    "}\n",
    "\n",
    "cat(\"Ready for analysis!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "43230586"
   },
   "source": [
    "## 1. Dataset Overview and Summary\n",
    "\n",
    "Generate comprehensive summary statistics and overview of the NASS dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATASET ANALYSIS SUMMARY ===\n",
      "Data shape: 139233 rows x 78 columns\n",
      "Data shape: 139233 rows x 78 columns\n",
      "Created WHITE indicator variable\n",
      "\n",
      "Top 10 procedures (CPTCCS1):\n",
      "   Created WHITE indicator variable\n",
      "\n",
      "Top 10 procedures (CPTCCS1):\n",
      "    CPTCCS1 CPTCCS1     N\n",
      "     <fctr> <int>\n",
      " 1:      15 11335\n",
      " 2:     160  8579\n",
      " 3:      84  7056\n",
      " 4:     152  5198\n",
      " 5:      85  5066\n",
      " 6:     162  4269\n",
      " 7:      86  4260\n",
      " 8:     124  4154     N\n",
      "     <fctr> <int>\n",
      " 1:      15 11335\n",
      " 2:     160  8579\n",
      " 3:      84  7056\n",
      " 4:     152  5198\n",
      " 5:      85  5066\n",
      " 6:     162  4269\n",
      " 7:      86  4260\n",
      " 8:     124  4154\n",
      " 9:     175  3813\n",
      "10:       6  3715\n",
      "\n",
      "Race distribution: White = 72.1 %, Non-White = 27.9 \n",
      " 9:     175  3813\n",
      "10:       6  3715\n",
      "\n",
      "Race distribution: White = 72.1 %, Non-White = 27.9 %\n",
      "\n",
      "Age distribution:\n",
      "%\n",
      "\n",
      "Age distribution:\n",
      "   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n",
      "   0.00   38.00   56.00   52.06   68.00  104.00 \n",
      "\n",
      "Income quartiles:\n",
      "   INCOME_LEVEL     N   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n",
      "   0.00   38.00   56.00   52.06   68.00  104.00 \n",
      "\n",
      "Income quartiles:\n",
      "   INCOME_LEVEL     N\n",
      "         <fctr> <int>\n",
      "1:\n",
      "         <fctr> <int>\n",
      "1:    Q1-Lowest 31913\n",
      "2:           Q2 39311\n",
      "3:           Q3 34833\n",
      "4:   Q4-Highest 31625\n",
      "5:      Unknown  1551\n",
      "\n",
      "Summary complete - ready for detailed analysis\n",
      "    Q1-Lowest 31913\n",
      "2:           Q2 39311\n",
      "3:           Q3 34833\n",
      "4:   Q4-Highest 31625\n",
      "5:      Unknown  1551\n",
      "\n",
      "Summary complete - ready for detailed analysis\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "# Dataset Analysis Summary\n",
    "cat(\"=== DATASET ANALYSIS SUMMARY ===\\n\")\n",
    "cat(\"Data shape:\", nrow(NASS), \"rows x\", ncol(NASS), \"columns\\n\")\n",
    "flush.console()\n",
    "\n",
    "# Create WHITE indicator variable (1=White, 0=Non-White)\n",
    "if(\"RACE\" %in% names(NASS)) {\n",
    "  NASS[, WHITE := ifelse(RACE == 1, 1, 0)]\n",
    "  cat(\"Created WHITE indicator variable\\n\")\n",
    "}\n",
    "\n",
    "# Top 10 procedures summary\n",
    "if(\"CPTCCS1\" %in% names(NASS)) {\n",
    "  top10 <- NASS[, .N, by = CPTCCS1][order(-N)][1:10]\n",
    "  cat(\"\\nTop 10 procedures (CPTCCS1):\\n\")\n",
    "  print(top10)\n",
    "} else {\n",
    "  cat(\"Warning: CPTCCS1 variable not found\\n\")\n",
    "}\n",
    "\n",
    "# Basic demographic summary\n",
    "if(\"WHITE\" %in% names(NASS)) {\n",
    "  white_pct <- round(mean(NASS$WHITE, na.rm = TRUE) * 100, 1)\n",
    "  cat(\"\\nRace distribution: White =\", white_pct, \"%, Non-White =\", 100 - white_pct, \"%\\n\")\n",
    "}\n",
    "\n",
    "if(\"AGE\" %in% names(NASS)) {\n",
    "  age_summary <- summary(NASS$AGE)\n",
    "  cat(\"\\nAge distribution:\\n\")\n",
    "  print(age_summary)\n",
    "}\n",
    "\n",
    "if(\"INCOME_LEVEL\" %in% names(NASS)) {\n",
    "  income_dist <- NASS[, .N, by = INCOME_LEVEL][order(INCOME_LEVEL)]\n",
    "  cat(\"\\nIncome quartiles:\\n\")\n",
    "  print(income_dist)\n",
    "}\n",
    "\n",
    "cat(\"\\nSummary complete - ready for detailed analysis\\n\")\n",
    "flush.console()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package Installation and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete - consistent theme and colors defined\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "corrplot 0.92 loaded\n",
       "========================================\n",
       "ComplexHeatmap version 2.20.0\n",
       "Bioconductor page: http://bioconductor.org/packages/ComplexHeatmap/\n",
       "Github page: https://github.com/jokergoo/ComplexHeatmap\n",
       "Documentation: http://jokergoo.github.io/ComplexHeatmap-reference\n",
       "\n",
       "If you use it in published research, please cite either one:\n",
       "- Gu, Z. Complex Heatmap Visualization. iMeta 2022.\n",
       "- Gu, Z. Complex heatmaps reveal patterns and correlations in multidimensional \n",
       "    genomic data. Bioinformatics 2016.\n",
       "\n",
       "\n",
       "The new InteractiveComplexHeatmap package can directly export static \n",
       "complex heatmaps into an interactive Shiny app with zero effort. Have a try!\n",
       "\n",
       "This message can be suppressed by:\n",
       "  suppressPackageStartupMessages(library(ComplexHeatmap))\n",
       "========================================\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "# Install and load required packages for comprehensive analysis\n",
    "\n",
    "required_packages <- c(\"ggplot2\", \"data.table\", \"gtsummary\", \"corrplot\", \n",
    "                      \"ComplexHeatmap\", \"scales\", \"RColorBrewer\")\n",
    "\n",
    "for(pkg in required_packages) {\n",
    "  if(!require(pkg, character.only = TRUE, quietly = TRUE)) {\n",
    "    cat(\"Installing\", pkg, \"...\\n\")\n",
    "    tryCatch({\n",
    "      install.packages(pkg, quiet = TRUE)\n",
    "      library(pkg, character.only = TRUE, quietly = TRUE)\n",
    "    }, error = function(e) {\n",
    "      cat(\"Warning: Failed to install/load\", pkg, \":\", e$message, \"\\n\")\n",
    "    })\n",
    "  }\n",
    "}\n",
    "\n",
    "# Set consistent theme for all visualizations\n",
    "if(require(\"ggplot2\", quietly = TRUE)) {\n",
    "  theme_nass <- theme_minimal() +\n",
    "    theme(\n",
    "      plot.title = element_text(size = 14, face = \"bold\", hjust = 0.5),\n",
    "      plot.subtitle = element_text(size = 12, hjust = 0.5, color = \"gray40\"),\n",
    "      axis.title = element_text(size = 11, face = \"bold\"),\n",
    "      axis.text = element_text(size = 10),\n",
    "      legend.title = element_text(size = 11, face = \"bold\"),\n",
    "      legend.text = element_text(size = 10),\n",
    "      strip.text = element_text(size = 10, face = \"bold\"),\n",
    "      panel.grid.minor = element_blank()\n",
    "    )\n",
    "}\n",
    "\n",
    "# Define consistent color palettes\n",
    "if(require(\"RColorBrewer\", quietly = TRUE)) {\n",
    "  race_colors <- RColorBrewer::brewer.pal(6, \"Set2\")\n",
    "  pay_colors <- RColorBrewer::brewer.pal(6, \"Dark2\")\n",
    "  region_colors <- RColorBrewer::brewer.pal(4, \"Set1\")\n",
    "} else {\n",
    "  # Fallback colors if RColorBrewer not available\n",
    "  race_colors <- rainbow(6)\n",
    "  pay_colors <- rainbow(6)\n",
    "  region_colors <- rainbow(4)\n",
    "}\n",
    "\n",
    "cat(\"Setup complete - consistent theme and colors defined\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "# Basic dataset summary\n",
    "cat(\"=== COMPREHENSIVE DATASET ANALYSIS ===\\n\")\n",
    "cat(\"Data shape:\", nrow(NASS), \"rows x\", ncol(NASS), \"columns\\n\")\n",
    "\n",
    "# Create essential derived variables (assuming these don't exist from previous analysis)\n",
    "if(!\"WHITE\" %in% names(NASS) && \"RACE\" %in% names(NASS)) {\n",
    "  NASS[, WHITE := ifelse(RACE == 1, 1, 0)]\n",
    "  cat(\"Created WHITE indicator variable\\n\")\n",
    "}\n",
    "\n",
    "if(!\"AGE_GROUP\" %in% names(NASS) && \"AGE\" %in% names(NASS)) {\n",
    "  NASS[, AGE_GROUP := cut(AGE, breaks = c(0, 18, 65, 120), \n",
    "                         labels = c(\"0-17\", \"18-64\", \"65+\"), \n",
    "                         include.lowest = TRUE, right = FALSE)]\n",
    "  cat(\"Created AGE_GROUP categories\\n\")\n",
    "}\n",
    "\n",
    "# Display basic demographics\n",
    "if(\"WHITE\" %in% names(NASS)) {\n",
    "  white_pct <- round(mean(NASS$WHITE, na.rm = TRUE) * 100, 1)\n",
    "  cat(\"Race distribution: White =\", white_pct, \"%, Non-White =\", 100 - white_pct, \"%\\n\")\n",
    "}\n",
    "\n",
    "if(\"AGE\" %in% names(NASS)) {\n",
    "  cat(\"Age summary:\\n\")\n",
    "  print(summary(NASS$AGE))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "# Hospital distribution by region and characteristics\n",
    "if(all(c(\"HOSP_REGION\", \"HOSP_BEDSIZE_CAT\", \"HOSP_LOCATION\", \"HOSP_TEACH\") %in% names(NASS))) {\n",
    "  \n",
    "  # Get unique hospital characteristics\n",
    "  hospital_chars <- unique(NASS[, .(HOSP_NASS, HOSP_LOCATION, HOSP_TEACH, \n",
    "                                   HOSP_REGION, HOSP_BEDSIZE_CAT)])\n",
    "  \n",
    "  # Define labels\n",
    "  bed_labels <- c(\"1\" = \"Small (0-99)\", \"2\" = \"Medium (100-299)\", \"3\" = \"Large (300+)\")\n",
    "  region_labels <- c(\"1\" = \"Northeast\", \"2\" = \"Midwest\", \"3\" = \"South\", \"4\" = \"West\")\n",
    "  teach_labels <- c(\"0\" = \"Non-Teaching\", \"1\" = \"Teaching\")\n",
    "  location_labels <- c(\"0\" = \"Rural\", \"1\" = \"Urban\")\n",
    "  \n",
    "  p1 <- ggplot(hospital_chars, aes(x = factor(HOSP_REGION), fill = factor(HOSP_BEDSIZE_CAT))) + \n",
    "    geom_bar(alpha = 0.8, color = \"white\", size = 0.3) + \n",
    "    theme_nass + \n",
    "    labs(\n",
    "      x = \"US Region\", \n",
    "      y = \"Number of Hospitals\",\n",
    "      title = \"Hospital Distribution in NASS 2020 Dataset\", \n",
    "      subtitle = \"By Region, Location, Teaching Status, and Bed Size\",\n",
    "      fill = \"Bed Size Category\"\n",
    "    ) + \n",
    "    scale_fill_manual(values = region_colors, labels = bed_labels) + \n",
    "    scale_x_discrete(labels = region_labels) +\n",
    "    facet_grid(HOSP_LOCATION ~ HOSP_TEACH, \n",
    "               labeller = labeller(HOSP_TEACH = teach_labels, \n",
    "                                 HOSP_LOCATION = location_labels)) +\n",
    "    theme(legend.position = \"bottom\")\n",
    "  \n",
    "  print(p1)\n",
    "  \n",
    "  cat(\"Hospital distribution plot generated for\", nrow(hospital_chars), \"hospitals\\n\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hospital Volume Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "# Hospital encounter volume distribution\n",
    "if(\"TOTAL_AS_ENCOUNTERS\" %in% names(NASS)) {\n",
    "  \n",
    "  hospital_volumes <- unique(NASS[, .(HOSP_NASS, HOSP_LOCATION, HOSP_TEACH, \n",
    "                                     HOSP_REGION, TOTAL_AS_ENCOUNTERS)])\n",
    "  \n",
    "  p2 <- ggplot(hospital_volumes, aes(x = factor(HOSP_REGION), y = TOTAL_AS_ENCOUNTERS)) + \n",
    "    geom_boxplot(aes(fill = factor(HOSP_REGION)), alpha = 0.7, outlier.alpha = 0.6) + \n",
    "    theme_nass + \n",
    "    labs(\n",
    "      x = \"US Region\", \n",
    "      y = \"Total Ambulatory Surgery Encounters\",\n",
    "      title = \"Hospital Ambulatory Surgery Volume Distribution\", \n",
    "      subtitle = \"By Region, Location, and Teaching Status\"\n",
    "    ) + \n",
    "    scale_fill_manual(values = region_colors, labels = region_labels, guide = \"none\") + \n",
    "    scale_x_discrete(labels = region_labels) +\n",
    "    scale_y_continuous(labels = comma_format()) +\n",
    "    facet_grid(HOSP_LOCATION ~ HOSP_TEACH, \n",
    "               labeller = labeller(HOSP_TEACH = teach_labels, \n",
    "                                 HOSP_LOCATION = location_labels))\n",
    "  \n",
    "  print(p2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "# Calculate and display top 10 procedures\n",
    "if(\"CPTCCS1\" %in% names(NASS)) {\n",
    "  \n",
    "  # Calculate top procedures\n",
    "  top_procedures <- NASS[, .N, by = CPTCCS1][order(-N)][1:10]\n",
    "  TopCPT <- top_procedures$CPTCCS1\n",
    "  \n",
    "  cat(\"Top 10 procedures (CPTCCS1):\\n\")\n",
    "  print(top_procedures)\n",
    "  \n",
    "  # Calculate coverage\n",
    "  coverage <- sum(top_procedures$N) / nrow(NASS)\n",
    "  cat(\"\\nTop 10 procedures represent\", round(coverage * 100, 1), \"% of all procedures\\n\")\n",
    "  \n",
    "  # Create subset for detailed analysis\n",
    "  NASS_top_procedures <- NASS[CPTCCS1 %in% TopCPT]\n",
    "  cat(\"Created subset with\", nrow(NASS_top_procedures), \"records for top procedures\\n\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "# Top procedures by income quartile\n",
    "if(exists(\"NASS_top_procedures\") && \"ZIPINC_QRTL\" %in% names(NASS)) {\n",
    "  \n",
    "  plot_data <- NASS_top_procedures[ZIPINC_QRTL %in% 1:4]\n",
    "  \n",
    "  if(nrow(plot_data) > 0) {\n",
    "    # Order procedures by frequency\n",
    "    proc_order <- plot_data[, .N, by = CPTCCS1][order(-N)]$CPTCCS1\n",
    "    plot_data[, CPTCCS1 := factor(CPTCCS1, levels = rev(proc_order))]\n",
    "    \n",
    "    p3 <- ggplot(plot_data, aes(x = CPTCCS1, fill = factor(ZIPINC_QRTL))) + \n",
    "      geom_bar(alpha = 0.8, color = \"white\", size = 0.2) + \n",
    "      coord_flip() +\n",
    "      theme_nass + \n",
    "      labs(\n",
    "        x = \"CCS Procedure Codes\", \n",
    "        y = \"Number of Procedures\",\n",
    "        title = \"Most Common Ambulatory Surgery Procedures\", \n",
    "        subtitle = \"Distribution by Patient Income Quartile (by ZIP code)\",\n",
    "        fill = \"Income Quartile\"\n",
    "      ) +\n",
    "      scale_fill_manual(values = pay_colors[1:4], \n",
    "                       labels = c(\"Q1 (Lowest)\", \"Q2\", \"Q3\", \"Q4 (Highest)\")) +\n",
    "      theme(legend.position = \"bottom\")\n",
    "    \n",
    "    print(p3)\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "# Top procedures by race\n",
    "if(exists(\"NASS_top_procedures\") && \"RACE\" %in% names(NASS)) {\n",
    "  \n",
    "  plot_data <- NASS_top_procedures[RACE %in% 1:6]\n",
    "  \n",
    "  if(nrow(plot_data) > 0) {\n",
    "    # Order procedures by frequency\n",
    "    proc_order <- plot_data[, .N, by = CPTCCS1][order(-N)]$CPTCCS1\n",
    "    plot_data[, CPTCCS1 := factor(CPTCCS1, levels = rev(proc_order))]\n",
    "    \n",
    "    race_labels <- c(\"1\" = \"White\", \"2\" = \"Black\", \"3\" = \"Hispanic\", \n",
    "                    \"4\" = \"Asian/Pacific\", \"5\" = \"Native American\", \"6\" = \"Other\")\n",
    "    \n",
    "    p4 <- ggplot(plot_data, aes(x = CPTCCS1, fill = factor(RACE))) + \n",
    "      geom_bar(alpha = 0.8, color = \"white\", size = 0.2) + \n",
    "      coord_flip() +\n",
    "      theme_nass + \n",
    "      labs(\n",
    "        x = \"CCS Procedure Codes\", \n",
    "        y = \"Number of Procedures\",\n",
    "        title = \"Most Common Ambulatory Surgery Procedures\", \n",
    "        subtitle = \"Distribution by Patient Race/Ethnicity\",\n",
    "        fill = \"Race/Ethnicity\"\n",
    "      ) + \n",
    "      scale_fill_manual(values = race_colors, labels = race_labels) +\n",
    "      theme(legend.position = \"bottom\")\n",
    "    \n",
    "    print(p4)\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "# Age distribution by race and region\n",
    "if(all(c(\"AGE\", \"RACE\", \"HOSP_REGION\", \"PL_NCHS\") %in% names(NASS))) {\n",
    "  \n",
    "  age_data <- NASS[RACE %in% 1:6 & PL_NCHS %in% 1:6 & AGE >= 0 & AGE <= 100]\n",
    "  \n",
    "  if(nrow(age_data) > 0) {\n",
    "    \n",
    "    race_labels <- c(\"1\" = \"White\", \"2\" = \"Black\", \"3\" = \"Hispanic\", \n",
    "                    \"4\" = \"Asian/Pacific\", \"5\" = \"Native American\", \"6\" = \"Other\")\n",
    "    region_labels <- c(\"1\" = \"Northeast\", \"2\" = \"Midwest\", \"3\" = \"South\", \"4\" = \"West\")\n",
    "    pl_nchs_labels <- c(\"1\" = \"Large Central\", \"2\" = \"Large Fringe\", \"3\" = \"Medium\", \n",
    "                       \"4\" = \"Small\", \"5\" = \"Micro\", \"6\" = \"Non-core\")\n",
    "    \n",
    "    p5 <- ggplot(age_data, aes(x = AGE)) + \n",
    "      geom_density(aes(fill = factor(RACE)), alpha = 0.7, color = \"white\", size = 0.2) + \n",
    "      theme_nass + \n",
    "      labs(\n",
    "        x = \"Age (years)\", \n",
    "        y = \"Density\",\n",
    "        title = \"Patient Age Distribution in NASS 2020\", \n",
    "        subtitle = \"By Urban-Rural Classification and US Region, Segmented by Race\",\n",
    "        fill = \"Race/Ethnicity\"\n",
    "      ) + \n",
    "      scale_fill_manual(values = race_colors, labels = race_labels) + \n",
    "      xlim(0, 100) +\n",
    "      facet_grid(HOSP_REGION ~ PL_NCHS, \n",
    "                 labeller = labeller(HOSP_REGION = region_labels, PL_NCHS = pl_nchs_labels)) + \n",
    "      theme(legend.position = \"bottom\", \n",
    "            strip.text = element_text(size = 8))\n",
    "    \n",
    "    print(p5)\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "# Age distribution by payer and region\n",
    "if(all(c(\"AGE\", \"PAY1\", \"HOSP_REGION\", \"PL_NCHS\") %in% names(NASS))) {\n",
    "  \n",
    "  age_payer_data <- NASS[PAY1 %in% 1:6 & PL_NCHS %in% 1:6 & AGE >= 0 & AGE <= 100]\n",
    "  \n",
    "  if(nrow(age_payer_data) > 0) {\n",
    "    \n",
    "    pay_labels <- c(\"1\" = \"Medicare\", \"2\" = \"Medicaid\", \"3\" = \"Private\", \n",
    "                   \"4\" = \"Self-pay\", \"5\" = \"No Charge\", \"6\" = \"Other\")\n",
    "    \n",
    "    p6 <- ggplot(age_payer_data, aes(x = AGE)) + \n",
    "      geom_density(aes(fill = factor(PAY1)), alpha = 0.7, color = \"white\", size = 0.2) + \n",
    "      theme_nass + \n",
    "      labs(\n",
    "        x = \"Age (years)\", \n",
    "        y = \"Density\",\n",
    "        title = \"Patient Age Distribution in NASS 2020\", \n",
    "        subtitle = \"By Urban-Rural Classification and US Region, Segmented by Payer\",\n",
    "        fill = \"Primary Payer\"\n",
    "      ) + \n",
    "      scale_fill_manual(values = pay_colors, labels = pay_labels) + \n",
    "      xlim(0, 100) +\n",
    "      facet_grid(HOSP_REGION ~ PL_NCHS, \n",
    "                 labeller = labeller(HOSP_REGION = region_labels, PL_NCHS = pl_nchs_labels)) + \n",
    "      theme(legend.position = \"bottom\",\n",
    "            strip.text = element_text(size = 8))\n",
    "    \n",
    "    print(p6)\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "# Payer distribution by race and age group\n",
    "if(all(c(\"RACE\", \"PAY1\", \"AGE_GROUP\") %in% names(NASS))) {\n",
    "  \n",
    "  payer_demo_data <- NASS[RACE %in% 1:6 & PAY1 %in% 1:6 & !is.na(AGE_GROUP)]\n",
    "  \n",
    "  if(nrow(payer_demo_data) > 0) {\n",
    "    \n",
    "    p7 <- ggplot(payer_demo_data, aes(x = factor(RACE), fill = factor(PAY1))) + \n",
    "      geom_bar(position = \"fill\", alpha = 0.8, color = \"white\", size = 0.2) + \n",
    "      theme_nass + \n",
    "      labs(\n",
    "        x = \"Race/Ethnicity\", \n",
    "        y = \"Proportion\",\n",
    "        title = \"Primary Payer Distribution by Demographics\", \n",
    "        subtitle = \"Proportions by Age Group and Race/Ethnicity\",\n",
    "        fill = \"Primary Payer\"\n",
    "      ) + \n",
    "      scale_fill_manual(values = pay_colors, labels = pay_labels) + \n",
    "      scale_x_discrete(labels = race_labels) +\n",
    "      scale_y_continuous(labels = percent_format()) +\n",
    "      facet_wrap(~ AGE_GROUP, ncol = 3) +\n",
    "      theme(axis.text.x = element_text(angle = 45, hjust = 1),\n",
    "            legend.position = \"bottom\")\n",
    "    \n",
    "    print(p7)\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "# Generate comprehensive summary table\n",
    "if(require(\"gtsummary\", quietly = TRUE)) {\n",
    "  \n",
    "  # Select key variables for summary\n",
    "  summary_vars <- c(\"AGE\", \"FEMALE\", \"RACE\", \"ZIPINC_QRTL\", \"PAY1\", \n",
    "                   \"HOSP_LOCATION\", \"HOSP_TEACH\", \"HOSP_REGION\")\n",
    "  \n",
    "  available_vars <- summary_vars[summary_vars %in% names(NASS)]\n",
    "  \n",
    "  if(length(available_vars) > 0) {\n",
    "    \n",
    "    # Convert to data.frame and apply labels\n",
    "    summary_data <- as.data.frame(NASS[, ..available_vars])\n",
    "    \n",
    "    # Apply factor labels\n",
    "    if(\"RACE\" %in% available_vars) {\n",
    "      summary_data$RACE <- factor(summary_data$RACE, levels = 1:6, \n",
    "                                 labels = c(\"White\", \"Black\", \"Hispanic\", \n",
    "                                          \"Asian/Pacific\", \"Native American\", \"Other\"))\n",
    "    }\n",
    "    if(\"PAY1\" %in% available_vars) {\n",
    "      summary_data$PAY1 <- factor(summary_data$PAY1, levels = 1:6, \n",
    "                                 labels = c(\"Medicare\", \"Medicaid\", \"Private\", \n",
    "                                          \"Self-pay\", \"No Charge\", \"Other\"))\n",
    "    }\n",
    "    if(\"FEMALE\" %in% available_vars) {\n",
    "      summary_data$FEMALE <- factor(summary_data$FEMALE, levels = 0:1, \n",
    "                                   labels = c(\"Male\", \"Female\"))\n",
    "    }\n",
    "    if(\"HOSP_LOCATION\" %in% available_vars) {\n",
    "      summary_data$HOSP_LOCATION <- factor(summary_data$HOSP_LOCATION, levels = 0:1, \n",
    "                                          labels = c(\"Rural\", \"Urban\"))\n",
    "    }\n",
    "    if(\"HOSP_TEACH\" %in% available_vars) {\n",
    "      summary_data$HOSP_TEACH <- factor(summary_data$HOSP_TEACH, levels = 0:1, \n",
    "                                       labels = c(\"Non-Teaching\", \"Teaching\"))\n",
    "    }\n",
    "    if(\"HOSP_REGION\" %in% available_vars) {\n",
    "      summary_data$HOSP_REGION <- factor(summary_data$HOSP_REGION, levels = 1:4, \n",
    "                                        labels = c(\"Northeast\", \"Midwest\", \"South\", \"West\"))\n",
    "    }\n",
    "    if(\"ZIPINC_QRTL\" %in% available_vars) {\n",
    "      summary_data$ZIPINC_QRTL <- factor(summary_data$ZIPINC_QRTL, levels = 1:4, \n",
    "                                        labels = c(\"Q1 (Lowest)\", \"Q2\", \"Q3\", \"Q4 (Highest)\"))\n",
    "    }\n",
    "    \n",
    "    # Generate summary table\n",
    "    summary_table <- summary_data %>%\n",
    "      tbl_summary(\n",
    "        statistic = list(\n",
    "          all_continuous() ~ \"{mean} ({sd})\",\n",
    "          all_categorical() ~ \"{n} ({p}%)\"\n",
    "        ),\n",
    "        digits = all_continuous() ~ 1\n",
    "      ) %>%\n",
    "      modify_header(label ~ \"**Variable**\") %>%\n",
    "      modify_caption(\"**NASS 2020 Ambulatory Surgery Dataset Summary**\")\n",
    "    \n",
    "    print(summary_table)\n",
    "  }\n",
    "}\n",
    "\n",
    "cat(\"\\n=== COMPREHENSIVE DATASET OVERVIEW COMPLETE ===\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Census Data Comparisons\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "20a6a8a8"
   },
   "source": [
    "### Census API Setup and Data Retrieval\n",
    "\n",
    "Set up Census API integration and pull 2020 DHC population data for comparison with NASS sample proportions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ Please Register at the Census website for an API Key ](https://api.census.gov/data/key_signup.html). Enter your Census API key for data retrieval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6d0c69b9"
   },
   "outputs": [],
   "source": [
    "import getpass, os, json, textwrap\n",
    "os.environ[\"CENSUS_API_KEY\"] = getpass.getpass(\"Enter your Census API key (will not echo):\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3c39ad38"
   },
   "source": [
    "### Census Data Retrieval and Processing\n",
    "\n",
    "Pull 2020 DHC population data by age, gender, and race for states included in NASS sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "240fd569"
   },
   "outputs": [],
   "source": [
    "%%R -i VERBOSE_PRINTS\n",
    "\n",
    "# Install and load required packages for Census analysis\n",
    "required_packages <- c(\"tidycensus\", \"dplyr\", \"tidyr\", \"survey\")\n",
    "\n",
    "for(pkg in required_packages) {\n",
    "  if(!require(pkg, character.only = TRUE, quietly = TRUE)) {\n",
    "    install.packages(pkg, quiet = TRUE)\n",
    "    library(pkg, character.only = TRUE, quietly = TRUE)\n",
    "  }\n",
    "}\n",
    "\n",
    "# Set Census API key\n",
    "census_api_key(Sys.getenv(\"CENSUS_API_KEY\"), overwrite = FALSE, install = FALSE)\n",
    "\n",
    "# Define states included in NASS 2020 dataset\n",
    "states_in_nass <- c(\"Alaska\", \"California\", \"Colorado\", \"Connecticut\", \"District of Columbia\", \n",
    "                    \"Florida\", \"Georgia\", \"Hawaii\", \"Iowa\", \"Illinois\", \"Indiana\", \"Kansas\", \n",
    "                    \"Kentucky\", \"Maryland\", \"Maine\", \"Michigan\", \"Minnesota\", \"Missouri\", \n",
    "                    \"North Carolina\", \"North Dakota\", \"Nebraska\", \"New Jersey\", \"Nevada\", \n",
    "                    \"New York\", \"Ohio\", \"Oklahoma\", \"Oregon\", \"Pennsylvania\", \"South Carolina\", \n",
    "                    \"South Dakota\", \"Tennessee\", \"Texas\", \"Utah\", \"Vermont\", \"Wisconsin\")\n",
    "\n",
    "cat(\"Defined\", length(states_in_nass), \"states included in NASS sample\\n\")\n",
    "\n",
    "# Function to construct population variables for Census queries\n",
    "get_population_variables <- function(base_variable) {\n",
    "    variables <- paste0(base_variable, \"_\", sprintf(\"%03dN\", 1:49))\n",
    "    \n",
    "    labels <- c(\n",
    "        \"Total\",\n",
    "        \"Male: Total\", \"Male: Under 5 years\", \"Male: 5 to 9 years\", \"Male: 10 to 14 years\",\n",
    "        \"Male: 15 to 17 years\", \"Male: 18 and 19 years\", \"Male: 20 years\", \"Male: 21 years\",\n",
    "        \"Male: 22 to 24 years\", \"Male: 25 to 29 years\", \"Male: 30 to 34 years\", \"Male: 35 to 39 years\",\n",
    "        \"Male: 40 to 44 years\", \"Male: 45 to 49 years\", \"Male: 50 to 54 years\", \"Male: 55 to 59 years\",\n",
    "        \"Male: 60 and 61 years\", \"Male: 62 to 64 years\", \"Male: 65 and 66 years\", \"Male: 67 to 69 years\",\n",
    "        \"Male: 70 to 74 years\", \"Male: 75 to 79 years\", \"Male: 80 to 84 years\", \"Male: 85 years and over\",\n",
    "        \"Female: Total\", \"Female: Under 5 years\", \"Female: 5 to 9 years\", \"Female: 10 to 14 years\",\n",
    "        \"Female: 15 to 17 years\", \"Female: 18 and 19 years\", \"Female: 20 years\", \"Female: 21 years\",\n",
    "        \"Female: 22 to 24 years\", \"Female: 25 to 29 years\", \"Female: 30 to 34 years\", \"Female: 35 to 39 years\",\n",
    "        \"Female: 40 to 44 years\", \"Female: 45 to 49 years\", \"Female: 50 to 54 years\", \"Female: 55 to 59 years\",\n",
    "        \"Female: 60 and 61 years\", \"Female: 62 to 64 years\", \"Female: 65 and 66 years\", \"Female: 67 to 69 years\",\n",
    "        \"Female: 70 to 74 years\", \"Female: 75 to 79 years\", \"Female: 80 to 84 years\", \"Female: 85 years and over\"\n",
    "    )\n",
    "    \n",
    "    names(labels) <- variables\n",
    "    return(list(variables = variables, labels = labels))\n",
    "}\n",
    "\n",
    "# Function to get population data from Census\n",
    "get_population_data <- function(variables, labels) {\n",
    "    population_data <- get_decennial(\n",
    "        geography = \"state\",\n",
    "        variables = variables,\n",
    "        year = 2020,\n",
    "        sumfile = \"dhc\"\n",
    "    )\n",
    "    \n",
    "    # Replace variable codes with descriptive labels\n",
    "    population_data <- population_data %>% \n",
    "        mutate(variable = recode(variable, !!!setNames(labels, variables)))\n",
    "    \n",
    "    # Reshape data for analysis\n",
    "    population_data <- population_data %>% \n",
    "        pivot_wider(names_from = variable, values_from = value)\n",
    "    \n",
    "    return(population_data)\n",
    "}\n",
    "\n",
    "# Get total population data (all races)\n",
    "cat(\"Retrieving total population data from 2020 Census...\\n\")\n",
    "population_info_total <- get_population_variables(\"P12\")\n",
    "total_population_by_age_gender <- get_population_data(population_info_total$variables, population_info_total$labels)\n",
    "\n",
    "# Get white alone population data\n",
    "cat(\"Retrieving white alone population data from 2020 Census...\\n\")\n",
    "population_info_white <- get_population_variables(\"P12I\")\n",
    "total_population_by_age_gender_white <- get_population_data(population_info_white$variables, population_info_white$labels)\n",
    "\n",
    "cat(\"Census data retrieval complete\\n\")\n",
    "\n",
    "if(VERBOSE_PRINTS) {\n",
    "  cat(\"\\nTotal population data structure:\\n\")\n",
    "  str(total_population_by_age_gender)\n",
    "  cat(\"\\nWhite population data structure:\\n\")\n",
    "  str(total_population_by_age_gender_white)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Comparison: NASS vs Census Proportions\n",
    "\n",
    "Compare unadjusted and weighted proportions of white individuals in NASS sample against Census benchmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "# ========================================\n",
    "# Stage 1a: Unadjusted Proportion Analysis\n",
    "# ========================================\n",
    "\n",
    "cat(\"=== STAGE 1A: UNADJUSTED PROPORTION ANALYSIS ===\\n\")\n",
    "\n",
    "# Calculate unadjusted proportion of white individuals in NASS\n",
    "unadjusted_proportion_white <- mean(NASS$WHITE, na.rm = TRUE)\n",
    "cat(\"Unadjusted proportion of WHITE in NASS:\", round(unadjusted_proportion_white, 4), \"\\n\")\n",
    "\n",
    "# Calculate reference proportion from entire US Census\n",
    "us_census_white_proportion <- sum(total_population_by_age_gender_white$Total, na.rm = TRUE) / \n",
    "                             sum(total_population_by_age_gender$Total, na.rm = TRUE)\n",
    "cat(\"US Census White alone proportion:\", round(us_census_white_proportion, 4), \"\\n\")\n",
    "\n",
    "# Statistical test for unadjusted proportion\n",
    "unadjusted_test <- prop.test(sum(NASS$WHITE, na.rm = TRUE), \n",
    "                            sum(!is.na(NASS$WHITE)), \n",
    "                            p = us_census_white_proportion)\n",
    "cat(\"\\nUnadjusted proportion test results:\\n\")\n",
    "print(unadjusted_test)\n",
    "\n",
    "# ========================================\n",
    "# Stage 1b: Weighted Proportion Analysis\n",
    "# ========================================\n",
    "\n",
    "cat(\"\\n=== STAGE 1B: WEIGHTED PROPORTION ANALYSIS ===\\n\")\n",
    "\n",
    "# Filter Census data for NASS-included states only\n",
    "filtered_total_population <- total_population_by_age_gender %>% \n",
    "    filter(NAME %in% states_in_nass)\n",
    "\n",
    "filtered_white_population <- total_population_by_age_gender_white %>% \n",
    "    filter(NAME %in% states_in_nass)\n",
    "\n",
    "# Calculate true proportion for NASS states\n",
    "total_population_nass_states <- sum(filtered_total_population$Total, na.rm = TRUE)\n",
    "total_white_population_nass_states <- sum(filtered_white_population$Total, na.rm = TRUE)\n",
    "true_proportion_white_nass_states <- total_white_population_nass_states / total_population_nass_states\n",
    "\n",
    "cat(\"True proportion of WHITE in NASS states:\", round(true_proportion_white_nass_states, 4), \"\\n\")\n",
    "\n",
    "# Calculate weighted proportion using survey design\n",
    "survey_design <- svydesign(ids = ~1, weights = ~DISCWT, data = NASS)\n",
    "weighted_proportion_white <- svymean(~WHITE, design = survey_design)\n",
    "cat(\"Weighted proportion of WHITE in NASS:\", round(coef(weighted_proportion_white), 4), \"\\n\")\n",
    "\n",
    "# Statistical test for weighted proportion\n",
    "weighted_test <- svyttest(WHITE ~ 1, design = survey_design, mu = true_proportion_white_nass_states)\n",
    "cat(\"\\nWeighted proportion test results:\\n\")\n",
    "print(weighted_test)\n",
    "\n",
    "cat(\"\\n=== PROPORTION ANALYSIS COMPLETE ===\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age-Gender Stratified Analysis\n",
    "\n",
    "Detailed comparison of white proportions by age group and gender between NASS sample and Census data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "# ========================================\n",
    "# Stage 2: Age-Gender Stratified Analysis\n",
    "# ========================================\n",
    "\n",
    "cat(\"=== STAGE 2: AGE-GENDER STRATIFIED ANALYSIS ===\\n\")\n",
    "\n",
    "# Define age groups matching Census categories\n",
    "age_breaks <- c(-Inf, 4, 9, 14, 17, 19, 20, 21, 24, 29, 34, 39, 44, 49, 54, 59, 61, 64, 66, 69, 74, 79, 84, Inf)\n",
    "age_labels <- c(\"Under 5 years\", \"5 to 9 years\", \"10 to 14 years\", \"15 to 17 years\", \"18 and 19 years\",\n",
    "                \"20 years\", \"21 years\", \"22 to 24 years\", \"25 to 29 years\", \"30 to 34 years\",\n",
    "                \"35 to 39 years\", \"40 to 44 years\", \"45 to 49 years\", \"50 to 54 years\", \"55 to 59 years\",\n",
    "                \"60 and 61 years\", \"62 to 64 years\", \"65 and 66 years\", \"67 to 69 years\", \"70 to 74 years\",\n",
    "                \"75 to 79 years\", \"80 to 84 years\", \"85 years and over\")\n",
    "\n",
    "# Create age group variable in NASS dataset\n",
    "NASS[, AGE_GROUP := cut(AGE, breaks = age_breaks, labels = age_labels, right = TRUE)]\n",
    "NASS[, GENDER := ifelse(FEMALE == 0, \"Male\", \"Female\")]\n",
    "\n",
    "cat(\"Created age groups and gender variables\\n\")\n",
    "\n",
    "# Calculate NASS proportions by age group and gender\n",
    "nass_proportions <- NASS[!is.na(AGE_GROUP) & !is.na(WHITE), \n",
    "                        .(total = .N,\n",
    "                          white = sum(WHITE, na.rm = TRUE),\n",
    "                          proportion_white = mean(WHITE, na.rm = TRUE)), \n",
    "                        by = .(AGE_GROUP, GENDER)]\n",
    "\n",
    "# Add confidence intervals\n",
    "nass_proportions[, ':='(\n",
    "  ci_lower = proportion_white - 1.96 * sqrt((proportion_white * (1 - proportion_white)) / total),\n",
    "  ci_upper = proportion_white + 1.96 * sqrt((proportion_white * (1 - proportion_white)) / total)\n",
    ")]\n",
    "\n",
    "cat(\"Calculated NASS proportions by age-gender groups\\n\")\n",
    "\n",
    "# Process Census data for comparison\n",
    "census_proportions <- total_population_by_age_gender_white %>% \n",
    "    select(NAME, starts_with(\"Male\"), starts_with(\"Female\")) %>% \n",
    "    pivot_longer(cols = -NAME, names_to = \"age_gender\", values_to = \"white_population\") %>% \n",
    "    separate(age_gender, into = c(\"gender\", \"age_group\"), sep = \": \") %>% \n",
    "    left_join(\n",
    "        total_population_by_age_gender %>% \n",
    "            select(NAME, starts_with(\"Male\"), starts_with(\"Female\")) %>% \n",
    "            pivot_longer(cols = -NAME, names_to = \"age_gender\", values_to = \"total_population\") %>% \n",
    "            separate(age_gender, into = c(\"gender\", \"age_group\"), sep = \": \"),\n",
    "        by = c(\"NAME\", \"gender\", \"age_group\")\n",
    "    ) %>% \n",
    "    filter(NAME %in% states_in_nass) %>%  # Filter for NASS states only\n",
    "    group_by(gender, age_group) %>% \n",
    "    summarize(\n",
    "        total_population = sum(total_population, na.rm = TRUE),\n",
    "        white_population = sum(white_population, na.rm = TRUE),\n",
    "        proportion_white = white_population / total_population,\n",
    "        .groups = 'drop'\n",
    "    ) %>% \n",
    "    filter(!is.na(age_group) & age_group != \"Total\")\n",
    "\n",
    "cat(\"Processed Census proportions by age-gender groups\\n\")\n",
    "\n",
    "# Convert to data.table for easier manipulation\n",
    "setDT(census_proportions)\n",
    "setDT(nass_proportions)\n",
    "\n",
    "# Convert age groups to factors for proper plotting\n",
    "census_proportions[, age_group := factor(age_group, levels = age_labels)]\n",
    "nass_proportions[, AGE_GROUP := factor(AGE_GROUP, levels = age_labels)]\n",
    "\n",
    "# Remove any missing age groups\n",
    "census_proportions <- census_proportions[!is.na(age_group)]\n",
    "nass_proportions <- nass_proportions[!is.na(AGE_GROUP)]\n",
    "\n",
    "cat(\"Data preparation complete\\n\")\n",
    "cat(\"NASS age-gender groups:\", nrow(nass_proportions), \"\\n\")\n",
    "cat(\"Census age-gender groups:\", nrow(census_proportions), \"\\n\")\n",
    "\n",
    "if(VERBOSE_PRINTS) {\n",
    "  cat(\"\\nSample NASS proportions:\\n\")\n",
    "  print(head(nass_proportions))\n",
    "  cat(\"\\nSample Census proportions:\\n\")\n",
    "  print(head(census_proportions))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Testing and Visualization\n",
    "\n",
    "Generate statistical tests comparing NASS and Census proportions across age-gender groups, with visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "# ========================================\n",
    "# Statistical Testing by Age-Gender Groups\n",
    "# ========================================\n",
    "\n",
    "cat(\"=== STATISTICAL TESTING BY AGE-GENDER GROUPS ===\\n\")\n",
    "\n",
    "# Perform statistical tests for each age-gender combination\n",
    "if(nrow(nass_proportions) > 0 && nrow(census_proportions) > 0) {\n",
    "  test_results <- merge(nass_proportions, census_proportions, \n",
    "                       by.x = c(\"AGE_GROUP\", \"GENDER\"), \n",
    "                       by.y = c(\"age_group\", \"gender\"),\n",
    "                       all.x = TRUE)\n",
    "  \n",
    "  # Function to perform proportion test safely\n",
    "  safe_prop_test <- function(white_count, total_count, census_prop) {\n",
    "    if(is.na(white_count) || is.na(total_count) || is.na(census_prop) || \n",
    "       total_count == 0 || census_prop == 0 || census_prop == 1) {\n",
    "      return(list(p.value = NA, significant = FALSE))\n",
    "    }\n",
    "    \n",
    "    tryCatch({\n",
    "      test_result <- prop.test(white_count, total_count, p = census_prop)\n",
    "      return(list(p.value = test_result$p.value, \n",
    "                 significant = test_result$p.value < 0.05))\n",
    "    }, error = function(e) {\n",
    "      return(list(p.value = NA, significant = FALSE))\n",
    "    })\n",
    "  }\n",
    "\n",
    "  # Apply tests\n",
    "  test_results[, c(\"p_value\", \"significant\") := {\n",
    "    test_res = safe_prop_test(white, total, proportion_white.y)\n",
    "    list(test_res$p.value, test_res$significant)\n",
    "  }, by = 1:nrow(test_results)]\n",
    "\n",
    "  cat(\"Statistical tests completed\\n\")\n",
    "\n",
    "  # Summary of significant differences\n",
    "  sig_count <- sum(test_results$significant, na.rm = TRUE)\n",
    "  total_tests <- sum(!is.na(test_results$p_value))\n",
    "  cat(\"Significant differences found:\", sig_count, \"out of\", total_tests, \"tests\\n\")\n",
    "\n",
    "  # Display results table\n",
    "  results_summary <- test_results[, .(\n",
    "    AGE_GROUP, GENDER,\n",
    "    NASS_count = total,\n",
    "    NASS_white_prop = round(proportion_white.x, 3),\n",
    "    Census_white_prop = round(proportion_white.y, 3),\n",
    "    p_value = round(p_value, 6),\n",
    "    significant = significant\n",
    "  )][order(AGE_GROUP, GENDER)]\n",
    "\n",
    "  cat(\"\\nDetailed results by age-gender group:\\n\")\n",
    "  print(results_summary)\n",
    "} else {\n",
    "  cat(\"Error: Missing proportion data for statistical testing\\n\")\n",
    "}\n",
    "\n",
    "# ========================================\n",
    "# Visualization\n",
    "# ========================================\n",
    "\n",
    "cat(\"\\n=== GENERATING VISUALIZATIONS ===\\n\")\n",
    "\n",
    "# Check if ggplot2 is available for plotting\n",
    "if(require(\"ggplot2\", quietly = TRUE)) {\n",
    "  \n",
    "  # Prepare data for plotting\n",
    "  plot_data_nass <- nass_proportions[, .(\n",
    "    AGE_GROUP, GENDER, proportion_white, ci_lower, ci_upper, source = \"NASS\"\n",
    "  )]\n",
    "  \n",
    "  plot_data_census <- census_proportions[, .(\n",
    "    AGE_GROUP = age_group, GENDER = gender, proportion_white, source = \"Census\"\n",
    "  )]\n",
    "  plot_data_census[, ':='(ci_lower = proportion_white, ci_upper = proportion_white)]\n",
    "  \n",
    "  plot_data <- rbind(plot_data_nass, plot_data_census, fill = TRUE)\n",
    "  \n",
    "  # Create the plot\n",
    "  age_gender_plot <- ggplot(plot_data, aes(x = AGE_GROUP, y = proportion_white, \n",
    "                                          color = source, group = interaction(source, GENDER))) +\n",
    "    geom_line(linewidth = 1) +\n",
    "    geom_point() +\n",
    "    geom_ribbon(data = plot_data[source == \"NASS\"], \n",
    "                aes(ymin = ci_lower, ymax = ci_upper, fill = source), \n",
    "                alpha = 0.2, color = NA) +\n",
    "    facet_wrap(~GENDER, ncol = 1) +\n",
    "    labs(title = \"White Proportion by Age Group: NASS vs Census\",\n",
    "         subtitle = \"Comparison across age groups and gender\",\n",
    "         x = \"Age Group\",\n",
    "         y = \"Proportion White\",\n",
    "         color = \"Data Source\",\n",
    "         fill = \"Confidence Interval\") +\n",
    "    theme_minimal() +\n",
    "    theme(axis.text.x = element_text(angle = 45, hjust = 1),\n",
    "          legend.position = \"bottom\") +\n",
    "    scale_y_continuous(limits = c(0, 1), labels = scales::percent)\n",
    "  \n",
    "  print(age_gender_plot)\n",
    "  cat(\"Visualization generated successfully\\n\")\n",
    "  \n",
    "} else {\n",
    "  cat(\"ggplot2 not available - using base R plotting\\n\")\n",
    "  \n",
    "  # Base R fallback plotting\n",
    "  par(mfrow = c(2, 1), mar = c(8, 4, 4, 2))\n",
    "  \n",
    "  # Males plot\n",
    "  male_nass <- nass_proportions[GENDER == \"Male\"]\n",
    "  male_census <- census_proportions[gender == \"Male\"]\n",
    "  \n",
    "  plot(1:nrow(male_nass), male_nass$proportion_white, type = \"b\", col = \"blue\",\n",
    "       xlab = \"\", ylab = \"Proportion White\", main = \"Males: NASS vs Census\",\n",
    "       ylim = c(0, 1), xaxt = \"n\")\n",
    "  lines(1:nrow(male_census), male_census$proportion_white, type = \"b\", col = \"red\")\n",
    "  axis(1, at = 1:nrow(male_nass), labels = male_nass$AGE_GROUP, las = 2, cex.axis = 0.8)\n",
    "  legend(\"topright\", legend = c(\"NASS\", \"Census\"), col = c(\"blue\", \"red\"), lty = 1)\n",
    "  \n",
    "  # Females plot\n",
    "  female_nass <- nass_proportions[GENDER == \"Female\"]\n",
    "  female_census <- census_proportions[gender == \"Female\"]\n",
    "  \n",
    "  plot(1:nrow(female_nass), female_nass$proportion_white, type = \"b\", col = \"blue\",\n",
    "       xlab = \"Age Group\", ylab = \"Proportion White\", main = \"Females: NASS vs Census\",\n",
    "       ylim = c(0, 1), xaxt = \"n\")\n",
    "  lines(1:nrow(female_census), female_census$proportion_white, type = \"b\", col = \"red\")\n",
    "  axis(1, at = 1:nrow(female_nass), labels = female_nass$AGE_GROUP, las = 2, cex.axis = 0.8)\n",
    "  legend(\"topright\", legend = c(\"NASS\", \"Census\"), col = c(\"blue\", \"red\"), lty = 1)\n",
    "  \n",
    "  par(mfrow = c(1, 1))\n",
    "  cat(\"Base R visualization generated\\n\")\n",
    "}\n",
    "\n",
    "cat(\"\\n=== CENSUS AGE-GENDER ANALYSIS COMPLETE ===\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-level Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
